/**
 * Generated by @openapi-codegen
 *
 * @version 1.65.4
 */
import type * as Fetcher from './fetcher';
import { type FetcherExtraProps, fetch } from './fetcher';
import type * as Schemas from './schemas';

export type ModelListModelsGetQueryParams = {
  /**
   * @default false
   */
  return_wildcard_routes?: boolean | null;
  team_id?: string | null;
};

export type ModelListModelsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ModelListModelsGetResponse = {
  [key: string]: any;
};

export type ModelListModelsGetVariables = {
  queryParams?: ModelListModelsGetQueryParams;
} & FetcherExtraProps;

/**
 * Use `/model/info` - to get detailed model information, example - pricing, mode, etc.
 *
 * This is just for compatibility with openai projects like aider.
 */
export const modelListModelsGet = (variables: ModelListModelsGetVariables, signal?: AbortSignal) =>
  fetch<ModelListModelsGetResponse, ModelListModelsGetError, undefined, {}, ModelListModelsGetQueryParams, {}>({
    url: '/models',
    method: 'get',
    ...variables,
    signal
  });

export type ModelListV1ModelsGetQueryParams = {
  /**
   * @default false
   */
  return_wildcard_routes?: boolean | null;
  team_id?: string | null;
};

export type ModelListV1ModelsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ModelListV1ModelsGetResponse = {
  [key: string]: any;
};

export type ModelListV1ModelsGetVariables = {
  queryParams?: ModelListV1ModelsGetQueryParams;
} & FetcherExtraProps;

/**
 * Use `/model/info` - to get detailed model information, example - pricing, mode, etc.
 *
 * This is just for compatibility with openai projects like aider.
 */
export const modelListV1ModelsGet = (variables: ModelListV1ModelsGetVariables, signal?: AbortSignal) =>
  fetch<ModelListV1ModelsGetResponse, ModelListV1ModelsGetError, undefined, {}, ModelListV1ModelsGetQueryParams, {}>({
    url: '/v1/models',
    method: 'get',
    ...variables,
    signal
  });

export type ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams = {
  model: string | null;
};

export type ChatCompletionOpenaiDeploymentsModelChatCompletionsPostError = Fetcher.ErrorWrapper<
  | {
      status: 400;
      payload: Schemas.ErrorResponse;
    }
  | {
      status: 401;
      payload: Schemas.ErrorResponse;
    }
  | {
      status: 403;
      payload: Schemas.ErrorResponse;
    }
  | {
      status: 404;
      payload: Schemas.ErrorResponse;
    }
  | {
      status: 408;
      payload: Schemas.ErrorResponse;
    }
  | {
      status: 422;
      payload: Schemas.ErrorResponse;
    }
  | {
      status: 429;
      payload: Schemas.ErrorResponse;
    }
  | {
      status: 500;
      payload: Schemas.ErrorResponse;
    }
  | {
      status: 503;
      payload: Schemas.ErrorResponse;
    }
>;

export type ChatCompletionOpenaiDeploymentsModelChatCompletionsPostResponse = {
  [key: string]: any;
};

export type ChatCompletionOpenaiDeploymentsModelChatCompletionsPostVariables = {
  pathParams: ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-4o",
 *     "messages": [
 *         {
 *             "role": "user",
 *             "content": "Hello!"
 *         }
 *     ]
 * }'
 * ```
 */
export const chatCompletionOpenaiDeploymentsModelChatCompletionsPost = (
  variables: ChatCompletionOpenaiDeploymentsModelChatCompletionsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    ChatCompletionOpenaiDeploymentsModelChatCompletionsPostResponse,
    ChatCompletionOpenaiDeploymentsModelChatCompletionsPostError,
    undefined,
    {},
    {},
    ChatCompletionOpenaiDeploymentsModelChatCompletionsPostPathParams
  >({ url: '/openai/deployments/{model}/chat/completions', method: 'post', ...variables, signal });

export type ChatCompletionEnginesModelChatCompletionsPostPathParams = {
  model: string | null;
};

export type ChatCompletionEnginesModelChatCompletionsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ChatCompletionEnginesModelChatCompletionsPostResponse = {
  [key: string]: any;
};

export type ChatCompletionEnginesModelChatCompletionsPostVariables = {
  pathParams: ChatCompletionEnginesModelChatCompletionsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-4o",
 *     "messages": [
 *         {
 *             "role": "user",
 *             "content": "Hello!"
 *         }
 *     ]
 * }'
 * ```
 */
export const chatCompletionEnginesModelChatCompletionsPost = (
  variables: ChatCompletionEnginesModelChatCompletionsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    ChatCompletionEnginesModelChatCompletionsPostResponse,
    ChatCompletionEnginesModelChatCompletionsPostError,
    undefined,
    {},
    {},
    ChatCompletionEnginesModelChatCompletionsPostPathParams
  >({ url: '/engines/{model}/chat/completions', method: 'post', ...variables, signal });

export type ChatCompletionChatCompletionsPostQueryParams = {
  model?: string | null;
};

export type ChatCompletionChatCompletionsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ChatCompletionChatCompletionsPostResponse = {
  [key: string]: any;
};

export type ChatCompletionChatCompletionsPostVariables = {
  queryParams?: ChatCompletionChatCompletionsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-4o",
 *     "messages": [
 *         {
 *             "role": "user",
 *             "content": "Hello!"
 *         }
 *     ]
 * }'
 * ```
 */
export const chatCompletionChatCompletionsPost = (
  variables: ChatCompletionChatCompletionsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    ChatCompletionChatCompletionsPostResponse,
    ChatCompletionChatCompletionsPostError,
    undefined,
    {},
    ChatCompletionChatCompletionsPostQueryParams,
    {}
  >({ url: '/chat/completions', method: 'post', ...variables, signal });

export type ChatCompletionV1ChatCompletionsPostQueryParams = {
  model?: string | null;
};

export type ChatCompletionV1ChatCompletionsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ChatCompletionV1ChatCompletionsPostResponse = {
  [key: string]: any;
};

export type ChatCompletionV1ChatCompletionsPostVariables = {
  queryParams?: ChatCompletionV1ChatCompletionsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-4o",
 *     "messages": [
 *         {
 *             "role": "user",
 *             "content": "Hello!"
 *         }
 *     ]
 * }'
 * ```
 */
export const chatCompletionV1ChatCompletionsPost = (
  variables: ChatCompletionV1ChatCompletionsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    ChatCompletionV1ChatCompletionsPostResponse,
    ChatCompletionV1ChatCompletionsPostError,
    undefined,
    {},
    ChatCompletionV1ChatCompletionsPostQueryParams,
    {}
  >({ url: '/v1/chat/completions', method: 'post', ...variables, signal });

export type CompletionOpenaiDeploymentsModelCompletionsPostPathParams = {
  model: string | null;
};

export type CompletionOpenaiDeploymentsModelCompletionsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CompletionOpenaiDeploymentsModelCompletionsPostResponse = {
  [key: string]: any;
};

export type CompletionOpenaiDeploymentsModelCompletionsPostVariables = {
  pathParams: CompletionOpenaiDeploymentsModelCompletionsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-3.5-turbo-instruct",
 *     "prompt": "Once upon a time",
 *     "max_tokens": 50,
 *     "temperature": 0.7
 * }'
 * ```
 */
export const completionOpenaiDeploymentsModelCompletionsPost = (
  variables: CompletionOpenaiDeploymentsModelCompletionsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CompletionOpenaiDeploymentsModelCompletionsPostResponse,
    CompletionOpenaiDeploymentsModelCompletionsPostError,
    undefined,
    {},
    {},
    CompletionOpenaiDeploymentsModelCompletionsPostPathParams
  >({ url: '/openai/deployments/{model}/completions', method: 'post', ...variables, signal });

export type CompletionEnginesModelCompletionsPostPathParams = {
  model: string | null;
};

export type CompletionEnginesModelCompletionsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CompletionEnginesModelCompletionsPostResponse = {
  [key: string]: any;
};

export type CompletionEnginesModelCompletionsPostVariables = {
  pathParams: CompletionEnginesModelCompletionsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-3.5-turbo-instruct",
 *     "prompt": "Once upon a time",
 *     "max_tokens": 50,
 *     "temperature": 0.7
 * }'
 * ```
 */
export const completionEnginesModelCompletionsPost = (
  variables: CompletionEnginesModelCompletionsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CompletionEnginesModelCompletionsPostResponse,
    CompletionEnginesModelCompletionsPostError,
    undefined,
    {},
    {},
    CompletionEnginesModelCompletionsPostPathParams
  >({ url: '/engines/{model}/completions', method: 'post', ...variables, signal });

export type CompletionCompletionsPostQueryParams = {
  model?: string | null;
};

export type CompletionCompletionsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CompletionCompletionsPostResponse = {
  [key: string]: any;
};

export type CompletionCompletionsPostVariables = {
  queryParams?: CompletionCompletionsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-3.5-turbo-instruct",
 *     "prompt": "Once upon a time",
 *     "max_tokens": 50,
 *     "temperature": 0.7
 * }'
 * ```
 */
export const completionCompletionsPost = (variables: CompletionCompletionsPostVariables, signal?: AbortSignal) =>
  fetch<
    CompletionCompletionsPostResponse,
    CompletionCompletionsPostError,
    undefined,
    {},
    CompletionCompletionsPostQueryParams,
    {}
  >({ url: '/completions', method: 'post', ...variables, signal });

export type CompletionV1CompletionsPostQueryParams = {
  model?: string | null;
};

export type CompletionV1CompletionsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CompletionV1CompletionsPostResponse = {
  [key: string]: any;
};

export type CompletionV1CompletionsPostVariables = {
  queryParams?: CompletionV1CompletionsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "gpt-3.5-turbo-instruct",
 *     "prompt": "Once upon a time",
 *     "max_tokens": 50,
 *     "temperature": 0.7
 * }'
 * ```
 */
export const completionV1CompletionsPost = (variables: CompletionV1CompletionsPostVariables, signal?: AbortSignal) =>
  fetch<
    CompletionV1CompletionsPostResponse,
    CompletionV1CompletionsPostError,
    undefined,
    {},
    CompletionV1CompletionsPostQueryParams,
    {}
  >({ url: '/v1/completions', method: 'post', ...variables, signal });

export type EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams = {
  model: string | null;
};

export type EmbeddingsOpenaiDeploymentsModelEmbeddingsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type EmbeddingsOpenaiDeploymentsModelEmbeddingsPostResponse = {
  [key: string]: any;
};

export type EmbeddingsOpenaiDeploymentsModelEmbeddingsPostVariables = {
  pathParams: EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "text-embedding-ada-002",
 *     "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsOpenaiDeploymentsModelEmbeddingsPost = (
  variables: EmbeddingsOpenaiDeploymentsModelEmbeddingsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    EmbeddingsOpenaiDeploymentsModelEmbeddingsPostResponse,
    EmbeddingsOpenaiDeploymentsModelEmbeddingsPostError,
    undefined,
    {},
    {},
    EmbeddingsOpenaiDeploymentsModelEmbeddingsPostPathParams
  >({ url: '/openai/deployments/{model}/embeddings', method: 'post', ...variables, signal });

export type EmbeddingsEnginesModelEmbeddingsPostPathParams = {
  model: string | null;
};

export type EmbeddingsEnginesModelEmbeddingsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type EmbeddingsEnginesModelEmbeddingsPostResponse = {
  [key: string]: any;
};

export type EmbeddingsEnginesModelEmbeddingsPostVariables = {
  pathParams: EmbeddingsEnginesModelEmbeddingsPostPathParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "text-embedding-ada-002",
 *     "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsEnginesModelEmbeddingsPost = (
  variables: EmbeddingsEnginesModelEmbeddingsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    EmbeddingsEnginesModelEmbeddingsPostResponse,
    EmbeddingsEnginesModelEmbeddingsPostError,
    undefined,
    {},
    {},
    EmbeddingsEnginesModelEmbeddingsPostPathParams
  >({ url: '/engines/{model}/embeddings', method: 'post', ...variables, signal });

export type EmbeddingsEmbeddingsPostQueryParams = {
  model?: string | null;
};

export type EmbeddingsEmbeddingsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type EmbeddingsEmbeddingsPostResponse = {
  [key: string]: any;
};

export type EmbeddingsEmbeddingsPostVariables = {
  queryParams?: EmbeddingsEmbeddingsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "text-embedding-ada-002",
 *     "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsEmbeddingsPost = (variables: EmbeddingsEmbeddingsPostVariables, signal?: AbortSignal) =>
  fetch<
    EmbeddingsEmbeddingsPostResponse,
    EmbeddingsEmbeddingsPostError,
    undefined,
    {},
    EmbeddingsEmbeddingsPostQueryParams,
    {}
  >({ url: '/embeddings', method: 'post', ...variables, signal });

export type EmbeddingsV1EmbeddingsPostQueryParams = {
  model?: string | null;
};

export type EmbeddingsV1EmbeddingsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type EmbeddingsV1EmbeddingsPostResponse = {
  [key: string]: any;
};

export type EmbeddingsV1EmbeddingsPostVariables = {
  queryParams?: EmbeddingsV1EmbeddingsPostQueryParams;
} & FetcherExtraProps;

/**
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 *     "model": "text-embedding-ada-002",
 *     "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsV1EmbeddingsPost = (variables: EmbeddingsV1EmbeddingsPostVariables, signal?: AbortSignal) =>
  fetch<
    EmbeddingsV1EmbeddingsPostResponse,
    EmbeddingsV1EmbeddingsPostError,
    undefined,
    {},
    EmbeddingsV1EmbeddingsPostQueryParams,
    {}
  >({ url: '/v1/embeddings', method: 'post', ...variables, signal });

export type ImageGenerationImagesGenerationsPostError = Fetcher.ErrorWrapper<undefined>;

export type ImageGenerationImagesGenerationsPostResponse = {
  [key: string]: any;
};

export type ImageGenerationImagesGenerationsPostVariables = FetcherExtraProps;

export const imageGenerationImagesGenerationsPost = (
  variables: ImageGenerationImagesGenerationsPostVariables,
  signal?: AbortSignal
) =>
  fetch<ImageGenerationImagesGenerationsPostResponse, ImageGenerationImagesGenerationsPostError, undefined, {}, {}, {}>(
    { url: '/images/generations', method: 'post', ...variables, signal }
  );

export type ImageGenerationV1ImagesGenerationsPostError = Fetcher.ErrorWrapper<undefined>;

export type ImageGenerationV1ImagesGenerationsPostResponse = {
  [key: string]: any;
};

export type ImageGenerationV1ImagesGenerationsPostVariables = FetcherExtraProps;

export const imageGenerationV1ImagesGenerationsPost = (
  variables: ImageGenerationV1ImagesGenerationsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    ImageGenerationV1ImagesGenerationsPostResponse,
    ImageGenerationV1ImagesGenerationsPostError,
    undefined,
    {},
    {},
    {}
  >({ url: '/v1/images/generations', method: 'post', ...variables, signal });

export type AudioSpeechAudioSpeechPostError = Fetcher.ErrorWrapper<undefined>;

export type AudioSpeechAudioSpeechPostResponse = {
  [key: string]: any;
};

export type AudioSpeechAudioSpeechPostVariables = FetcherExtraProps;

/**
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createSpeech
 */
export const audioSpeechAudioSpeechPost = (variables: AudioSpeechAudioSpeechPostVariables, signal?: AbortSignal) =>
  fetch<AudioSpeechAudioSpeechPostResponse, AudioSpeechAudioSpeechPostError, undefined, {}, {}, {}>({
    url: '/audio/speech',
    method: 'post',
    ...variables,
    signal
  });

export type AudioSpeechV1AudioSpeechPostError = Fetcher.ErrorWrapper<undefined>;

export type AudioSpeechV1AudioSpeechPostResponse = {
  [key: string]: any;
};

export type AudioSpeechV1AudioSpeechPostVariables = FetcherExtraProps;

/**
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createSpeech
 */
export const audioSpeechV1AudioSpeechPost = (variables: AudioSpeechV1AudioSpeechPostVariables, signal?: AbortSignal) =>
  fetch<AudioSpeechV1AudioSpeechPostResponse, AudioSpeechV1AudioSpeechPostError, undefined, {}, {}, {}>({
    url: '/v1/audio/speech',
    method: 'post',
    ...variables,
    signal
  });

export type AudioTranscriptionsAudioTranscriptionsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type AudioTranscriptionsAudioTranscriptionsPostResponse = {
  [key: string]: any;
};

export type AudioTranscriptionsAudioTranscriptionsPostVariables = {
  body: Schemas.BodyAudioTranscriptionsAudioTranscriptionsPost;
} & FetcherExtraProps;

/**
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 */
export const audioTranscriptionsAudioTranscriptionsPost = (
  variables: AudioTranscriptionsAudioTranscriptionsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    AudioTranscriptionsAudioTranscriptionsPostResponse,
    AudioTranscriptionsAudioTranscriptionsPostError,
    Schemas.BodyAudioTranscriptionsAudioTranscriptionsPost,
    {},
    {},
    {}
  >({ url: '/audio/transcriptions', method: 'post', ...variables, signal });

export type AudioTranscriptionsV1AudioTranscriptionsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type AudioTranscriptionsV1AudioTranscriptionsPostResponse = {
  [key: string]: any;
};

export type AudioTranscriptionsV1AudioTranscriptionsPostVariables = {
  body: Schemas.BodyAudioTranscriptionsV1AudioTranscriptionsPost;
} & FetcherExtraProps;

/**
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 */
export const audioTranscriptionsV1AudioTranscriptionsPost = (
  variables: AudioTranscriptionsV1AudioTranscriptionsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    AudioTranscriptionsV1AudioTranscriptionsPostResponse,
    AudioTranscriptionsV1AudioTranscriptionsPostError,
    Schemas.BodyAudioTranscriptionsV1AudioTranscriptionsPost,
    {},
    {},
    {}
  >({ url: '/v1/audio/transcriptions', method: 'post', ...variables, signal });

export type GetAssistantsAssistantsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetAssistantsAssistantsGetResponse = {
  [key: string]: any;
};

export type GetAssistantsAssistantsGetVariables = FetcherExtraProps;

/**
 * Returns a list of assistants.
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 */
export const getAssistantsAssistantsGet = (variables: GetAssistantsAssistantsGetVariables, signal?: AbortSignal) =>
  fetch<GetAssistantsAssistantsGetResponse, GetAssistantsAssistantsGetError, undefined, {}, {}, {}>({
    url: '/assistants',
    method: 'get',
    ...variables,
    signal
  });

export type CreateAssistantAssistantsPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateAssistantAssistantsPostResponse = {
  [key: string]: any;
};

export type CreateAssistantAssistantsPostVariables = FetcherExtraProps;

/**
 * Create assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const createAssistantAssistantsPost = (
  variables: CreateAssistantAssistantsPostVariables,
  signal?: AbortSignal
) =>
  fetch<CreateAssistantAssistantsPostResponse, CreateAssistantAssistantsPostError, undefined, {}, {}, {}>({
    url: '/assistants',
    method: 'post',
    ...variables,
    signal
  });

export type GetAssistantsV1AssistantsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetAssistantsV1AssistantsGetResponse = {
  [key: string]: any;
};

export type GetAssistantsV1AssistantsGetVariables = FetcherExtraProps;

/**
 * Returns a list of assistants.
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 */
export const getAssistantsV1AssistantsGet = (variables: GetAssistantsV1AssistantsGetVariables, signal?: AbortSignal) =>
  fetch<GetAssistantsV1AssistantsGetResponse, GetAssistantsV1AssistantsGetError, undefined, {}, {}, {}>({
    url: '/v1/assistants',
    method: 'get',
    ...variables,
    signal
  });

export type CreateAssistantV1AssistantsPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateAssistantV1AssistantsPostResponse = {
  [key: string]: any;
};

export type CreateAssistantV1AssistantsPostVariables = FetcherExtraProps;

/**
 * Create assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const createAssistantV1AssistantsPost = (
  variables: CreateAssistantV1AssistantsPostVariables,
  signal?: AbortSignal
) =>
  fetch<CreateAssistantV1AssistantsPostResponse, CreateAssistantV1AssistantsPostError, undefined, {}, {}, {}>({
    url: '/v1/assistants',
    method: 'post',
    ...variables,
    signal
  });

export type DeleteAssistantAssistantsAssistantIdDeletePathParams = {
  assistantId: string;
};

export type DeleteAssistantAssistantsAssistantIdDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteAssistantAssistantsAssistantIdDeleteResponse = {
  [key: string]: any;
};

export type DeleteAssistantAssistantsAssistantIdDeleteVariables = {
  pathParams: DeleteAssistantAssistantsAssistantIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const deleteAssistantAssistantsAssistantIdDelete = (
  variables: DeleteAssistantAssistantsAssistantIdDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteAssistantAssistantsAssistantIdDeleteResponse,
    DeleteAssistantAssistantsAssistantIdDeleteError,
    undefined,
    {},
    {},
    DeleteAssistantAssistantsAssistantIdDeletePathParams
  >({ url: '/assistants/{assistantId}', method: 'delete', ...variables, signal });

export type DeleteAssistantV1AssistantsAssistantIdDeletePathParams = {
  assistantId: string;
};

export type DeleteAssistantV1AssistantsAssistantIdDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteAssistantV1AssistantsAssistantIdDeleteResponse = {
  [key: string]: any;
};

export type DeleteAssistantV1AssistantsAssistantIdDeleteVariables = {
  pathParams: DeleteAssistantV1AssistantsAssistantIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const deleteAssistantV1AssistantsAssistantIdDelete = (
  variables: DeleteAssistantV1AssistantsAssistantIdDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteAssistantV1AssistantsAssistantIdDeleteResponse,
    DeleteAssistantV1AssistantsAssistantIdDeleteError,
    undefined,
    {},
    {},
    DeleteAssistantV1AssistantsAssistantIdDeletePathParams
  >({ url: '/v1/assistants/{assistantId}', method: 'delete', ...variables, signal });

export type CreateThreadsThreadsPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateThreadsThreadsPostResponse = {
  [key: string]: any;
};

export type CreateThreadsThreadsPostVariables = FetcherExtraProps;

/**
 * Create a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 */
export const createThreadsThreadsPost = (variables: CreateThreadsThreadsPostVariables, signal?: AbortSignal) =>
  fetch<CreateThreadsThreadsPostResponse, CreateThreadsThreadsPostError, undefined, {}, {}, {}>({
    url: '/threads',
    method: 'post',
    ...variables,
    signal
  });

export type CreateThreadsV1ThreadsPostError = Fetcher.ErrorWrapper<undefined>;

export type CreateThreadsV1ThreadsPostResponse = {
  [key: string]: any;
};

export type CreateThreadsV1ThreadsPostVariables = FetcherExtraProps;

/**
 * Create a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 */
export const createThreadsV1ThreadsPost = (variables: CreateThreadsV1ThreadsPostVariables, signal?: AbortSignal) =>
  fetch<CreateThreadsV1ThreadsPostResponse, CreateThreadsV1ThreadsPostError, undefined, {}, {}, {}>({
    url: '/v1/threads',
    method: 'post',
    ...variables,
    signal
  });

export type GetThreadThreadsThreadIdGetPathParams = {
  threadId: string;
};

export type GetThreadThreadsThreadIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetThreadThreadsThreadIdGetResponse = {
  [key: string]: any;
};

export type GetThreadThreadsThreadIdGetVariables = {
  pathParams: GetThreadThreadsThreadIdGetPathParams;
} & FetcherExtraProps;

/**
 * Retrieves a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 */
export const getThreadThreadsThreadIdGet = (variables: GetThreadThreadsThreadIdGetVariables, signal?: AbortSignal) =>
  fetch<
    GetThreadThreadsThreadIdGetResponse,
    GetThreadThreadsThreadIdGetError,
    undefined,
    {},
    {},
    GetThreadThreadsThreadIdGetPathParams
  >({ url: '/threads/{threadId}', method: 'get', ...variables, signal });

export type GetThreadV1ThreadsThreadIdGetPathParams = {
  threadId: string;
};

export type GetThreadV1ThreadsThreadIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetThreadV1ThreadsThreadIdGetResponse = {
  [key: string]: any;
};

export type GetThreadV1ThreadsThreadIdGetVariables = {
  pathParams: GetThreadV1ThreadsThreadIdGetPathParams;
} & FetcherExtraProps;

/**
 * Retrieves a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 */
export const getThreadV1ThreadsThreadIdGet = (
  variables: GetThreadV1ThreadsThreadIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetThreadV1ThreadsThreadIdGetResponse,
    GetThreadV1ThreadsThreadIdGetError,
    undefined,
    {},
    {},
    GetThreadV1ThreadsThreadIdGetPathParams
  >({ url: '/v1/threads/{threadId}', method: 'get', ...variables, signal });

export type AddMessagesThreadsThreadIdMessagesPostPathParams = {
  threadId: string;
};

export type AddMessagesThreadsThreadIdMessagesPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type AddMessagesThreadsThreadIdMessagesPostResponse = {
  [key: string]: any;
};

export type AddMessagesThreadsThreadIdMessagesPostVariables = {
  pathParams: AddMessagesThreadsThreadIdMessagesPostPathParams;
} & FetcherExtraProps;

/**
 * Create a message.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 */
export const addMessagesThreadsThreadIdMessagesPost = (
  variables: AddMessagesThreadsThreadIdMessagesPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    AddMessagesThreadsThreadIdMessagesPostResponse,
    AddMessagesThreadsThreadIdMessagesPostError,
    undefined,
    {},
    {},
    AddMessagesThreadsThreadIdMessagesPostPathParams
  >({ url: '/threads/{threadId}/messages', method: 'post', ...variables, signal });

export type GetMessagesThreadsThreadIdMessagesGetPathParams = {
  threadId: string;
};

export type GetMessagesThreadsThreadIdMessagesGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetMessagesThreadsThreadIdMessagesGetResponse = {
  [key: string]: any;
};

export type GetMessagesThreadsThreadIdMessagesGetVariables = {
  pathParams: GetMessagesThreadsThreadIdMessagesGetPathParams;
} & FetcherExtraProps;

/**
 * Returns a list of messages for a given thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 */
export const getMessagesThreadsThreadIdMessagesGet = (
  variables: GetMessagesThreadsThreadIdMessagesGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetMessagesThreadsThreadIdMessagesGetResponse,
    GetMessagesThreadsThreadIdMessagesGetError,
    undefined,
    {},
    {},
    GetMessagesThreadsThreadIdMessagesGetPathParams
  >({ url: '/threads/{threadId}/messages', method: 'get', ...variables, signal });

export type AddMessagesV1ThreadsThreadIdMessagesPostPathParams = {
  threadId: string;
};

export type AddMessagesV1ThreadsThreadIdMessagesPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type AddMessagesV1ThreadsThreadIdMessagesPostResponse = {
  [key: string]: any;
};

export type AddMessagesV1ThreadsThreadIdMessagesPostVariables = {
  pathParams: AddMessagesV1ThreadsThreadIdMessagesPostPathParams;
} & FetcherExtraProps;

/**
 * Create a message.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 */
export const addMessagesV1ThreadsThreadIdMessagesPost = (
  variables: AddMessagesV1ThreadsThreadIdMessagesPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    AddMessagesV1ThreadsThreadIdMessagesPostResponse,
    AddMessagesV1ThreadsThreadIdMessagesPostError,
    undefined,
    {},
    {},
    AddMessagesV1ThreadsThreadIdMessagesPostPathParams
  >({ url: '/v1/threads/{threadId}/messages', method: 'post', ...variables, signal });

export type GetMessagesV1ThreadsThreadIdMessagesGetPathParams = {
  threadId: string;
};

export type GetMessagesV1ThreadsThreadIdMessagesGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetMessagesV1ThreadsThreadIdMessagesGetResponse = {
  [key: string]: any;
};

export type GetMessagesV1ThreadsThreadIdMessagesGetVariables = {
  pathParams: GetMessagesV1ThreadsThreadIdMessagesGetPathParams;
} & FetcherExtraProps;

/**
 * Returns a list of messages for a given thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 */
export const getMessagesV1ThreadsThreadIdMessagesGet = (
  variables: GetMessagesV1ThreadsThreadIdMessagesGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetMessagesV1ThreadsThreadIdMessagesGetResponse,
    GetMessagesV1ThreadsThreadIdMessagesGetError,
    undefined,
    {},
    {},
    GetMessagesV1ThreadsThreadIdMessagesGetPathParams
  >({ url: '/v1/threads/{threadId}/messages', method: 'get', ...variables, signal });

export type RunThreadThreadsThreadIdRunsPostPathParams = {
  threadId: string;
};

export type RunThreadThreadsThreadIdRunsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type RunThreadThreadsThreadIdRunsPostResponse = {
  [key: string]: any;
};

export type RunThreadThreadsThreadIdRunsPostVariables = {
  pathParams: RunThreadThreadsThreadIdRunsPostPathParams;
} & FetcherExtraProps;

/**
 * Create a run.
 *
 * API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 */
export const runThreadThreadsThreadIdRunsPost = (
  variables: RunThreadThreadsThreadIdRunsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    RunThreadThreadsThreadIdRunsPostResponse,
    RunThreadThreadsThreadIdRunsPostError,
    undefined,
    {},
    {},
    RunThreadThreadsThreadIdRunsPostPathParams
  >({ url: '/threads/{threadId}/runs', method: 'post', ...variables, signal });

export type RunThreadV1ThreadsThreadIdRunsPostPathParams = {
  threadId: string;
};

export type RunThreadV1ThreadsThreadIdRunsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type RunThreadV1ThreadsThreadIdRunsPostResponse = {
  [key: string]: any;
};

export type RunThreadV1ThreadsThreadIdRunsPostVariables = {
  pathParams: RunThreadV1ThreadsThreadIdRunsPostPathParams;
} & FetcherExtraProps;

/**
 * Create a run.
 *
 * API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 */
export const runThreadV1ThreadsThreadIdRunsPost = (
  variables: RunThreadV1ThreadsThreadIdRunsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    RunThreadV1ThreadsThreadIdRunsPostResponse,
    RunThreadV1ThreadsThreadIdRunsPostError,
    undefined,
    {},
    {},
    RunThreadV1ThreadsThreadIdRunsPostPathParams
  >({ url: '/v1/threads/{threadId}/runs', method: 'post', ...variables, signal });

export type ModerationsModerationsPostError = Fetcher.ErrorWrapper<undefined>;

export type ModerationsModerationsPostResponse = {
  [key: string]: any;
};

export type ModerationsModerationsPostVariables = FetcherExtraProps;

/**
 * The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.
 *
 * Quick Start
 * ```
 * curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'
 * ```
 */
export const moderationsModerationsPost = (variables: ModerationsModerationsPostVariables, signal?: AbortSignal) =>
  fetch<ModerationsModerationsPostResponse, ModerationsModerationsPostError, undefined, {}, {}, {}>({
    url: '/moderations',
    method: 'post',
    ...variables,
    signal
  });

export type ModerationsV1ModerationsPostError = Fetcher.ErrorWrapper<undefined>;

export type ModerationsV1ModerationsPostResponse = {
  [key: string]: any;
};

export type ModerationsV1ModerationsPostVariables = FetcherExtraProps;

/**
 * The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.
 *
 * Quick Start
 * ```
 * curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'
 * ```
 */
export const moderationsV1ModerationsPost = (variables: ModerationsV1ModerationsPostVariables, signal?: AbortSignal) =>
  fetch<ModerationsV1ModerationsPostResponse, ModerationsV1ModerationsPostError, undefined, {}, {}, {}>({
    url: '/v1/moderations',
    method: 'post',
    ...variables,
    signal
  });

export type TokenCounterUtilsTokenCounterPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type TokenCounterUtilsTokenCounterPostVariables = {
  body: Schemas.TokenCountRequest;
} & FetcherExtraProps;

export const tokenCounterUtilsTokenCounterPost = (
  variables: TokenCounterUtilsTokenCounterPostVariables,
  signal?: AbortSignal
) =>
  fetch<Schemas.TokenCountResponse, TokenCounterUtilsTokenCounterPostError, Schemas.TokenCountRequest, {}, {}, {}>({
    url: '/utils/token_counter',
    method: 'post',
    ...variables,
    signal
  });

export type SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams = {
  model: string;
};

export type SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetResponse = {
  [key: string]: any;
};

export type SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetVariables = {
  queryParams: SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns supported openai params for a given litellm model name
 *
 * e.g. `gpt-4` vs `gpt-3.5-turbo`
 *
 * Example curl:
 * ```
 * curl -X GET --location 'http://localhost:4000/utils/supported_openai_params?model=gpt-3.5-turbo-16k'         --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const supportedOpenaiParamsUtilsSupportedOpenaiParamsGet = (
  variables: SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetResponse,
    SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetError,
    undefined,
    {},
    SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetQueryParams,
    {}
  >({ url: '/utils/supported_openai_params', method: 'get', ...variables, signal });

export type TransformRequestUtilsTransformRequestPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type TransformRequestUtilsTransformRequestPostVariables = {
  body: Schemas.TransformRequestBody;
} & FetcherExtraProps;

export const transformRequestUtilsTransformRequestPost = (
  variables: TransformRequestUtilsTransformRequestPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.RawRequestTypedDict,
    TransformRequestUtilsTransformRequestPostError,
    Schemas.TransformRequestBody,
    {},
    {},
    {}
  >({ url: '/utils/transform_request', method: 'post', ...variables, signal });

export type ModelInfoV1V1ModelInfoGetQueryParams = {
  litellm_model_id?: string | null;
};

export type ModelInfoV1V1ModelInfoGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ModelInfoV1V1ModelInfoGetResponse = {
  data?: Schemas.Deployment[];
} & {
  [key: string]: any;
};

export type ModelInfoV1V1ModelInfoGetVariables = {
  queryParams?: ModelInfoV1V1ModelInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)
 *
 * Parameters:
 *     litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)
 *
 *     - When litellm_model_id is passed, it will return the info for that specific model
 *     - When litellm_model_id is not passed, it will return the info for all models
 *
 * Returns:
 *     Returns a dictionary containing information about each model.
 *
 * Example Response:
 * ```json
 * {
 *     "data": [
 *                 {
 *                     "model_name": "fake-openai-endpoint",
 *                     "litellm_params": {
 *                         "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",
 *                         "model": "openai/fake"
 *                     },
 *                     "model_info": {
 *                         "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",
 *                         "db_model": false
 *                     }
 *                 }
 *             ]
 * }
 *
 * ```
 */
export const modelInfoV1V1ModelInfoGet = (variables: ModelInfoV1V1ModelInfoGetVariables, signal?: AbortSignal) =>
  fetch<
    ModelInfoV1V1ModelInfoGetResponse,
    ModelInfoV1V1ModelInfoGetError,
    undefined,
    {},
    ModelInfoV1V1ModelInfoGetQueryParams,
    {}
  >({ url: '/v1/model/info', method: 'get', ...variables, signal });

export type ModelInfoV1ModelInfoGetQueryParams = {
  litellm_model_id?: string | null;
};

export type ModelInfoV1ModelInfoGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ModelInfoV1ModelInfoGetResponse = {
  [key: string]: any;
};

export type ModelInfoV1ModelInfoGetVariables = {
  queryParams?: ModelInfoV1ModelInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)
 *
 * Parameters:
 *     litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)
 *
 *     - When litellm_model_id is passed, it will return the info for that specific model
 *     - When litellm_model_id is not passed, it will return the info for all models
 *
 * Returns:
 *     Returns a dictionary containing information about each model.
 *
 * Example Response:
 * ```json
 * {
 *     "data": [
 *                 {
 *                     "model_name": "fake-openai-endpoint",
 *                     "litellm_params": {
 *                         "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",
 *                         "model": "openai/fake"
 *                     },
 *                     "model_info": {
 *                         "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",
 *                         "db_model": false
 *                     }
 *                 }
 *             ]
 * }
 *
 * ```
 */
export const modelInfoV1ModelInfoGet = (variables: ModelInfoV1ModelInfoGetVariables, signal?: AbortSignal) =>
  fetch<
    ModelInfoV1ModelInfoGetResponse,
    ModelInfoV1ModelInfoGetError,
    undefined,
    {},
    ModelInfoV1ModelInfoGetQueryParams,
    {}
  >({ url: '/model/info', method: 'get', ...variables, signal });

export type ModelGroupInfoModelGroupInfoGetQueryParams = {
  model_group?: string | null;
};

export type ModelGroupInfoModelGroupInfoGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ModelGroupInfoModelGroupInfoGetResponse = {
  [key: string]: any;
};

export type ModelGroupInfoModelGroupInfoGetVariables = {
  queryParams?: ModelGroupInfoModelGroupInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Get information about all the deployments on litellm proxy, including config.yaml descriptions (except api key and api base)
 *
 * - /model_group/info returns all model groups. End users of proxy should use /model_group/info since those models will be used for /chat/completions, /embeddings, etc.
 * - /model_group/info?model_group=rerank-english-v3.0 returns all model groups for a specific model group (`model_name` in config.yaml)
 *
 *
 *
 * Example Request (All Models):
 * ```shell
 * curl -X 'GET'     'http://localhost:4000/model_group/info'     -H 'accept: application/json'     -H 'x-api-key: sk-1234'
 * ```
 *
 * Example Request (Specific Model Group):
 * ```shell
 * curl -X 'GET'     'http://localhost:4000/model_group/info?model_group=rerank-english-v3.0'     -H 'accept: application/json'     -H 'Authorization: Bearer sk-1234'
 * ```
 *
 * Example Request (Specific Wildcard Model Group): (e.g. `model_name: openai/*` on config.yaml)
 * ```shell
 * curl -X 'GET'     'http://localhost:4000/model_group/info?model_group=openai/tts-1'
 * -H 'accept: application/json'     -H 'Authorization: Bearersk-1234'
 * ```
 *
 * Learn how to use and set wildcard models [here](https://docs.litellm.ai/docs/wildcard_routing)
 *
 * Example Response:
 * ```json
 *     {
 *         "data": [
 *             {
 *             "model_group": "rerank-english-v3.0",
 *             "providers": [
 *                 "cohere"
 *             ],
 *             "max_input_tokens": null,
 *             "max_output_tokens": null,
 *             "input_cost_per_token": 0.0,
 *             "output_cost_per_token": 0.0,
 *             "mode": null,
 *             "tpm": null,
 *             "rpm": null,
 *             "supports_parallel_function_calling": false,
 *             "supports_vision": false,
 *             "supports_function_calling": false,
 *             "supported_openai_params": [
 *                 "stream",
 *                 "temperature",
 *                 "max_tokens",
 *                 "logit_bias",
 *                 "top_p",
 *                 "frequency_penalty",
 *                 "presence_penalty",
 *                 "stop",
 *                 "n",
 *                 "extra_headers"
 *             ]
 *             },
 *             {
 *             "model_group": "gpt-3.5-turbo",
 *             "providers": [
 *                 "openai"
 *             ],
 *             "max_input_tokens": 16385.0,
 *             "max_output_tokens": 4096.0,
 *             "input_cost_per_token": 1.5e-06,
 *             "output_cost_per_token": 2e-06,
 *             "mode": "chat",
 *             "tpm": null,
 *             "rpm": null,
 *             "supports_parallel_function_calling": false,
 *             "supports_vision": false,
 *             "supports_function_calling": true,
 *             "supported_openai_params": [
 *                 "frequency_penalty",
 *                 "logit_bias",
 *                 "logprobs",
 *                 "top_logprobs",
 *                 "max_tokens",
 *                 "max_completion_tokens",
 *                 "n",
 *                 "presence_penalty",
 *                 "seed",
 *                 "stop",
 *                 "stream",
 *                 "stream_options",
 *                 "temperature",
 *                 "top_p",
 *                 "tools",
 *                 "tool_choice",
 *                 "function_call",
 *                 "functions",
 *                 "max_retries",
 *                 "extra_headers",
 *                 "parallel_tool_calls",
 *                 "response_format"
 *             ]
 *             },
 *             {
 *             "model_group": "llava-hf",
 *             "providers": [
 *                 "openai"
 *             ],
 *             "max_input_tokens": null,
 *             "max_output_tokens": null,
 *             "input_cost_per_token": 0.0,
 *             "output_cost_per_token": 0.0,
 *             "mode": null,
 *             "tpm": null,
 *             "rpm": null,
 *             "supports_parallel_function_calling": false,
 *             "supports_vision": true,
 *             "supports_function_calling": false,
 *             "supported_openai_params": [
 *                 "frequency_penalty",
 *                 "logit_bias",
 *                 "logprobs",
 *                 "top_logprobs",
 *                 "max_tokens",
 *                 "max_completion_tokens",
 *                 "n",
 *                 "presence_penalty",
 *                 "seed",
 *                 "stop",
 *                 "stream",
 *                 "stream_options",
 *                 "temperature",
 *                 "top_p",
 *                 "tools",
 *                 "tool_choice",
 *                 "function_call",
 *                 "functions",
 *                 "max_retries",
 *                 "extra_headers",
 *                 "parallel_tool_calls",
 *                 "response_format"
 *             ]
 *             }
 *         ]
 *         }
 * ```
 */
export const modelGroupInfoModelGroupInfoGet = (
  variables: ModelGroupInfoModelGroupInfoGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    ModelGroupInfoModelGroupInfoGetResponse,
    ModelGroupInfoModelGroupInfoGetError,
    undefined,
    {},
    ModelGroupInfoModelGroupInfoGetQueryParams,
    {}
  >({ url: '/model_group/info', method: 'get', ...variables, signal });

export type HomeGetError = Fetcher.ErrorWrapper<undefined>;

export type HomeGetResponse = {
  [key: string]: any;
};

export type HomeGetVariables = FetcherExtraProps;

export const homeGet = (variables: HomeGetVariables, signal?: AbortSignal) =>
  fetch<HomeGetResponse, HomeGetError, undefined, {}, {}, {}>({ url: '/', method: 'get', ...variables, signal });

export type GetRoutesRoutesGetError = Fetcher.ErrorWrapper<undefined>;

export type GetRoutesRoutesGetResponse = {
  [key: string]: any;
};

export type GetRoutesRoutesGetVariables = FetcherExtraProps;

/**
 * Get a list of available routes in the FastAPI application.
 */
export const getRoutesRoutesGet = (variables: GetRoutesRoutesGetVariables, signal?: AbortSignal) =>
  fetch<GetRoutesRoutesGetResponse, GetRoutesRoutesGetError, undefined, {}, {}, {}>({
    url: '/routes',
    method: 'get',
    ...variables,
    signal
  });

export type ResponsesApiResponsesPostError = Fetcher.ErrorWrapper<undefined>;

export type ResponsesApiResponsesPostResponse = {
  [key: string]: any;
};

export type ResponsesApiResponsesPostVariables = FetcherExtraProps;

/**
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{
 *     "model": "gpt-4o",
 *     "input": "Tell me about AI"
 * }'
 * ```
 */
export const responsesApiResponsesPost = (variables: ResponsesApiResponsesPostVariables, signal?: AbortSignal) =>
  fetch<ResponsesApiResponsesPostResponse, ResponsesApiResponsesPostError, undefined, {}, {}, {}>({
    url: '/responses',
    method: 'post',
    ...variables,
    signal
  });

export type ResponsesApiV1ResponsesPostError = Fetcher.ErrorWrapper<undefined>;

export type ResponsesApiV1ResponsesPostResponse = {
  [key: string]: any;
};

export type ResponsesApiV1ResponsesPostVariables = FetcherExtraProps;

/**
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{
 *     "model": "gpt-4o",
 *     "input": "Tell me about AI"
 * }'
 * ```
 */
export const responsesApiV1ResponsesPost = (variables: ResponsesApiV1ResponsesPostVariables, signal?: AbortSignal) =>
  fetch<ResponsesApiV1ResponsesPostResponse, ResponsesApiV1ResponsesPostError, undefined, {}, {}, {}>({
    url: '/v1/responses',
    method: 'post',
    ...variables,
    signal
  });

export type GetResponseResponsesResponseIdGetPathParams = {
  responseId: string;
};

export type GetResponseResponsesResponseIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetResponseResponsesResponseIdGetResponse = {
  [key: string]: any;
};

export type GetResponseResponsesResponseIdGetVariables = {
  pathParams: GetResponseResponsesResponseIdGetPathParams;
} & FetcherExtraProps;

/**
 * Get a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseResponsesResponseIdGet = (
  variables: GetResponseResponsesResponseIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetResponseResponsesResponseIdGetResponse,
    GetResponseResponsesResponseIdGetError,
    undefined,
    {},
    {},
    GetResponseResponsesResponseIdGetPathParams
  >({ url: '/responses/{responseId}', method: 'get', ...variables, signal });

export type DeleteResponseResponsesResponseIdDeletePathParams = {
  responseId: string;
};

export type DeleteResponseResponsesResponseIdDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteResponseResponsesResponseIdDeleteResponse = {
  [key: string]: any;
};

export type DeleteResponseResponsesResponseIdDeleteVariables = {
  pathParams: DeleteResponseResponsesResponseIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete
 *
 * ```bash
 * curl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const deleteResponseResponsesResponseIdDelete = (
  variables: DeleteResponseResponsesResponseIdDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteResponseResponsesResponseIdDeleteResponse,
    DeleteResponseResponsesResponseIdDeleteError,
    undefined,
    {},
    {},
    DeleteResponseResponsesResponseIdDeletePathParams
  >({ url: '/responses/{responseId}', method: 'delete', ...variables, signal });

export type GetResponseV1ResponsesResponseIdGetPathParams = {
  responseId: string;
};

export type GetResponseV1ResponsesResponseIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetResponseV1ResponsesResponseIdGetResponse = {
  [key: string]: any;
};

export type GetResponseV1ResponsesResponseIdGetVariables = {
  pathParams: GetResponseV1ResponsesResponseIdGetPathParams;
} & FetcherExtraProps;

/**
 * Get a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseV1ResponsesResponseIdGet = (
  variables: GetResponseV1ResponsesResponseIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetResponseV1ResponsesResponseIdGetResponse,
    GetResponseV1ResponsesResponseIdGetError,
    undefined,
    {},
    {},
    GetResponseV1ResponsesResponseIdGetPathParams
  >({ url: '/v1/responses/{responseId}', method: 'get', ...variables, signal });

export type DeleteResponseV1ResponsesResponseIdDeletePathParams = {
  responseId: string;
};

export type DeleteResponseV1ResponsesResponseIdDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteResponseV1ResponsesResponseIdDeleteResponse = {
  [key: string]: any;
};

export type DeleteResponseV1ResponsesResponseIdDeleteVariables = {
  pathParams: DeleteResponseV1ResponsesResponseIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Delete a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete
 *
 * ```bash
 * curl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const deleteResponseV1ResponsesResponseIdDelete = (
  variables: DeleteResponseV1ResponsesResponseIdDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteResponseV1ResponsesResponseIdDeleteResponse,
    DeleteResponseV1ResponsesResponseIdDeleteError,
    undefined,
    {},
    {},
    DeleteResponseV1ResponsesResponseIdDeletePathParams
  >({ url: '/v1/responses/{responseId}', method: 'delete', ...variables, signal });

export type GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams = {
  responseId: string;
};

export type GetResponseInputItemsResponsesResponseIdInputItemsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetResponseInputItemsResponsesResponseIdInputItemsGetResponse = {
  [key: string]: any;
};

export type GetResponseInputItemsResponsesResponseIdInputItemsGetVariables = {
  pathParams: GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams;
} & FetcherExtraProps;

/**
 * Get input items for a response.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/input-items
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123/input_items     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseInputItemsResponsesResponseIdInputItemsGet = (
  variables: GetResponseInputItemsResponsesResponseIdInputItemsGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetResponseInputItemsResponsesResponseIdInputItemsGetResponse,
    GetResponseInputItemsResponsesResponseIdInputItemsGetError,
    undefined,
    {},
    {},
    GetResponseInputItemsResponsesResponseIdInputItemsGetPathParams
  >({ url: '/responses/{responseId}/input_items', method: 'get', ...variables, signal });

export type GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams = {
  responseId: string;
};

export type GetResponseInputItemsV1ResponsesResponseIdInputItemsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetResponseInputItemsV1ResponsesResponseIdInputItemsGetResponse = {
  [key: string]: any;
};

export type GetResponseInputItemsV1ResponsesResponseIdInputItemsGetVariables = {
  pathParams: GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams;
} & FetcherExtraProps;

/**
 * Get input items for a response.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/input-items
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123/input_items     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseInputItemsV1ResponsesResponseIdInputItemsGet = (
  variables: GetResponseInputItemsV1ResponsesResponseIdInputItemsGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetResponseInputItemsV1ResponsesResponseIdInputItemsGetResponse,
    GetResponseInputItemsV1ResponsesResponseIdInputItemsGetError,
    undefined,
    {},
    {},
    GetResponseInputItemsV1ResponsesResponseIdInputItemsGetPathParams
  >({ url: '/v1/responses/{responseId}/input_items', method: 'get', ...variables, signal });

export type CreateBatchBatchesPostQueryParams = {
  provider?: string | null;
};

export type CreateBatchBatchesPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreateBatchBatchesPostResponse = {
  [key: string]: any;
};

export type CreateBatchBatchesPostVariables = {
  queryParams?: CreateBatchBatchesPostQueryParams;
} & FetcherExtraProps;

/**
 * Create large batches of API requests for asynchronous processing.
 * This is the equivalent of POST https://api.openai.com/v1/batch
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "input_file_id": "file-abc123",
 *         "endpoint": "/v1/chat/completions",
 *         "completion_window": "24h"
 * }'
 * ```
 */
export const createBatchBatchesPost = (variables: CreateBatchBatchesPostVariables, signal?: AbortSignal) =>
  fetch<
    CreateBatchBatchesPostResponse,
    CreateBatchBatchesPostError,
    undefined,
    {},
    CreateBatchBatchesPostQueryParams,
    {}
  >({ url: '/batches', method: 'post', ...variables, signal });

export type ListBatchesBatchesGetQueryParams = {
  provider?: string | null;
  limit?: number | null;
  after?: string | null;
};

export type ListBatchesBatchesGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListBatchesBatchesGetResponse = {
  [key: string]: any;
};

export type ListBatchesBatchesGetVariables = {
  queryParams?: ListBatchesBatchesGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists
 * This is the equivalent of GET https://api.openai.com/v1/batches/
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const listBatchesBatchesGet = (variables: ListBatchesBatchesGetVariables, signal?: AbortSignal) =>
  fetch<ListBatchesBatchesGetResponse, ListBatchesBatchesGetError, undefined, {}, ListBatchesBatchesGetQueryParams, {}>(
    { url: '/batches', method: 'get', ...variables, signal }
  );

export type CreateBatchV1BatchesPostQueryParams = {
  provider?: string | null;
};

export type CreateBatchV1BatchesPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreateBatchV1BatchesPostResponse = {
  [key: string]: any;
};

export type CreateBatchV1BatchesPostVariables = {
  queryParams?: CreateBatchV1BatchesPostQueryParams;
} & FetcherExtraProps;

/**
 * Create large batches of API requests for asynchronous processing.
 * This is the equivalent of POST https://api.openai.com/v1/batch
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "input_file_id": "file-abc123",
 *         "endpoint": "/v1/chat/completions",
 *         "completion_window": "24h"
 * }'
 * ```
 */
export const createBatchV1BatchesPost = (variables: CreateBatchV1BatchesPostVariables, signal?: AbortSignal) =>
  fetch<
    CreateBatchV1BatchesPostResponse,
    CreateBatchV1BatchesPostError,
    undefined,
    {},
    CreateBatchV1BatchesPostQueryParams,
    {}
  >({ url: '/v1/batches', method: 'post', ...variables, signal });

export type ListBatchesV1BatchesGetQueryParams = {
  provider?: string | null;
  limit?: number | null;
  after?: string | null;
};

export type ListBatchesV1BatchesGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListBatchesV1BatchesGetResponse = {
  [key: string]: any;
};

export type ListBatchesV1BatchesGetVariables = {
  queryParams?: ListBatchesV1BatchesGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists
 * This is the equivalent of GET https://api.openai.com/v1/batches/
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const listBatchesV1BatchesGet = (variables: ListBatchesV1BatchesGetVariables, signal?: AbortSignal) =>
  fetch<
    ListBatchesV1BatchesGetResponse,
    ListBatchesV1BatchesGetError,
    undefined,
    {},
    ListBatchesV1BatchesGetQueryParams,
    {}
  >({ url: '/v1/batches', method: 'get', ...variables, signal });

export type CreateBatchProviderV1BatchesPostPathParams = {
  provider: string | null;
};

export type CreateBatchProviderV1BatchesPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreateBatchProviderV1BatchesPostResponse = {
  [key: string]: any;
};

export type CreateBatchProviderV1BatchesPostVariables = {
  pathParams: CreateBatchProviderV1BatchesPostPathParams;
} & FetcherExtraProps;

/**
 * Create large batches of API requests for asynchronous processing.
 * This is the equivalent of POST https://api.openai.com/v1/batch
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 *         "input_file_id": "file-abc123",
 *         "endpoint": "/v1/chat/completions",
 *         "completion_window": "24h"
 * }'
 * ```
 */
export const createBatchProviderV1BatchesPost = (
  variables: CreateBatchProviderV1BatchesPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CreateBatchProviderV1BatchesPostResponse,
    CreateBatchProviderV1BatchesPostError,
    undefined,
    {},
    {},
    CreateBatchProviderV1BatchesPostPathParams
  >({ url: '/{provider}/v1/batches', method: 'post', ...variables, signal });

export type ListBatchesProviderV1BatchesGetPathParams = {
  provider: string | null;
};

export type ListBatchesProviderV1BatchesGetQueryParams = {
  limit?: number | null;
  after?: string | null;
};

export type ListBatchesProviderV1BatchesGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListBatchesProviderV1BatchesGetResponse = {
  [key: string]: any;
};

export type ListBatchesProviderV1BatchesGetVariables = {
  pathParams: ListBatchesProviderV1BatchesGetPathParams;
  queryParams?: ListBatchesProviderV1BatchesGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists
 * This is the equivalent of GET https://api.openai.com/v1/batches/
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const listBatchesProviderV1BatchesGet = (
  variables: ListBatchesProviderV1BatchesGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    ListBatchesProviderV1BatchesGetResponse,
    ListBatchesProviderV1BatchesGetError,
    undefined,
    {},
    ListBatchesProviderV1BatchesGetQueryParams,
    ListBatchesProviderV1BatchesGetPathParams
  >({ url: '/{provider}/v1/batches', method: 'get', ...variables, signal });

export type RetrieveBatchBatchesBatchIdGetPathParams = {
  /**
   * The ID of the batch to retrieve
   */
  batchId: string;
};

export type RetrieveBatchBatchesBatchIdGetQueryParams = {
  provider?: string | null;
};

export type RetrieveBatchBatchesBatchIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type RetrieveBatchBatchesBatchIdGetResponse = {
  [key: string]: any;
};

export type RetrieveBatchBatchesBatchIdGetVariables = {
  pathParams: RetrieveBatchBatchesBatchIdGetPathParams;
  queryParams?: RetrieveBatchBatchesBatchIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieves a batch.
 * This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const retrieveBatchBatchesBatchIdGet = (
  variables: RetrieveBatchBatchesBatchIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    RetrieveBatchBatchesBatchIdGetResponse,
    RetrieveBatchBatchesBatchIdGetError,
    undefined,
    {},
    RetrieveBatchBatchesBatchIdGetQueryParams,
    RetrieveBatchBatchesBatchIdGetPathParams
  >({ url: '/batches/{batchId}', method: 'get', ...variables, signal });

export type RetrieveBatchV1BatchesBatchIdGetPathParams = {
  /**
   * The ID of the batch to retrieve
   */
  batchId: string;
};

export type RetrieveBatchV1BatchesBatchIdGetQueryParams = {
  provider?: string | null;
};

export type RetrieveBatchV1BatchesBatchIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type RetrieveBatchV1BatchesBatchIdGetResponse = {
  [key: string]: any;
};

export type RetrieveBatchV1BatchesBatchIdGetVariables = {
  pathParams: RetrieveBatchV1BatchesBatchIdGetPathParams;
  queryParams?: RetrieveBatchV1BatchesBatchIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieves a batch.
 * This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const retrieveBatchV1BatchesBatchIdGet = (
  variables: RetrieveBatchV1BatchesBatchIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    RetrieveBatchV1BatchesBatchIdGetResponse,
    RetrieveBatchV1BatchesBatchIdGetError,
    undefined,
    {},
    RetrieveBatchV1BatchesBatchIdGetQueryParams,
    RetrieveBatchV1BatchesBatchIdGetPathParams
  >({ url: '/v1/batches/{batchId}', method: 'get', ...variables, signal });

export type RetrieveBatchProviderV1BatchesBatchIdGetPathParams = {
  provider: string | null;
  /**
   * The ID of the batch to retrieve
   */
  batchId: string;
};

export type RetrieveBatchProviderV1BatchesBatchIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type RetrieveBatchProviderV1BatchesBatchIdGetResponse = {
  [key: string]: any;
};

export type RetrieveBatchProviderV1BatchesBatchIdGetVariables = {
  pathParams: RetrieveBatchProviderV1BatchesBatchIdGetPathParams;
} & FetcherExtraProps;

/**
 * Retrieves a batch.
 * This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const retrieveBatchProviderV1BatchesBatchIdGet = (
  variables: RetrieveBatchProviderV1BatchesBatchIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    RetrieveBatchProviderV1BatchesBatchIdGetResponse,
    RetrieveBatchProviderV1BatchesBatchIdGetError,
    undefined,
    {},
    {},
    RetrieveBatchProviderV1BatchesBatchIdGetPathParams
  >({ url: '/{provider}/v1/batches/{batchId}', method: 'get', ...variables, signal });

export type CancelBatchBatchesBatchIdCancelPostPathParams = {
  batchId: string;
};

export type CancelBatchBatchesBatchIdCancelPostQueryParams = {
  provider?: string | null;
};

export type CancelBatchBatchesBatchIdCancelPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CancelBatchBatchesBatchIdCancelPostResponse = {
  [key: string]: any;
};

export type CancelBatchBatchesBatchIdCancelPostVariables = {
  pathParams: CancelBatchBatchesBatchIdCancelPostPathParams;
  queryParams?: CancelBatchBatchesBatchIdCancelPostQueryParams;
} & FetcherExtraProps;

/**
 * Cancel a batch.
 * This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST
 *
 * ```
 */
export const cancelBatchBatchesBatchIdCancelPost = (
  variables: CancelBatchBatchesBatchIdCancelPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CancelBatchBatchesBatchIdCancelPostResponse,
    CancelBatchBatchesBatchIdCancelPostError,
    undefined,
    {},
    CancelBatchBatchesBatchIdCancelPostQueryParams,
    CancelBatchBatchesBatchIdCancelPostPathParams
  >({ url: '/batches/{batchId}/cancel', method: 'post', ...variables, signal });

export type CancelBatchV1BatchesBatchIdCancelPostPathParams = {
  batchId: string;
};

export type CancelBatchV1BatchesBatchIdCancelPostQueryParams = {
  provider?: string | null;
};

export type CancelBatchV1BatchesBatchIdCancelPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CancelBatchV1BatchesBatchIdCancelPostResponse = {
  [key: string]: any;
};

export type CancelBatchV1BatchesBatchIdCancelPostVariables = {
  pathParams: CancelBatchV1BatchesBatchIdCancelPostPathParams;
  queryParams?: CancelBatchV1BatchesBatchIdCancelPostQueryParams;
} & FetcherExtraProps;

/**
 * Cancel a batch.
 * This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST
 *
 * ```
 */
export const cancelBatchV1BatchesBatchIdCancelPost = (
  variables: CancelBatchV1BatchesBatchIdCancelPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CancelBatchV1BatchesBatchIdCancelPostResponse,
    CancelBatchV1BatchesBatchIdCancelPostError,
    undefined,
    {},
    CancelBatchV1BatchesBatchIdCancelPostQueryParams,
    CancelBatchV1BatchesBatchIdCancelPostPathParams
  >({ url: '/v1/batches/{batchId}/cancel', method: 'post', ...variables, signal });

export type CancelBatchProviderV1BatchesBatchIdCancelPostPathParams = {
  batchId: string;
  provider: string | null;
};

export type CancelBatchProviderV1BatchesBatchIdCancelPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CancelBatchProviderV1BatchesBatchIdCancelPostResponse = {
  [key: string]: any;
};

export type CancelBatchProviderV1BatchesBatchIdCancelPostVariables = {
  pathParams: CancelBatchProviderV1BatchesBatchIdCancelPostPathParams;
} & FetcherExtraProps;

/**
 * Cancel a batch.
 * This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST
 *
 * ```
 */
export const cancelBatchProviderV1BatchesBatchIdCancelPost = (
  variables: CancelBatchProviderV1BatchesBatchIdCancelPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CancelBatchProviderV1BatchesBatchIdCancelPostResponse,
    CancelBatchProviderV1BatchesBatchIdCancelPostError,
    undefined,
    {},
    {},
    CancelBatchProviderV1BatchesBatchIdCancelPostPathParams
  >({ url: '/{provider}/v1/batches/{batchId}/cancel', method: 'post', ...variables, signal });

export type RerankRerankPostError = Fetcher.ErrorWrapper<undefined>;

export type RerankRerankPostResponse = {
  [key: string]: any;
};

export type RerankRerankPostVariables = FetcherExtraProps;

export const rerankRerankPost = (variables: RerankRerankPostVariables, signal?: AbortSignal) =>
  fetch<RerankRerankPostResponse, RerankRerankPostError, undefined, {}, {}, {}>({
    url: '/rerank',
    method: 'post',
    ...variables,
    signal
  });

export type RerankV1RerankPostError = Fetcher.ErrorWrapper<undefined>;

export type RerankV1RerankPostResponse = {
  [key: string]: any;
};

export type RerankV1RerankPostVariables = FetcherExtraProps;

export const rerankV1RerankPost = (variables: RerankV1RerankPostVariables, signal?: AbortSignal) =>
  fetch<RerankV1RerankPostResponse, RerankV1RerankPostError, undefined, {}, {}, {}>({
    url: '/v1/rerank',
    method: 'post',
    ...variables,
    signal
  });

export type RerankV2RerankPostError = Fetcher.ErrorWrapper<undefined>;

export type RerankV2RerankPostResponse = {
  [key: string]: any;
};

export type RerankV2RerankPostVariables = FetcherExtraProps;

export const rerankV2RerankPost = (variables: RerankV2RerankPostVariables, signal?: AbortSignal) =>
  fetch<RerankV2RerankPostResponse, RerankV2RerankPostError, undefined, {}, {}, {}>({
    url: '/v2/rerank',
    method: 'post',
    ...variables,
    signal
  });

export type CreateFineTuningJobFineTuningJobsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreateFineTuningJobFineTuningJobsPostResponse = {
  [key: string]: any;
};

export type CreateFineTuningJobFineTuningJobsPostVariables = {
  body: Schemas.LiteLLMFineTuningJobCreate;
} & FetcherExtraProps;

/**
 * Creates a fine-tuning job which begins the process of creating a new model from a given dataset.
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/create
 *
 * Example Curl:
 * ```
 * curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{
 *     "model": "gpt-3.5-turbo",
 *     "training_file": "file-abc123",
 *     "hyperparameters": {
 *       "n_epochs": 4
 *     }
 *   }'
 * ```
 */
export const createFineTuningJobFineTuningJobsPost = (
  variables: CreateFineTuningJobFineTuningJobsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CreateFineTuningJobFineTuningJobsPostResponse,
    CreateFineTuningJobFineTuningJobsPostError,
    Schemas.LiteLLMFineTuningJobCreate,
    {},
    {},
    {}
  >({ url: '/fine_tuning/jobs', method: 'post', ...variables, signal });

export type ListFineTuningJobsFineTuningJobsGetQueryParams = {
  custom_llm_provider: 'openai' | 'azure';
  after?: string | null;
  limit?: number | null;
};

export type ListFineTuningJobsFineTuningJobsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListFineTuningJobsFineTuningJobsGetResponse = {
  [key: string]: any;
};

export type ListFineTuningJobsFineTuningJobsGetVariables = {
  queryParams: ListFineTuningJobsFineTuningJobsGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists fine-tuning jobs for the organization.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `after`: Identifier for the last job from the previous pagination request.
 * - `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 */
export const listFineTuningJobsFineTuningJobsGet = (
  variables: ListFineTuningJobsFineTuningJobsGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    ListFineTuningJobsFineTuningJobsGetResponse,
    ListFineTuningJobsFineTuningJobsGetError,
    undefined,
    {},
    ListFineTuningJobsFineTuningJobsGetQueryParams,
    {}
  >({ url: '/fine_tuning/jobs', method: 'get', ...variables, signal });

export type CreateFineTuningJobV1FineTuningJobsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreateFineTuningJobV1FineTuningJobsPostResponse = {
  [key: string]: any;
};

export type CreateFineTuningJobV1FineTuningJobsPostVariables = {
  body: Schemas.LiteLLMFineTuningJobCreate;
} & FetcherExtraProps;

/**
 * Creates a fine-tuning job which begins the process of creating a new model from a given dataset.
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/create
 *
 * Example Curl:
 * ```
 * curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{
 *     "model": "gpt-3.5-turbo",
 *     "training_file": "file-abc123",
 *     "hyperparameters": {
 *       "n_epochs": 4
 *     }
 *   }'
 * ```
 */
export const createFineTuningJobV1FineTuningJobsPost = (
  variables: CreateFineTuningJobV1FineTuningJobsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CreateFineTuningJobV1FineTuningJobsPostResponse,
    CreateFineTuningJobV1FineTuningJobsPostError,
    Schemas.LiteLLMFineTuningJobCreate,
    {},
    {},
    {}
  >({ url: '/v1/fine_tuning/jobs', method: 'post', ...variables, signal });

export type ListFineTuningJobsV1FineTuningJobsGetQueryParams = {
  custom_llm_provider: 'openai' | 'azure';
  after?: string | null;
  limit?: number | null;
};

export type ListFineTuningJobsV1FineTuningJobsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListFineTuningJobsV1FineTuningJobsGetResponse = {
  [key: string]: any;
};

export type ListFineTuningJobsV1FineTuningJobsGetVariables = {
  queryParams: ListFineTuningJobsV1FineTuningJobsGetQueryParams;
} & FetcherExtraProps;

/**
 * Lists fine-tuning jobs for the organization.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `after`: Identifier for the last job from the previous pagination request.
 * - `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 */
export const listFineTuningJobsV1FineTuningJobsGet = (
  variables: ListFineTuningJobsV1FineTuningJobsGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    ListFineTuningJobsV1FineTuningJobsGetResponse,
    ListFineTuningJobsV1FineTuningJobsGetError,
    undefined,
    {},
    ListFineTuningJobsV1FineTuningJobsGetQueryParams,
    {}
  >({ url: '/v1/fine_tuning/jobs', method: 'get', ...variables, signal });

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams = {
  fineTuningJobId: string;
};

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams = {
  custom_llm_provider: 'openai' | 'azure';
};

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetResponse = {
  [key: string]: any;
};

export type RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetVariables = {
  pathParams: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams;
  queryParams: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieves a fine-tuning job.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 */
export const retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet = (
  variables: RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetResponse,
    RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetError,
    undefined,
    {},
    RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetQueryParams,
    RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetPathParams
  >({ url: '/fine_tuning/jobs/{fineTuningJobId}', method: 'get', ...variables, signal });

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams = {
  fineTuningJobId: string;
};

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams = {
  custom_llm_provider: 'openai' | 'azure';
};

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetResponse = {
  [key: string]: any;
};

export type RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetVariables = {
  pathParams: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams;
  queryParams: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieves a fine-tuning job.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 */
export const retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet = (
  variables: RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetResponse,
    RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetError,
    undefined,
    {},
    RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetQueryParams,
    RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetPathParams
  >({ url: '/v1/fine_tuning/jobs/{fineTuningJobId}', method: 'get', ...variables, signal });

export type CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams = {
  fineTuningJobId: string;
};

export type CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostResponse = {
  [key: string]: any;
};

export type CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostVariables = {
  pathParams: CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams;
} & FetcherExtraProps;

/**
 * Cancel a fine-tuning job.
 *
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 */
export const cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost = (
  variables: CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostResponse,
    CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostError,
    undefined,
    {},
    {},
    CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostPathParams
  >({ url: '/fine_tuning/jobs/{fineTuningJobId}/cancel', method: 'post', ...variables, signal });

export type CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams = {
  fineTuningJobId: string;
};

export type CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostResponse = {
  [key: string]: any;
};

export type CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostVariables = {
  pathParams: CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams;
} & FetcherExtraProps;

/**
 * Cancel a fine-tuning job.
 *
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 */
export const cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost = (
  variables: CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostResponse,
    CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostError,
    undefined,
    {},
    {},
    CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostPathParams
  >({ url: '/v1/fine_tuning/jobs/{fineTuningJobId}/cancel', method: 'post', ...variables, signal });

export type GetCredentialsCredentialsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetCredentialsCredentialsGetResponse = {
  [key: string]: any;
};

export type GetCredentialsCredentialsGetVariables = FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const getCredentialsCredentialsGet = (variables: GetCredentialsCredentialsGetVariables, signal?: AbortSignal) =>
  fetch<GetCredentialsCredentialsGetResponse, GetCredentialsCredentialsGetError, undefined, {}, {}, {}>({
    url: '/credentials',
    method: 'get',
    ...variables,
    signal
  });

export type CreateCredentialCredentialsPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreateCredentialCredentialsPostResponse = {
  [key: string]: any;
};

export type CreateCredentialCredentialsPostVariables = {
  body: Schemas.CreateCredentialItem;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 * Stores credential in DB.
 * Reloads credentials in memory.
 */
export const createCredentialCredentialsPost = (
  variables: CreateCredentialCredentialsPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CreateCredentialCredentialsPostResponse,
    CreateCredentialCredentialsPostError,
    Schemas.CreateCredentialItem,
    {},
    {},
    {}
  >({ url: '/credentials', method: 'post', ...variables, signal });

export type GetCredentialCredentialsByModelModelIdGetPathParams = {
  modelId: string | null;
};

export type GetCredentialCredentialsByModelModelIdGetQueryParams = {
  credential_name?: string | null;
};

export type GetCredentialCredentialsByModelModelIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetCredentialCredentialsByModelModelIdGetVariables = {
  pathParams: GetCredentialCredentialsByModelModelIdGetPathParams;
  queryParams?: GetCredentialCredentialsByModelModelIdGetQueryParams;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const getCredentialCredentialsByModelModelIdGet = (
  variables: GetCredentialCredentialsByModelModelIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.CredentialItem,
    GetCredentialCredentialsByModelModelIdGetError,
    undefined,
    {},
    GetCredentialCredentialsByModelModelIdGetQueryParams,
    GetCredentialCredentialsByModelModelIdGetPathParams
  >({ url: '/credentials/by_model/{modelId}', method: 'get', ...variables, signal });

export type GetCredentialCredentialsByNameCredentialNameGetPathParams = {
  credentialName: string | null;
};

export type GetCredentialCredentialsByNameCredentialNameGetQueryParams = {
  model_id?: string | null;
};

export type GetCredentialCredentialsByNameCredentialNameGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetCredentialCredentialsByNameCredentialNameGetVariables = {
  pathParams: GetCredentialCredentialsByNameCredentialNameGetPathParams;
  queryParams?: GetCredentialCredentialsByNameCredentialNameGetQueryParams;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const getCredentialCredentialsByNameCredentialNameGet = (
  variables: GetCredentialCredentialsByNameCredentialNameGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.CredentialItem,
    GetCredentialCredentialsByNameCredentialNameGetError,
    undefined,
    {},
    GetCredentialCredentialsByNameCredentialNameGetQueryParams,
    GetCredentialCredentialsByNameCredentialNameGetPathParams
  >({ url: '/credentials/by_name/{credentialName}', method: 'get', ...variables, signal });

export type DeleteCredentialCredentialsCredentialNameDeletePathParams = {
  credentialName: string;
};

export type DeleteCredentialCredentialsCredentialNameDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteCredentialCredentialsCredentialNameDeleteResponse = {
  [key: string]: any;
};

export type DeleteCredentialCredentialsCredentialNameDeleteVariables = {
  pathParams: DeleteCredentialCredentialsCredentialNameDeletePathParams;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const deleteCredentialCredentialsCredentialNameDelete = (
  variables: DeleteCredentialCredentialsCredentialNameDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteCredentialCredentialsCredentialNameDeleteResponse,
    DeleteCredentialCredentialsCredentialNameDeleteError,
    undefined,
    {},
    {},
    DeleteCredentialCredentialsCredentialNameDeletePathParams
  >({ url: '/credentials/{credentialName}', method: 'delete', ...variables, signal });

export type UpdateCredentialCredentialsCredentialNamePatchPathParams = {
  credentialName: string;
};

export type UpdateCredentialCredentialsCredentialNamePatchError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UpdateCredentialCredentialsCredentialNamePatchVariables = {
  body: Schemas.CredentialItem;
  pathParams: UpdateCredentialCredentialsCredentialNamePatchPathParams;
} & FetcherExtraProps;

/**
 * [BETA] endpoint. This might change unexpectedly.
 */
export const updateCredentialCredentialsCredentialNamePatch = (
  variables: UpdateCredentialCredentialsCredentialNamePatchVariables,
  signal?: AbortSignal
) =>
  fetch<
    void,
    UpdateCredentialCredentialsCredentialNamePatchError,
    Schemas.CredentialItem,
    {},
    {},
    UpdateCredentialCredentialsCredentialNamePatchPathParams
  >({ url: '/credentials/{credentialName}', method: 'patch', ...variables, signal });

export type HandleSseMcpGetError = Fetcher.ErrorWrapper<undefined>;

export type HandleSseMcpGetVariables = FetcherExtraProps;

export const handleSseMcpGet = (variables: HandleSseMcpGetVariables, signal?: AbortSignal) =>
  fetch<undefined, HandleSseMcpGetError, undefined, {}, {}, {}>({ url: '/mcp/', method: 'get', ...variables, signal });

export type HandleMessagesMcpSseMessagesPostError = Fetcher.ErrorWrapper<undefined>;

export type HandleMessagesMcpSseMessagesPostResponse = {
  [key: string]: any;
};

export type HandleMessagesMcpSseMessagesPostVariables = FetcherExtraProps;

export const handleMessagesMcpSseMessagesPost = (
  variables: HandleMessagesMcpSseMessagesPostVariables,
  signal?: AbortSignal
) =>
  fetch<HandleMessagesMcpSseMessagesPostResponse, HandleMessagesMcpSseMessagesPostError, undefined, {}, {}, {}>({
    url: '/mcp/sse/messages',
    method: 'post',
    ...variables,
    signal
  });

export type ListToolRestApiMcpToolsListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListToolRestApiMcpToolsListGetResponse = Schemas.ListMCPToolsRestAPIResponseObject[];

export type ListToolRestApiMcpToolsListGetVariables = FetcherExtraProps;

/**
 * List all available tools with information about the server they belong to.
 *
 * Example response:
 * Tools:
 * [
 *     {
 *         "name": "create_zap",
 *         "description": "Create a new zap",
 *         "inputSchema": "tool_input_schema",
 *         "mcp_info": {
 *             "server_name": "zapier",
 *             "logo_url": "https://www.zapier.com/logo.png",
 *         }
 *     },
 *     {
 *         "name": "fetch_data",
 *         "description": "Fetch data from a URL",
 *         "inputSchema": "tool_input_schema",
 *         "mcp_info": {
 *             "server_name": "fetch",
 *             "logo_url": "https://www.fetch.com/logo.png",
 *         }
 *     }
 * ]
 */
export const listToolRestApiMcpToolsListGet = (
  variables: ListToolRestApiMcpToolsListGetVariables,
  signal?: AbortSignal
) =>
  fetch<ListToolRestApiMcpToolsListGetResponse, ListToolRestApiMcpToolsListGetError, undefined, {}, {}, {}>({
    url: '/mcp/tools/list',
    method: 'get',
    ...variables,
    signal
  });

export type CallToolRestApiMcpToolsCallPostError = Fetcher.ErrorWrapper<undefined>;

export type CallToolRestApiMcpToolsCallPostResponse = {
  [key: string]: any;
};

export type CallToolRestApiMcpToolsCallPostVariables = FetcherExtraProps;

/**
 * REST API to call a specific MCP tool with the provided arguments
 */
export const callToolRestApiMcpToolsCallPost = (
  variables: CallToolRestApiMcpToolsCallPostVariables,
  signal?: AbortSignal
) =>
  fetch<CallToolRestApiMcpToolsCallPostResponse, CallToolRestApiMcpToolsCallPostError, undefined, {}, {}, {}>({
    url: '/mcp/tools/call',
    method: 'post',
    ...variables,
    signal
  });

export type GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams = {
  endpoint_id?: string | null;
};

export type GetPassThroughEndpointsConfigPassThroughEndpointGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetPassThroughEndpointsConfigPassThroughEndpointGetVariables = {
  queryParams?: GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams;
} & FetcherExtraProps;

/**
 * GET configured pass through endpoint.
 *
 * If no endpoint_id given, return all configured endpoints.
 */
export const getPassThroughEndpointsConfigPassThroughEndpointGet = (
  variables: GetPassThroughEndpointsConfigPassThroughEndpointGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.PassThroughEndpointResponse,
    GetPassThroughEndpointsConfigPassThroughEndpointGetError,
    undefined,
    {},
    GetPassThroughEndpointsConfigPassThroughEndpointGetQueryParams,
    {}
  >({ url: '/config/pass_through_endpoint', method: 'get', ...variables, signal });

export type CreatePassThroughEndpointsConfigPassThroughEndpointPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreatePassThroughEndpointsConfigPassThroughEndpointPostResponse = {
  [key: string]: any;
};

export type CreatePassThroughEndpointsConfigPassThroughEndpointPostVariables = {
  body: Schemas.PassThroughGenericEndpoint;
} & FetcherExtraProps;

/**
 * Create new pass-through endpoint
 */
export const createPassThroughEndpointsConfigPassThroughEndpointPost = (
  variables: CreatePassThroughEndpointsConfigPassThroughEndpointPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CreatePassThroughEndpointsConfigPassThroughEndpointPostResponse,
    CreatePassThroughEndpointsConfigPassThroughEndpointPostError,
    Schemas.PassThroughGenericEndpoint,
    {},
    {},
    {}
  >({ url: '/config/pass_through_endpoint', method: 'post', ...variables, signal });

export type DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams = {
  endpoint_id: string;
};

export type DeletePassThroughEndpointsConfigPassThroughEndpointDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeletePassThroughEndpointsConfigPassThroughEndpointDeleteVariables = {
  queryParams: DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams;
} & FetcherExtraProps;

/**
 * Delete a pass-through endpoint
 *
 * Returns - the deleted endpoint
 */
export const deletePassThroughEndpointsConfigPassThroughEndpointDelete = (
  variables: DeletePassThroughEndpointsConfigPassThroughEndpointDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.PassThroughEndpointResponse,
    DeletePassThroughEndpointsConfigPassThroughEndpointDeleteError,
    undefined,
    {},
    DeletePassThroughEndpointsConfigPassThroughEndpointDeleteQueryParams,
    {}
  >({ url: '/config/pass_through_endpoint', method: 'delete', ...variables, signal });

export type UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams = {
  endpointId: string;
};

export type UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostResponse = {
  [key: string]: any;
};

export type UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostVariables = {
  pathParams: UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams;
} & FetcherExtraProps;

/**
 * Update a pass-through endpoint
 */
export const updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost = (
  variables: UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostResponse,
    UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostError,
    undefined,
    {},
    {},
    UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostPathParams
  >({ url: '/config/pass_through_endpoint/{endpointId}', method: 'post', ...variables, signal });

export type TestEndpointTestGetError = Fetcher.ErrorWrapper<undefined>;

export type TestEndpointTestGetResponse = {
  [key: string]: any;
};

export type TestEndpointTestGetVariables = FetcherExtraProps;

/**
 * [DEPRECATED] use `/health/liveliness` instead.
 *
 * A test endpoint that pings the proxy server to check if it's healthy.
 *
 * Parameters:
 *     request (Request): The incoming request.
 *
 * Returns:
 *     dict: A dictionary containing the route of the request URL.
 */
export const testEndpointTestGet = (variables: TestEndpointTestGetVariables, signal?: AbortSignal) =>
  fetch<TestEndpointTestGetResponse, TestEndpointTestGetError, undefined, {}, {}, {}>({
    url: '/test',
    method: 'get',
    ...variables,
    signal
  });

export type HealthServicesEndpointHealthServicesGetQueryParams = {
  /**
   * Specify the service being hit.
   */
  service:
    | ('slack_budget_alerts' | 'langfuse' | 'slack' | 'openmeter' | 'webhook' | 'email' | 'braintrust' | 'datadog')
    | string;
};

export type HealthServicesEndpointHealthServicesGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type HealthServicesEndpointHealthServicesGetResponse = {
  [key: string]: any;
};

export type HealthServicesEndpointHealthServicesGetVariables = {
  queryParams: HealthServicesEndpointHealthServicesGetQueryParams;
} & FetcherExtraProps;

/**
 * Use this admin-only endpoint to check if the service is healthy.
 *
 * Example:
 * ```
 * curl -L -X GET 'http://0.0.0.0:4000/health/services?service=datadog'     -H 'Authorization: Bearer sk-1234'
 * ```
 */
export const healthServicesEndpointHealthServicesGet = (
  variables: HealthServicesEndpointHealthServicesGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    HealthServicesEndpointHealthServicesGetResponse,
    HealthServicesEndpointHealthServicesGetError,
    undefined,
    {},
    HealthServicesEndpointHealthServicesGetQueryParams,
    {}
  >({ url: '/health/services', method: 'get', ...variables, signal });

export type HealthEndpointHealthGetQueryParams = {
  /**
   * Specify the model name (optional)
   */
  model?: string | null;
};

export type HealthEndpointHealthGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type HealthEndpointHealthGetResponse = {
  [key: string]: any;
};

export type HealthEndpointHealthGetVariables = {
  queryParams?: HealthEndpointHealthGetQueryParams;
} & FetcherExtraProps;

/**
 *  USE `/health/liveliness` to health check the proxy 
 *
 * See more  https://docs.litellm.ai/docs/proxy/health
 *
 *
 * Check the health of all the endpoints in config.yaml
 *
 * To run health checks in the background, add this to config.yaml:
 * ```
 * general_settings:
 *     # ... other settings
 *     background_health_checks: True
 * ```
 * else, the health checks will be run on models when /health is called.
 */
export const healthEndpointHealthGet = (variables: HealthEndpointHealthGetVariables, signal?: AbortSignal) =>
  fetch<
    HealthEndpointHealthGetResponse,
    HealthEndpointHealthGetError,
    undefined,
    {},
    HealthEndpointHealthGetQueryParams,
    {}
  >({ url: '/health', method: 'get', ...variables, signal });

export type ActiveCallbacksActiveCallbacksGetError = Fetcher.ErrorWrapper<undefined>;

export type ActiveCallbacksActiveCallbacksGetResponse = {
  [key: string]: any;
};

export type ActiveCallbacksActiveCallbacksGetVariables = FetcherExtraProps;

/**
 * Returns a list of litellm level settings
 *
 * This is useful for debugging and ensuring the proxy server is configured correctly.
 *
 * Response schema:
 * ```
 * {
 *     "alerting": _alerting,
 *     "litellm.callbacks": litellm_callbacks,
 *     "litellm.input_callback": litellm_input_callbacks,
 *     "litellm.failure_callback": litellm_failure_callbacks,
 *     "litellm.success_callback": litellm_success_callbacks,
 *     "litellm._async_success_callback": litellm_async_success_callbacks,
 *     "litellm._async_failure_callback": litellm_async_failure_callbacks,
 *     "litellm._async_input_callback": litellm_async_input_callbacks,
 *     "all_litellm_callbacks": all_litellm_callbacks,
 *     "num_callbacks": len(all_litellm_callbacks),
 *     "num_alerting": _num_alerting,
 *     "litellm.request_timeout": litellm.request_timeout,
 * }
 * ```
 */
export const activeCallbacksActiveCallbacksGet = (
  variables: ActiveCallbacksActiveCallbacksGetVariables,
  signal?: AbortSignal
) =>
  fetch<ActiveCallbacksActiveCallbacksGetResponse, ActiveCallbacksActiveCallbacksGetError, undefined, {}, {}, {}>({
    url: '/active/callbacks',
    method: 'get',
    ...variables,
    signal
  });

export type ActiveCallbacksSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type ActiveCallbacksSettingsGetResponse = {
  [key: string]: any;
};

export type ActiveCallbacksSettingsGetVariables = FetcherExtraProps;

/**
 * Returns a list of litellm level settings
 *
 * This is useful for debugging and ensuring the proxy server is configured correctly.
 *
 * Response schema:
 * ```
 * {
 *     "alerting": _alerting,
 *     "litellm.callbacks": litellm_callbacks,
 *     "litellm.input_callback": litellm_input_callbacks,
 *     "litellm.failure_callback": litellm_failure_callbacks,
 *     "litellm.success_callback": litellm_success_callbacks,
 *     "litellm._async_success_callback": litellm_async_success_callbacks,
 *     "litellm._async_failure_callback": litellm_async_failure_callbacks,
 *     "litellm._async_input_callback": litellm_async_input_callbacks,
 *     "all_litellm_callbacks": all_litellm_callbacks,
 *     "num_callbacks": len(all_litellm_callbacks),
 *     "num_alerting": _num_alerting,
 *     "litellm.request_timeout": litellm.request_timeout,
 * }
 * ```
 */
export const activeCallbacksSettingsGet = (variables: ActiveCallbacksSettingsGetVariables, signal?: AbortSignal) =>
  fetch<ActiveCallbacksSettingsGetResponse, ActiveCallbacksSettingsGetError, undefined, {}, {}, {}>({
    url: '/settings',
    method: 'get',
    ...variables,
    signal
  });

export type HealthReadinessHealthReadinessGetError = Fetcher.ErrorWrapper<undefined>;

export type HealthReadinessHealthReadinessGetResponse = {
  [key: string]: any;
};

export type HealthReadinessHealthReadinessGetVariables = FetcherExtraProps;

/**
 * Unprotected endpoint for checking if worker can receive requests
 */
export const healthReadinessHealthReadinessGet = (
  variables: HealthReadinessHealthReadinessGetVariables,
  signal?: AbortSignal
) =>
  fetch<HealthReadinessHealthReadinessGetResponse, HealthReadinessHealthReadinessGetError, undefined, {}, {}, {}>({
    url: '/health/readiness',
    method: 'get',
    ...variables,
    signal
  });

export type HealthLivelinessHealthLivenessGetError = Fetcher.ErrorWrapper<undefined>;

export type HealthLivelinessHealthLivenessGetResponse = {
  [key: string]: any;
};

export type HealthLivelinessHealthLivenessGetVariables = FetcherExtraProps;

/**
 * Unprotected endpoint for checking if worker is alive
 */
export const healthLivelinessHealthLivenessGet = (
  variables: HealthLivelinessHealthLivenessGetVariables,
  signal?: AbortSignal
) =>
  fetch<HealthLivelinessHealthLivenessGetResponse, HealthLivelinessHealthLivenessGetError, undefined, {}, {}, {}>({
    url: '/health/liveness',
    method: 'get',
    ...variables,
    signal
  });

export type HealthLivelinessHealthLivelinessGetError = Fetcher.ErrorWrapper<undefined>;

export type HealthLivelinessHealthLivelinessGetResponse = {
  [key: string]: any;
};

export type HealthLivelinessHealthLivelinessGetVariables = FetcherExtraProps;

/**
 * Unprotected endpoint for checking if worker is alive
 */
export const healthLivelinessHealthLivelinessGet = (
  variables: HealthLivelinessHealthLivelinessGetVariables,
  signal?: AbortSignal
) =>
  fetch<HealthLivelinessHealthLivelinessGetResponse, HealthLivelinessHealthLivelinessGetError, undefined, {}, {}, {}>({
    url: '/health/liveliness',
    method: 'get',
    ...variables,
    signal
  });

export type TestModelConnectionHealthTestConnectionPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type TestModelConnectionHealthTestConnectionPostResponse = {
  [key: string]: any;
};

export type TestModelConnectionHealthTestConnectionPostVariables = {
  body?: Schemas.BodyTestModelConnectionHealthTestConnectionPost;
} & FetcherExtraProps;

/**
 * Test a direct connection to a specific model.
 *
 * This endpoint allows you to verify if your proxy can successfully connect to a specific model.
 * It's useful for troubleshooting model connectivity issues without going through the full proxy routing.
 *
 * Example:
 * ```bash
 * curl -X POST 'http://localhost:4000/health/test_connection' \
 *   -H 'Authorization: Bearer sk-1234' \
 *   -H 'Content-Type: application/json' \
 *   -d '{
 *     "litellm_params": {
 *         "model": "gpt-4",
 *         "custom_llm_provider": "azure_ai",
 *         "litellm_credential_name": null,
 *         "api_key": "6xxxxxxx",
 *         "api_base": "https://litellm8397336933.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-10-21",
 *     },
 *     "mode": "chat"
 *   }'
 * ```
 *
 * Returns:
 *     dict: A dictionary containing the health check result with either success information or error details.
 */
export const testModelConnectionHealthTestConnectionPost = (
  variables: TestModelConnectionHealthTestConnectionPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    TestModelConnectionHealthTestConnectionPostResponse,
    TestModelConnectionHealthTestConnectionPostError,
    Schemas.BodyTestModelConnectionHealthTestConnectionPost,
    {},
    {},
    {}
  >({ url: '/health/test_connection', method: 'post', ...variables, signal });

export type GenerateKeyFnKeyGeneratePostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type GenerateKeyFnKeyGeneratePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GenerateKeyFnKeyGeneratePostVariables = {
  body?: Schemas.GenerateKeyRequest;
  headers?: GenerateKeyFnKeyGeneratePostHeaders;
} & FetcherExtraProps;

/**
 * Generate an API key based on the provided data.
 *
 * Docs: https://docs.litellm.ai/docs/proxy/virtual_keys
 *
 * Parameters:
 * - duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - key_alias: Optional[str] - User defined key alias
 * - key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.
 * - team_id: Optional[str] - The team id of the key
 * - user_id: Optional[str] - The user id of the key
 * - budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.
 * - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)
 * - aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models
 * - config: Optional[dict] - any key-specific configs, overrides config in config.yaml
 * - spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend
 * - send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key
 * - max_budget: Optional[float] - Specify max budget for a given key.
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 * - metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.
 * - model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.
 * - model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request
 * - blocked: Optional[bool] - Whether the key is blocked.
 * - rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)
 * - tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)
 * - soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)
 *
 * Examples:
 *
 * 1. Allow users to turn on/off pii masking
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/generate'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 *         "permissions": {"allow_pii_controls": true}
 * }'
 * ```
 *
 * Returns:
 * - key: (str) The generated api key
 * - expires: (datetime) Datetime object for when key expires.
 * - user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 */
export const generateKeyFnKeyGeneratePost = (variables: GenerateKeyFnKeyGeneratePostVariables, signal?: AbortSignal) =>
  fetch<
    Schemas.GenerateKeyResponse,
    GenerateKeyFnKeyGeneratePostError,
    Schemas.GenerateKeyRequest,
    GenerateKeyFnKeyGeneratePostHeaders,
    {},
    {}
  >({ url: '/key/generate', method: 'post', ...variables, signal });

export type UpdateKeyFnKeyUpdatePostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type UpdateKeyFnKeyUpdatePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UpdateKeyFnKeyUpdatePostResponse = {
  [key: string]: any;
};

export type UpdateKeyFnKeyUpdatePostVariables = {
  body: Schemas.UpdateKeyRequest;
  headers?: UpdateKeyFnKeyUpdatePostHeaders;
} & FetcherExtraProps;

/**
 * Update an existing API key's parameters.
 *
 * Parameters:
 * - key: str - The key to update
 * - key_alias: Optional[str] - User-friendly key alias
 * - user_id: Optional[str] - User ID associated with key
 * - team_id: Optional[str] - Team ID associated with key
 * - budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.
 * - models: Optional[list] - Model_name's a user is allowed to call
 * - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)
 * - enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)
 * - spend: Optional[float] - Amount spent by key
 * - max_budget: Optional[float] - Max budget for key
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - soft_budget: Optional[float] - [TODO] Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.
 * - max_parallel_requests: Optional[int] - Rate limit for parallel requests
 * - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}
 * - tpm_limit: Optional[int] - Tokens per minute limit
 * - rpm_limit: Optional[int] - Requests per minute limit
 * - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}
 * - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values
 * - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)
 * - permissions: Optional[dict] - Key-specific permissions
 * - send_invite_email: Optional[bool] - Send invite email to user_id
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - blocked: Optional[bool] - Whether the key is blocked
 * - aliases: Optional[dict] - Model aliases for the key - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)
 * - config: Optional[dict] - [DEPRECATED PARAM] Key-specific config.
 * - temp_budget_increase: Optional[float] - Temporary budget increase for the key (Enterprise only).
 * - temp_budget_expiry: Optional[str] - Expiry time for the temporary budget increase (Enterprise only).
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "key": "sk-1234",
 *     "key_alias": "my-key",
 *     "user_id": "user-1234",
 *     "team_id": "team-1234",
 *     "max_budget": 100,
 *     "metadata": {"any_key": "any-val"},
 * }'
 * ```
 */
export const updateKeyFnKeyUpdatePost = (variables: UpdateKeyFnKeyUpdatePostVariables, signal?: AbortSignal) =>
  fetch<
    UpdateKeyFnKeyUpdatePostResponse,
    UpdateKeyFnKeyUpdatePostError,
    Schemas.UpdateKeyRequest,
    UpdateKeyFnKeyUpdatePostHeaders,
    {},
    {}
  >({ url: '/key/update', method: 'post', ...variables, signal });

export type DeleteKeyFnKeyDeletePostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type DeleteKeyFnKeyDeletePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteKeyFnKeyDeletePostResponse = {
  [key: string]: any;
};

export type DeleteKeyFnKeyDeletePostVariables = {
  body?: Schemas.KeyRequest;
  headers?: DeleteKeyFnKeyDeletePostHeaders;
} & FetcherExtraProps;

/**
 * Delete a key from the key management system.
 *
 * Parameters::
 * - keys (List[str]): A list of keys or hashed keys to delete. Example {"keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}
 * - key_aliases (List[str]): A list of key aliases to delete. Can be passed instead of `keys`.Example {"key_aliases": ["alias1", "alias2"]}
 *
 * Returns:
 * - deleted_keys (List[str]): A list of deleted keys. Example {"deleted_keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "keys": ["sk-QWrxEynunsNpV1zT48HIrw"]
 * }'
 * ```
 *
 * Raises:
 *     HTTPException: If an error occurs during key deletion.
 */
export const deleteKeyFnKeyDeletePost = (variables: DeleteKeyFnKeyDeletePostVariables, signal?: AbortSignal) =>
  fetch<
    DeleteKeyFnKeyDeletePostResponse,
    DeleteKeyFnKeyDeletePostError,
    Schemas.KeyRequest,
    DeleteKeyFnKeyDeletePostHeaders,
    {},
    {}
  >({ url: '/key/delete', method: 'post', ...variables, signal });

export type InfoKeyFnKeyInfoGetQueryParams = {
  /**
   * Key in the request parameters
   */
  key?: string | null;
};

export type InfoKeyFnKeyInfoGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type InfoKeyFnKeyInfoGetResponse = {
  [key: string]: any;
};

export type InfoKeyFnKeyInfoGetVariables = {
  queryParams?: InfoKeyFnKeyInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Retrieve information about a key.
 * Parameters:
 *     key: Optional[str] = Query parameter representing the key in the request
 *     user_api_key_dict: UserAPIKeyAuth = Dependency representing the user's API key
 * Returns:
 *     Dict containing the key and its associated information
 *
 * Example Curl:
 * ```
 * curl -X GET "http://0.0.0.0:4000/key/info?key=sk-02Wr4IAlN3NvPXvL5JVvDA" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Curl - if no key is passed, it will use the Key Passed in Authorization Header
 * ```
 * curl -X GET "http://0.0.0.0:4000/key/info" -H "Authorization: Bearer sk-02Wr4IAlN3NvPXvL5JVvDA"
 * ```
 */
export const infoKeyFnKeyInfoGet = (variables: InfoKeyFnKeyInfoGetVariables, signal?: AbortSignal) =>
  fetch<InfoKeyFnKeyInfoGetResponse, InfoKeyFnKeyInfoGetError, undefined, {}, InfoKeyFnKeyInfoGetQueryParams, {}>({
    url: '/key/info',
    method: 'get',
    ...variables,
    signal
  });

export type RegenerateKeyFnKeyRegeneratePostQueryParams = {
  key?: string | null;
};

export type RegenerateKeyFnKeyRegeneratePostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type RegenerateKeyFnKeyRegeneratePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type RegenerateKeyFnKeyRegeneratePostVariables = {
  body?: Schemas.RegenerateKeyRequest | null;
  headers?: RegenerateKeyFnKeyRegeneratePostHeaders;
  queryParams?: RegenerateKeyFnKeyRegeneratePostQueryParams;
} & FetcherExtraProps;

/**
 * Regenerate an existing API key while optionally updating its parameters.
 *
 * Parameters:
 * - key: str (path parameter) - The key to regenerate
 * - data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update
 *     - key_alias: Optional[str] - User-friendly key alias
 *     - user_id: Optional[str] - User ID associated with key
 *     - team_id: Optional[str] - Team ID associated with key
 *     - models: Optional[list] - Model_name's a user is allowed to call
 *     - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)
 *     - spend: Optional[float] - Amount spent by key
 *     - max_budget: Optional[float] - Max budget for key
 *     - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}
 *     - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 *     - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.
 *     - max_parallel_requests: Optional[int] - Rate limit for parallel requests
 *     - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}
 *     - tpm_limit: Optional[int] - Tokens per minute limit
 *     - rpm_limit: Optional[int] - Requests per minute limit
 *     - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}
 *     - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}
 *     - allowed_cache_controls: Optional[list] - List of allowed cache control values
 *     - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)
 *     - permissions: Optional[dict] - Key-specific permissions
 *     - guardrails: Optional[List[str]] - List of active guardrails for the key
 *     - blocked: Optional[bool] - Whether the key is blocked
 *
 *
 * Returns:
 * - GenerateKeyResponse containing the new key and its updated parameters
 *
 * Example:
 * ```bash
 * curl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "max_budget": 100,
 *     "metadata": {"team": "core-infra"},
 *     "models": ["gpt-4", "gpt-3.5-turbo"]
 * }'
 * ```
 *
 * Note: This is an Enterprise feature. It requires a premium license to use.
 */
export const regenerateKeyFnKeyRegeneratePost = (
  variables: RegenerateKeyFnKeyRegeneratePostVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.GenerateKeyResponse | null,
    RegenerateKeyFnKeyRegeneratePostError,
    Schemas.RegenerateKeyRequest | null,
    RegenerateKeyFnKeyRegeneratePostHeaders,
    RegenerateKeyFnKeyRegeneratePostQueryParams,
    {}
  >({ url: '/key/regenerate', method: 'post', ...variables, signal });

export type RegenerateKeyFnKeyKeyRegeneratePostPathParams = {
  key: string | null;
};

export type RegenerateKeyFnKeyKeyRegeneratePostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type RegenerateKeyFnKeyKeyRegeneratePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type RegenerateKeyFnKeyKeyRegeneratePostVariables = {
  body?: Schemas.RegenerateKeyRequest | null;
  headers?: RegenerateKeyFnKeyKeyRegeneratePostHeaders;
  pathParams: RegenerateKeyFnKeyKeyRegeneratePostPathParams;
} & FetcherExtraProps;

/**
 * Regenerate an existing API key while optionally updating its parameters.
 *
 * Parameters:
 * - key: str (path parameter) - The key to regenerate
 * - data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update
 *     - key_alias: Optional[str] - User-friendly key alias
 *     - user_id: Optional[str] - User ID associated with key
 *     - team_id: Optional[str] - Team ID associated with key
 *     - models: Optional[list] - Model_name's a user is allowed to call
 *     - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)
 *     - spend: Optional[float] - Amount spent by key
 *     - max_budget: Optional[float] - Max budget for key
 *     - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}
 *     - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 *     - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.
 *     - max_parallel_requests: Optional[int] - Rate limit for parallel requests
 *     - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}
 *     - tpm_limit: Optional[int] - Tokens per minute limit
 *     - rpm_limit: Optional[int] - Requests per minute limit
 *     - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}
 *     - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}
 *     - allowed_cache_controls: Optional[list] - List of allowed cache control values
 *     - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)
 *     - permissions: Optional[dict] - Key-specific permissions
 *     - guardrails: Optional[List[str]] - List of active guardrails for the key
 *     - blocked: Optional[bool] - Whether the key is blocked
 *
 *
 * Returns:
 * - GenerateKeyResponse containing the new key and its updated parameters
 *
 * Example:
 * ```bash
 * curl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "max_budget": 100,
 *     "metadata": {"team": "core-infra"},
 *     "models": ["gpt-4", "gpt-3.5-turbo"]
 * }'
 * ```
 *
 * Note: This is an Enterprise feature. It requires a premium license to use.
 */
export const regenerateKeyFnKeyKeyRegeneratePost = (
  variables: RegenerateKeyFnKeyKeyRegeneratePostVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.GenerateKeyResponse | null,
    RegenerateKeyFnKeyKeyRegeneratePostError,
    Schemas.RegenerateKeyRequest | null,
    RegenerateKeyFnKeyKeyRegeneratePostHeaders,
    {},
    RegenerateKeyFnKeyKeyRegeneratePostPathParams
  >({ url: '/key/{key}/regenerate', method: 'post', ...variables, signal });

export type ListKeysKeyListGetQueryParams = {
  /**
   * Page number
   *
   * @minimum 1
   * @default 1
   */
  page?: number;
  /**
   * Page size
   *
   * @maximum 100
   * @minimum 1
   * @default 10
   */
  size?: number;
  /**
   * Filter keys by user ID
   */
  user_id?: string | null;
  /**
   * Filter keys by team ID
   */
  team_id?: string | null;
  /**
   * Filter keys by organization ID
   */
  organization_id?: string | null;
  /**
   * Filter keys by key alias
   */
  key_alias?: string | null;
  /**
   * Return full key object
   *
   * @default false
   */
  return_full_object?: boolean;
  /**
   * Include all keys for teams that user is an admin of.
   *
   * @default false
   */
  include_team_keys?: boolean;
};

export type ListKeysKeyListGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListKeysKeyListGetVariables = {
  queryParams?: ListKeysKeyListGetQueryParams;
} & FetcherExtraProps;

/**
 * List all keys for a given user / team / organization.
 *
 * Returns:
 *     {
 *         "keys": List[str] or List[UserAPIKeyAuth],
 *         "total_count": int,
 *         "current_page": int,
 *         "total_pages": int,
 *     }
 */
export const listKeysKeyListGet = (variables: ListKeysKeyListGetVariables, signal?: AbortSignal) =>
  fetch<Schemas.KeyListResponseObject, ListKeysKeyListGetError, undefined, {}, ListKeysKeyListGetQueryParams, {}>({
    url: '/key/list',
    method: 'get',
    ...variables,
    signal
  });

export type BlockKeyKeyBlockPostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type BlockKeyKeyBlockPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type BlockKeyKeyBlockPostVariables = {
  body: Schemas.BlockKeyRequest;
  headers?: BlockKeyKeyBlockPostHeaders;
} & FetcherExtraProps;

/**
 * Block an Virtual key from making any requests.
 *
 * Parameters:
 * - key: str - The key to block. Can be either the unhashed key (sk-...) or the hashed key value
 *
 *  Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"
 * }'
 * ```
 *
 * Note: This is an admin-only endpoint. Only proxy admins can block keys.
 */
export const blockKeyKeyBlockPost = (variables: BlockKeyKeyBlockPostVariables, signal?: AbortSignal) =>
  fetch<
    Schemas.LiteLLMVerificationToken | null,
    BlockKeyKeyBlockPostError,
    Schemas.BlockKeyRequest,
    BlockKeyKeyBlockPostHeaders,
    {},
    {}
  >({ url: '/key/block', method: 'post', ...variables, signal });

export type UnblockKeyKeyUnblockPostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type UnblockKeyKeyUnblockPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UnblockKeyKeyUnblockPostResponse = {
  [key: string]: any;
};

export type UnblockKeyKeyUnblockPostVariables = {
  body: Schemas.BlockKeyRequest;
  headers?: UnblockKeyKeyUnblockPostHeaders;
} & FetcherExtraProps;

/**
 * Unblock a Virtual key to allow it to make requests again.
 *
 * Parameters:
 * - key: str - The key to unblock. Can be either the unhashed key (sk-...) or the hashed key value
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"
 * }'
 * ```
 *
 * Note: This is an admin-only endpoint. Only proxy admins can unblock keys.
 */
export const unblockKeyKeyUnblockPost = (variables: UnblockKeyKeyUnblockPostVariables, signal?: AbortSignal) =>
  fetch<
    UnblockKeyKeyUnblockPostResponse,
    UnblockKeyKeyUnblockPostError,
    Schemas.BlockKeyRequest,
    UnblockKeyKeyUnblockPostHeaders,
    {},
    {}
  >({ url: '/key/unblock', method: 'post', ...variables, signal });

export type KeyHealthKeyHealthPostError = Fetcher.ErrorWrapper<undefined>;

export type KeyHealthKeyHealthPostVariables = FetcherExtraProps;

/**
 * Check the health of the key
 *
 * Checks:
 * - If key based logging is configured correctly - sends a test log
 *
 * Usage
 *
 * Pass the key in the request header
 *
 * ```bash
 * curl -X POST "http://localhost:4000/key/health"      -H "Authorization: Bearer sk-1234"      -H "Content-Type: application/json"
 * ```
 *
 * Response when logging callbacks are setup correctly:
 *
 * ```json
 * {
 *   "key": "healthy",
 *   "logging_callbacks": {
 *     "callbacks": [
 *       "gcs_bucket"
 *     ],
 *     "status": "healthy",
 *     "details": "No logger exceptions triggered, system is healthy. Manually check if logs were sent to ['gcs_bucket']"
 *   }
 * }
 * ```
 *
 *
 * Response when logging callbacks are not setup correctly:
 * ```json
 * {
 *   "key": "unhealthy",
 *   "logging_callbacks": {
 *     "callbacks": [
 *       "gcs_bucket"
 *     ],
 *     "status": "unhealthy",
 *     "details": "Logger exceptions triggered, system is unhealthy: Failed to load vertex credentials. Check to see if credentials containing partial/invalid information."
 *   }
 * }
 * ```
 */
export const keyHealthKeyHealthPost = (variables: KeyHealthKeyHealthPostVariables, signal?: AbortSignal) =>
  fetch<Schemas.KeyHealthResponse, KeyHealthKeyHealthPostError, undefined, {}, {}, {}>({
    url: '/key/health',
    method: 'post',
    ...variables,
    signal
  });

export type NewUserUserNewPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type NewUserUserNewPostVariables = {
  body?: Schemas.NewUserRequest;
} & FetcherExtraProps;

/**
 * Use this to create a new INTERNAL user with a budget.
 * Internal Users can access LiteLLM Admin UI to make keys, request access to models.
 * This creates a new user and generates a new api key for the new user. The new api key is returned.
 *
 * Returns user id, budget + new key.
 *
 * Parameters:
 * - user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.
 * - user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.
 * - teams: Optional[list] - specify a list of team id's a user belongs to.
 * - user_email: Optional[str] - Specify a user email.
 * - send_invite_email: Optional[bool] - Specify if an invite email should be sent.
 * - user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`
 * - max_budget: Optional[float] - Specify max budget for a given user.
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 * - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models). Set to ['no-default-models'] to block all model access. Restricting user to only team-based model access.
 * - tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)
 * - rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)
 * - auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response
 * - aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)
 * - config: Optional[dict] - [DEPRECATED PARAM] User-specific config.
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-
 * - blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.
 * - guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user
 * - permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.
 * - metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 * - soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.
 * - model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)
 * - model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 * - model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 * - spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 * - team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None.
 * - duration: Optional[str] - Duration for the key auto-created on `/user/new`. Default is None.
 * - key_alias: Optional[str] - Alias for the key auto-created on `/user/new`. Default is None.
 *
 * Returns:
 * - key: (str) The generated api key for the user
 * - expires: (datetime) Datetime object for when key expires.
 * - user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 * - max_budget: (float|None) Max budget for given user.
 *
 * Usage Example
 *
 * ```shell
 *  curl -X POST "http://localhost:4000/user/new"      -H "Content-Type: application/json"      -H "Authorization: Bearer sk-1234"      -d '{
 *      "username": "new_user",
 *      "email": "new_user@example.com"
 *  }'
 * ```
 */
export const newUserUserNewPost = (variables: NewUserUserNewPostVariables, signal?: AbortSignal) =>
  fetch<Schemas.NewUserResponse, NewUserUserNewPostError, Schemas.NewUserRequest, {}, {}, {}>({
    url: '/user/new',
    method: 'post',
    ...variables,
    signal
  });

export type UserInfoUserInfoGetQueryParams = {
  /**
   * User ID in the request parameters
   */
  user_id?: string | null;
};

export type UserInfoUserInfoGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UserInfoUserInfoGetResponse = {
  [key: string]: any;
};

export type UserInfoUserInfoGetVariables = {
  queryParams?: UserInfoUserInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * [10/07/2024]
 * Note: To get all users (+pagination), use `/user/list` endpoint.
 *
 *
 * Use this to get user information. (user row + all user key info)
 *
 * Example request
 * ```
 * curl -X GET 'http://localhost:4000/user/info?user_id=krrish7%40berri.ai'     --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const userInfoUserInfoGet = (variables: UserInfoUserInfoGetVariables, signal?: AbortSignal) =>
  fetch<UserInfoUserInfoGetResponse, UserInfoUserInfoGetError, undefined, {}, UserInfoUserInfoGetQueryParams, {}>({
    url: '/user/info',
    method: 'get',
    ...variables,
    signal
  });

export type UserUpdateUserUpdatePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UserUpdateUserUpdatePostResponse = {
  [key: string]: any;
};

export type UserUpdateUserUpdatePostVariables = {
  body?: Schemas.UpdateUserRequest;
} & FetcherExtraProps;

/**
 * Example curl
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/user/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "user_id": "test-litellm-user-4",
 *     "user_role": "proxy_admin_viewer"
 * }'
 * ```
 *
 * Parameters:
 *     - user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.
 *     - user_email: Optional[str] - Specify a user email.
 *     - password: Optional[str] - Specify a user password.
 *     - user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.
 *     - teams: Optional[list] - specify a list of team id's a user belongs to.
 *     - send_invite_email: Optional[bool] - Specify if an invite email should be sent.
 *     - user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`
 *     - max_budget: Optional[float] - Specify max budget for a given user.
 *     - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 *     - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)
 *     - tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)
 *     - rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)
 *     - auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response
 *     - aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)
 *     - config: Optional[dict] - [DEPRECATED PARAM] User-specific config.
 *     - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-
 *     - blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.
 *     - guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user
 *     - permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.
 *     - metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 *     - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 *     - soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.
 *     - model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)
 *     - model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 *     - model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 *     - spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 *     - team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None.
 *     - duration: Optional[str] - [NOT IMPLEMENTED].
 *     - key_alias: Optional[str] - [NOT IMPLEMENTED].
 */
export const userUpdateUserUpdatePost = (variables: UserUpdateUserUpdatePostVariables, signal?: AbortSignal) =>
  fetch<UserUpdateUserUpdatePostResponse, UserUpdateUserUpdatePostError, Schemas.UpdateUserRequest, {}, {}, {}>({
    url: '/user/update',
    method: 'post',
    ...variables,
    signal
  });

export type GetUsersUserListGetQueryParams = {
  /**
   * Filter users by role
   */
  role?: string | null;
  /**
   * Get list of users by user_ids
   */
  user_ids?: string | null;
  /**
   * Page number
   *
   * @minimum 1
   * @default 1
   */
  page?: number;
  /**
   * Number of items per page
   *
   * @maximum 100
   * @minimum 1
   * @default 25
   */
  page_size?: number;
};

export type GetUsersUserListGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetUsersUserListGetResponse = {
  [key: string]: any;
};

export type GetUsersUserListGetVariables = {
  queryParams?: GetUsersUserListGetQueryParams;
} & FetcherExtraProps;

/**
 * Get a paginated list of users, optionally filtered by role.
 *
 * Used by the UI to populate the user lists.
 *
 * Parameters:
 *     role: Optional[str]
 *         Filter users by role. Can be one of:
 *         - proxy_admin
 *         - proxy_admin_viewer
 *         - internal_user
 *         - internal_user_viewer
 *     user_ids: Optional[str]
 *         Get list of users by user_ids. Comma separated list of user_ids.
 *     page: int
 *         The page number to return
 *     page_size: int
 *         The number of items per page
 *
 * Currently - admin-only endpoint.
 *
 * Example curl:
 * ```
 * http://0.0.0.0:4000/user/list?user_ids=default_user_id,693c1a4a-1cc0-4c7c-afe8-b5d2c8d52e17
 * ```
 */
export const getUsersUserListGet = (variables: GetUsersUserListGetVariables, signal?: AbortSignal) =>
  fetch<GetUsersUserListGetResponse, GetUsersUserListGetError, undefined, {}, GetUsersUserListGetQueryParams, {}>({
    url: '/user/list',
    method: 'get',
    ...variables,
    signal
  });

export type GetUsersUserGetUsersGetQueryParams = {
  /**
   * Filter users by role
   */
  role?: string | null;
  /**
   * Get list of users by user_ids
   */
  user_ids?: string | null;
  /**
   * Page number
   *
   * @minimum 1
   * @default 1
   */
  page?: number;
  /**
   * Number of items per page
   *
   * @maximum 100
   * @minimum 1
   * @default 25
   */
  page_size?: number;
};

export type GetUsersUserGetUsersGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetUsersUserGetUsersGetResponse = {
  [key: string]: any;
};

export type GetUsersUserGetUsersGetVariables = {
  queryParams?: GetUsersUserGetUsersGetQueryParams;
} & FetcherExtraProps;

/**
 * Get a paginated list of users, optionally filtered by role.
 *
 * Used by the UI to populate the user lists.
 *
 * Parameters:
 *     role: Optional[str]
 *         Filter users by role. Can be one of:
 *         - proxy_admin
 *         - proxy_admin_viewer
 *         - internal_user
 *         - internal_user_viewer
 *     user_ids: Optional[str]
 *         Get list of users by user_ids. Comma separated list of user_ids.
 *     page: int
 *         The page number to return
 *     page_size: int
 *         The number of items per page
 *
 * Currently - admin-only endpoint.
 *
 * Example curl:
 * ```
 * http://0.0.0.0:4000/user/list?user_ids=default_user_id,693c1a4a-1cc0-4c7c-afe8-b5d2c8d52e17
 * ```
 */
export const getUsersUserGetUsersGet = (variables: GetUsersUserGetUsersGetVariables, signal?: AbortSignal) =>
  fetch<
    GetUsersUserGetUsersGetResponse,
    GetUsersUserGetUsersGetError,
    undefined,
    {},
    GetUsersUserGetUsersGetQueryParams,
    {}
  >({ url: '/user/get_users', method: 'get', ...variables, signal });

export type DeleteUserUserDeletePostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type DeleteUserUserDeletePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteUserUserDeletePostResponse = {
  [key: string]: any;
};

export type DeleteUserUserDeletePostVariables = {
  body: Schemas.DeleteUserRequest;
  headers?: DeleteUserUserDeletePostHeaders;
} & FetcherExtraProps;

/**
 * delete user and associated user keys
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/user/delete'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data-raw '{
 *     "user_ids": ["45e3e396-ee08-4a61-a88e-16b3ce7e0849"]
 * }'
 * ```
 *
 * Parameters:
 * - user_ids: List[str] - The list of user id's to be deleted.
 */
export const deleteUserUserDeletePost = (variables: DeleteUserUserDeletePostVariables, signal?: AbortSignal) =>
  fetch<
    DeleteUserUserDeletePostResponse,
    DeleteUserUserDeletePostError,
    Schemas.DeleteUserRequest,
    DeleteUserUserDeletePostHeaders,
    {},
    {}
  >({ url: '/user/delete', method: 'post', ...variables, signal });

export type GetUserDailyActivityUserDailyActivityGetQueryParams = {
  /**
   * Start date in YYYY-MM-DD format
   */
  start_date?: string | null;
  /**
   * End date in YYYY-MM-DD format
   */
  end_date?: string | null;
  /**
   * Filter by specific model
   */
  model?: string | null;
  /**
   * Filter by specific API key
   */
  api_key?: string | null;
  /**
   * Page number for pagination
   *
   * @minimum 1
   * @default 1
   */
  page?: number;
  /**
   * Items per page
   *
   * @maximum 100
   * @minimum 1
   * @default 50
   */
  page_size?: number;
};

export type GetUserDailyActivityUserDailyActivityGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetUserDailyActivityUserDailyActivityGetVariables = {
  queryParams?: GetUserDailyActivityUserDailyActivityGetQueryParams;
} & FetcherExtraProps;

/**
 * [BETA] This is a beta endpoint. It will change.
 *
 * Meant to optimize querying spend data for analytics for a user.
 *
 * Returns:
 * (by date)
 * - spend
 * - prompt_tokens
 * - completion_tokens
 * - total_tokens
 * - api_requests
 * - breakdown by model, api_key, provider
 */
export const getUserDailyActivityUserDailyActivityGet = (
  variables: GetUserDailyActivityUserDailyActivityGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.SpendAnalyticsPaginatedResponse,
    GetUserDailyActivityUserDailyActivityGetError,
    undefined,
    {},
    GetUserDailyActivityUserDailyActivityGetQueryParams,
    {}
  >({ url: '/user/daily/activity', method: 'get', ...variables, signal });

export type NewTeamTeamNewPostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type NewTeamTeamNewPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type NewTeamTeamNewPostVariables = {
  body?: Schemas.NewTeamRequest;
  headers?: NewTeamTeamNewPostHeaders;
} & FetcherExtraProps;

/**
 * Allow users to create a new team. Apply user permissions to their team.
 *
 *  [Detailed Doc on setting team budgets](https://docs.litellm.ai/docs/proxy/team_budgets)
 *
 *
 * Parameters:
 * - team_alias: Optional[str] - User defined team alias
 * - team_id: Optional[str] - The team id of the user. If none passed, we'll generate it.
 * - members_with_roles: List[{"role": "admin" or "user", "user_id": "<user-id>"}] - A list of users and their roles in the team. Get user_id when making a new user via `/user/new`.
 * - metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"extra_info": "some info"}
 * - tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit
 * - rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit
 * - max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget
 * - budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)
 * - models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.
 * - blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.
 * - members: Optional[List] - Control team members via `/team/member/add` and `/team/member/delete`.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.
 * - model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)
 * - guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)
 * Returns:
 * - team_id: (str) Unique team id - used for tracking spend across multiple keys for same team id.
 *
 * _deprecated_params:
 * - admins: list - A list of user_id's for the admin role
 * - users: list - A list of user_id's for the user role
 *
 * Example Request:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *   "team_alias": "my-new-team_2",
 *   "members_with_roles": [{"role": "admin", "user_id": "user-1234"},
 *     {"role": "user", "user_id": "user-2434"}]
 * }'
 *
 * ```
 *
 *  ```
 * curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *             "team_alias": "QA Prod Bot",
 *             "max_budget": 0.000000001,
 *             "budget_duration": "1d"
 *         }'
 * ```
 */
export const newTeamTeamNewPost = (variables: NewTeamTeamNewPostVariables, signal?: AbortSignal) =>
  fetch<Schemas.LiteLLMTeamTable, NewTeamTeamNewPostError, Schemas.NewTeamRequest, NewTeamTeamNewPostHeaders, {}, {}>({
    url: '/team/new',
    method: 'post',
    ...variables,
    signal
  });

export type UpdateTeamTeamUpdatePostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type UpdateTeamTeamUpdatePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UpdateTeamTeamUpdatePostResponse = {
  [key: string]: any;
};

export type UpdateTeamTeamUpdatePostVariables = {
  body: Schemas.UpdateTeamRequest;
  headers?: UpdateTeamTeamUpdatePostHeaders;
} & FetcherExtraProps;

/**
 * Use `/team/member_add` AND `/team/member/delete` to add/remove new team members
 *
 * You can now update team budget / rate limits via /team/update
 *
 * Parameters:
 * - team_id: str - The team id of the user. Required param.
 * - team_alias: Optional[str] - User defined team alias
 * - metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit
 * - rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit
 * - max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget
 * - budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)
 * - models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.
 * - blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.
 * - model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)
 * - guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)
 * Example - update team TPM Limit
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",
 *     "tpm_limit": 100
 * }'
 * ```
 *
 * Example - Update Team `max_budget` budget
 * ```
 * curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",
 *     "max_budget": 10
 * }'
 * ```
 */
export const updateTeamTeamUpdatePost = (variables: UpdateTeamTeamUpdatePostVariables, signal?: AbortSignal) =>
  fetch<
    UpdateTeamTeamUpdatePostResponse,
    UpdateTeamTeamUpdatePostError,
    Schemas.UpdateTeamRequest,
    UpdateTeamTeamUpdatePostHeaders,
    {},
    {}
  >({ url: '/team/update', method: 'post', ...variables, signal });

export type TeamMemberAddTeamMemberAddPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type TeamMemberAddTeamMemberAddPostVariables = {
  body: Schemas.TeamMemberAddRequest;
} & FetcherExtraProps;

/**
 * [BETA]
 *
 * Add new members (either via user_email or user_id) to a team
 *
 * If user doesn't exist, new user row will also be added to User Table
 *
 * Only proxy_admin or admin of team, allowed to access this endpoint.
 * ```
 *
 * curl -X POST 'http://0.0.0.0:4000/team/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{"team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849", "member": {"role": "user", "user_id": "krrish247652@berri.ai"}}'
 *
 * ```
 */
export const teamMemberAddTeamMemberAddPost = (
  variables: TeamMemberAddTeamMemberAddPostVariables,
  signal?: AbortSignal
) =>
  fetch<Schemas.TeamAddMemberResponse, TeamMemberAddTeamMemberAddPostError, Schemas.TeamMemberAddRequest, {}, {}, {}>({
    url: '/team/member_add',
    method: 'post',
    ...variables,
    signal
  });

export type TeamMemberDeleteTeamMemberDeletePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type TeamMemberDeleteTeamMemberDeletePostResponse = {
  [key: string]: any;
};

export type TeamMemberDeleteTeamMemberDeletePostVariables = {
  body: Schemas.TeamMemberDeleteRequest;
} & FetcherExtraProps;

/**
 * [BETA]
 *
 * delete members (either via user_email or user_id) from a team
 *
 * If user doesn't exist, an exception will be raised
 * ```
 * curl -X POST 'http://0.0.0.0:8000/team/member_delete'
 * -H 'Authorization: Bearer sk-1234'
 * -H 'Content-Type: application/json'
 * -d '{
 *     "team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",
 *     "user_id": "krrish247652@berri.ai"
 * }'
 * ```
 */
export const teamMemberDeleteTeamMemberDeletePost = (
  variables: TeamMemberDeleteTeamMemberDeletePostVariables,
  signal?: AbortSignal
) =>
  fetch<
    TeamMemberDeleteTeamMemberDeletePostResponse,
    TeamMemberDeleteTeamMemberDeletePostError,
    Schemas.TeamMemberDeleteRequest,
    {},
    {},
    {}
  >({ url: '/team/member_delete', method: 'post', ...variables, signal });

export type TeamMemberUpdateTeamMemberUpdatePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type TeamMemberUpdateTeamMemberUpdatePostVariables = {
  body: Schemas.TeamMemberUpdateRequest;
} & FetcherExtraProps;

/**
 * [BETA]
 *
 * Update team member budgets and team member role
 */
export const teamMemberUpdateTeamMemberUpdatePost = (
  variables: TeamMemberUpdateTeamMemberUpdatePostVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.TeamMemberUpdateResponse,
    TeamMemberUpdateTeamMemberUpdatePostError,
    Schemas.TeamMemberUpdateRequest,
    {},
    {},
    {}
  >({ url: '/team/member_update', method: 'post', ...variables, signal });

export type DeleteTeamTeamDeletePostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type DeleteTeamTeamDeletePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteTeamTeamDeletePostResponse = {
  [key: string]: any;
};

export type DeleteTeamTeamDeletePostVariables = {
  body: Schemas.DeleteTeamRequest;
  headers?: DeleteTeamTeamDeletePostHeaders;
} & FetcherExtraProps;

/**
 * delete team and associated team keys
 *
 * Parameters:
 * - team_ids: List[str] - Required. List of team IDs to delete. Example: ["team-1234", "team-5678"]
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/team/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 *     "team_ids": ["8d916b1c-510d-4894-a334-1c16a93344f5"]
 * }'
 * ```
 */
export const deleteTeamTeamDeletePost = (variables: DeleteTeamTeamDeletePostVariables, signal?: AbortSignal) =>
  fetch<
    DeleteTeamTeamDeletePostResponse,
    DeleteTeamTeamDeletePostError,
    Schemas.DeleteTeamRequest,
    DeleteTeamTeamDeletePostHeaders,
    {},
    {}
  >({ url: '/team/delete', method: 'post', ...variables, signal });

export type TeamInfoTeamInfoGetQueryParams = {
  /**
   * Team ID in the request parameters
   */
  team_id?: string;
};

export type TeamInfoTeamInfoGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type TeamInfoTeamInfoGetResponse = {
  [key: string]: any;
};

export type TeamInfoTeamInfoGetVariables = {
  queryParams?: TeamInfoTeamInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * get info on team + related keys
 *
 * Parameters:
 * - team_id: str - Required. The unique identifier of the team to get info on.
 *
 * ```
 * curl --location 'http://localhost:4000/team/info?team_id=your_team_id_here'     --header 'Authorization: Bearer your_api_key_here'
 * ```
 */
export const teamInfoTeamInfoGet = (variables: TeamInfoTeamInfoGetVariables, signal?: AbortSignal) =>
  fetch<TeamInfoTeamInfoGetResponse, TeamInfoTeamInfoGetError, undefined, {}, TeamInfoTeamInfoGetQueryParams, {}>({
    url: '/team/info',
    method: 'get',
    ...variables,
    signal
  });

export type BlockTeamTeamBlockPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type BlockTeamTeamBlockPostResponse = {
  [key: string]: any;
};

export type BlockTeamTeamBlockPostVariables = {
  body: Schemas.BlockTeamRequest;
} & FetcherExtraProps;

/**
 * Blocks all calls from keys with this team id.
 *
 * Parameters:
 * - team_id: str - Required. The unique identifier of the team to block.
 *
 * Example:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "team_id": "team-1234"
 * }'
 * ```
 *
 * Returns:
 * - The updated team record with blocked=True
 */
export const blockTeamTeamBlockPost = (variables: BlockTeamTeamBlockPostVariables, signal?: AbortSignal) =>
  fetch<BlockTeamTeamBlockPostResponse, BlockTeamTeamBlockPostError, Schemas.BlockTeamRequest, {}, {}, {}>({
    url: '/team/block',
    method: 'post',
    ...variables,
    signal
  });

export type UnblockTeamTeamUnblockPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UnblockTeamTeamUnblockPostResponse = {
  [key: string]: any;
};

export type UnblockTeamTeamUnblockPostVariables = {
  body: Schemas.BlockTeamRequest;
} & FetcherExtraProps;

/**
 * Blocks all calls from keys with this team id.
 *
 * Parameters:
 * - team_id: str - Required. The unique identifier of the team to unblock.
 *
 * Example:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "team_id": "team-1234"
 * }'
 * ```
 */
export const unblockTeamTeamUnblockPost = (variables: UnblockTeamTeamUnblockPostVariables, signal?: AbortSignal) =>
  fetch<UnblockTeamTeamUnblockPostResponse, UnblockTeamTeamUnblockPostError, Schemas.BlockTeamRequest, {}, {}, {}>({
    url: '/team/unblock',
    method: 'post',
    ...variables,
    signal
  });

export type ListAvailableTeamsTeamAvailableGetQueryParams = {
  response_model?: undefined;
};

export type ListAvailableTeamsTeamAvailableGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListAvailableTeamsTeamAvailableGetResponse = {
  [key: string]: any;
};

export type ListAvailableTeamsTeamAvailableGetVariables = {
  queryParams?: ListAvailableTeamsTeamAvailableGetQueryParams;
} & FetcherExtraProps;

export const listAvailableTeamsTeamAvailableGet = (
  variables: ListAvailableTeamsTeamAvailableGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    ListAvailableTeamsTeamAvailableGetResponse,
    ListAvailableTeamsTeamAvailableGetError,
    undefined,
    {},
    ListAvailableTeamsTeamAvailableGetQueryParams,
    {}
  >({ url: '/team/available', method: 'get', ...variables, signal });

export type ListTeamTeamListGetQueryParams = {
  /**
   * Only return teams which this 'user_id' belongs to
   */
  user_id?: string | null;
  organization_id?: string | null;
};

export type ListTeamTeamListGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListTeamTeamListGetResponse = {
  [key: string]: any;
};

export type ListTeamTeamListGetVariables = {
  queryParams?: ListTeamTeamListGetQueryParams;
} & FetcherExtraProps;

/**
 * ```
 * curl --location --request GET 'http://0.0.0.0:4000/team/list'         --header 'Authorization: Bearer sk-1234'
 * ```
 *
 * Parameters:
 * - user_id: str - Optional. If passed will only return teams that the user_id is a member of.
 * - organization_id: str - Optional. If passed will only return teams that belong to the organization_id. Pass 'default_organization' to get all teams without organization_id.
 */
export const listTeamTeamListGet = (variables: ListTeamTeamListGetVariables, signal?: AbortSignal) =>
  fetch<ListTeamTeamListGetResponse, ListTeamTeamListGetError, undefined, {}, ListTeamTeamListGetQueryParams, {}>({
    url: '/team/list',
    method: 'get',
    ...variables,
    signal
  });

export type TeamModelAddTeamModelAddPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type TeamModelAddTeamModelAddPostResponse = {
  [key: string]: any;
};

export type TeamModelAddTeamModelAddPostVariables = {
  body: Schemas.TeamModelAddRequest;
} & FetcherExtraProps;

/**
 * Add models to a team's allowed model list. Only proxy admin or team admin can add models.
 *
 * Parameters:
 * - team_id: str - Required. The team to add models to
 * - models: List[str] - Required. List of models to add to the team
 *
 * Example Request:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/model/add'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "team_id": "team-1234",
 *     "models": ["gpt-4", "claude-2"]
 * }'
 * ```
 */
export const teamModelAddTeamModelAddPost = (variables: TeamModelAddTeamModelAddPostVariables, signal?: AbortSignal) =>
  fetch<
    TeamModelAddTeamModelAddPostResponse,
    TeamModelAddTeamModelAddPostError,
    Schemas.TeamModelAddRequest,
    {},
    {},
    {}
  >({ url: '/team/model/add', method: 'post', ...variables, signal });

export type TeamModelDeleteTeamModelDeletePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type TeamModelDeleteTeamModelDeletePostResponse = {
  [key: string]: any;
};

export type TeamModelDeleteTeamModelDeletePostVariables = {
  body: Schemas.TeamModelDeleteRequest;
} & FetcherExtraProps;

/**
 * Remove models from a team's allowed model list. Only proxy admin or team admin can remove models.
 *
 * Parameters:
 * - team_id: str - Required. The team to remove models from
 * - models: List[str] - Required. List of models to remove from the team
 *
 * Example Request:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/model/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "team_id": "team-1234",
 *     "models": ["gpt-4"]
 * }'
 * ```
 */
export const teamModelDeleteTeamModelDeletePost = (
  variables: TeamModelDeleteTeamModelDeletePostVariables,
  signal?: AbortSignal
) =>
  fetch<
    TeamModelDeleteTeamModelDeletePostResponse,
    TeamModelDeleteTeamModelDeletePostError,
    Schemas.TeamModelDeleteRequest,
    {},
    {},
    {}
  >({ url: '/team/model/delete', method: 'post', ...variables, signal });

export type NewOrganizationOrganizationNewPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type NewOrganizationOrganizationNewPostVariables = {
  body: Schemas.NewOrganizationRequest;
} & FetcherExtraProps;

/**
 * Allow orgs to own teams
 *
 * Set org level budgets + model access.
 *
 * Only admins can create orgs.
 *
 * # Parameters
 *
 * - organization_alias: *str* - The name of the organization.
 * - models: *List* - The models the organization has access to.
 * - budget_id: *Optional[str]* - The id for a budget (tpm/rpm/max budget) for the organization.
 * ### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###
 * - max_budget: *Optional[float]* - Max budget for org
 * - tpm_limit: *Optional[int]* - Max tpm limit for org
 * - rpm_limit: *Optional[int]* - Max rpm limit for org
 * - max_parallel_requests: *Optional[int]* - [Not Implemented Yet] Max parallel requests for org
 * - soft_budget: *Optional[float]* - [Not Implemented Yet] Get a slack alert when this soft budget is reached. Don't block requests.
 * - model_max_budget: *Optional[dict]* - Max budget for a specific model
 * - budget_duration: *Optional[str]* - Frequency of reseting org budget
 * - metadata: *Optional[dict]* - Metadata for organization, store information for organization. Example metadata - {"extra_info": "some info"}
 * - blocked: *bool* - Flag indicating if the org is blocked or not - will stop all calls from keys with this org_id.
 * - tags: *Optional[List[str]]* - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - organization_id: *Optional[str]* - The organization id of the team. Default is None. Create via `/organization/new`.
 * - model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)
 *
 * Case 1: Create new org **without** a budget_id
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/organization/new'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 *     "organization_alias": "my-secret-org",
 *     "models": ["model1", "model2"],
 *     "max_budget": 100
 * }'
 *
 *
 * ```
 *
 * Case 2: Create new org **with** a budget_id
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/organization/new'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 *     "organization_alias": "my-secret-org",
 *     "models": ["model1", "model2"],
 *     "budget_id": "428eeaa8-f3ac-4e85-a8fb-7dc8d7aa8689"
 * }'
 * ```
 */
export const newOrganizationOrganizationNewPost = (
  variables: NewOrganizationOrganizationNewPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.NewOrganizationResponse,
    NewOrganizationOrganizationNewPostError,
    Schemas.NewOrganizationRequest,
    {},
    {},
    {}
  >({ url: '/organization/new', method: 'post', ...variables, signal });

export type UpdateOrganizationOrganizationUpdatePatchError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UpdateOrganizationOrganizationUpdatePatchVariables = {
  body?: Schemas.LiteLLMOrganizationTableUpdate;
} & FetcherExtraProps;

/**
 * Update an organization
 */
export const updateOrganizationOrganizationUpdatePatch = (
  variables: UpdateOrganizationOrganizationUpdatePatchVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.LiteLLMOrganizationTableWithMembers,
    UpdateOrganizationOrganizationUpdatePatchError,
    Schemas.LiteLLMOrganizationTableUpdate,
    {},
    {},
    {}
  >({ url: '/organization/update', method: 'patch', ...variables, signal });

export type DeleteOrganizationOrganizationDeleteDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteOrganizationOrganizationDeleteDeleteResponse = Schemas.LiteLLMOrganizationTableWithMembers[];

export type DeleteOrganizationOrganizationDeleteDeleteVariables = {
  body: Schemas.DeleteOrganizationRequest;
} & FetcherExtraProps;

/**
 * Delete an organization
 *
 * # Parameters:
 *
 * - organization_ids: List[str] - The organization ids to delete.
 */
export const deleteOrganizationOrganizationDeleteDelete = (
  variables: DeleteOrganizationOrganizationDeleteDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteOrganizationOrganizationDeleteDeleteResponse,
    DeleteOrganizationOrganizationDeleteDeleteError,
    Schemas.DeleteOrganizationRequest,
    {},
    {},
    {}
  >({ url: '/organization/delete', method: 'delete', ...variables, signal });

export type ListOrganizationOrganizationListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListOrganizationOrganizationListGetResponse = Schemas.LiteLLMOrganizationTableWithMembers[];

export type ListOrganizationOrganizationListGetVariables = FetcherExtraProps;

/**
 * ```
 * curl --location --request GET 'http://0.0.0.0:4000/organization/list'         --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const listOrganizationOrganizationListGet = (
  variables: ListOrganizationOrganizationListGetVariables,
  signal?: AbortSignal
) =>
  fetch<ListOrganizationOrganizationListGetResponse, ListOrganizationOrganizationListGetError, undefined, {}, {}, {}>({
    url: '/organization/list',
    method: 'get',
    ...variables,
    signal
  });

export type InfoOrganizationOrganizationInfoGetQueryParams = {
  organization_id: string;
};

export type InfoOrganizationOrganizationInfoGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type InfoOrganizationOrganizationInfoGetVariables = {
  queryParams: InfoOrganizationOrganizationInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Get the org specific information
 */
export const infoOrganizationOrganizationInfoGet = (
  variables: InfoOrganizationOrganizationInfoGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.LiteLLMOrganizationTableWithMembers,
    InfoOrganizationOrganizationInfoGetError,
    undefined,
    {},
    InfoOrganizationOrganizationInfoGetQueryParams,
    {}
  >({ url: '/organization/info', method: 'get', ...variables, signal });

export type DeprecatedInfoOrganizationOrganizationInfoPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeprecatedInfoOrganizationOrganizationInfoPostResponse = {
  [key: string]: any;
};

export type DeprecatedInfoOrganizationOrganizationInfoPostVariables = {
  body: Schemas.OrganizationRequest;
} & FetcherExtraProps;

/**
 * DEPRECATED: Use GET /organization/info instead
 */
export const deprecatedInfoOrganizationOrganizationInfoPost = (
  variables: DeprecatedInfoOrganizationOrganizationInfoPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeprecatedInfoOrganizationOrganizationInfoPostResponse,
    DeprecatedInfoOrganizationOrganizationInfoPostError,
    Schemas.OrganizationRequest,
    {},
    {},
    {}
  >({ url: '/organization/info', method: 'post', ...variables, signal });

export type OrganizationMemberAddOrganizationMemberAddPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type OrganizationMemberAddOrganizationMemberAddPostVariables = {
  body: Schemas.OrganizationMemberAddRequest;
} & FetcherExtraProps;

/**
 * [BETA]
 *
 * Add new members (either via user_email or user_id) to an organization
 *
 * If user doesn't exist, new user row will also be added to User Table
 *
 * Only proxy_admin or org_admin of organization, allowed to access this endpoint.
 *
 * # Parameters:
 *
 * - organization_id: str (required)
 * - member: Union[List[Member], Member] (required)
 *     - role: Literal[LitellmUserRoles] (required)
 *     - user_id: Optional[str]
 *     - user_email: Optional[str]
 *
 * Note: Either user_id or user_email must be provided for each member.
 *
 * Example:
 * ```
 * curl -X POST 'http://0.0.0.0:4000/organization/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{
 *     "organization_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",
 *     "member": {
 *         "role": "internal_user",
 *         "user_id": "krrish247652@berri.ai"
 *     },
 *     "max_budget_in_organization": 100.0
 * }'
 * ```
 *
 * The following is executed in this function:
 *
 * 1. Check if organization exists
 * 2. Creates a new Internal User if the user_id or user_email is not found in LiteLLM_UserTable
 * 3. Add Internal User to the `LiteLLM_OrganizationMembership` table
 */
export const organizationMemberAddOrganizationMemberAddPost = (
  variables: OrganizationMemberAddOrganizationMemberAddPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.OrganizationAddMemberResponse,
    OrganizationMemberAddOrganizationMemberAddPostError,
    Schemas.OrganizationMemberAddRequest,
    {},
    {},
    {}
  >({ url: '/organization/member_add', method: 'post', ...variables, signal });

export type OrganizationMemberUpdateOrganizationMemberUpdatePatchError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type OrganizationMemberUpdateOrganizationMemberUpdatePatchVariables = {
  body: Schemas.OrganizationMemberUpdateRequest;
} & FetcherExtraProps;

/**
 * Update a member's role in an organization
 */
export const organizationMemberUpdateOrganizationMemberUpdatePatch = (
  variables: OrganizationMemberUpdateOrganizationMemberUpdatePatchVariables,
  signal?: AbortSignal
) =>
  fetch<
    Schemas.LiteLLMOrganizationMembershipTable,
    OrganizationMemberUpdateOrganizationMemberUpdatePatchError,
    Schemas.OrganizationMemberUpdateRequest,
    {},
    {},
    {}
  >({ url: '/organization/member_update', method: 'patch', ...variables, signal });

export type OrganizationMemberDeleteOrganizationMemberDeleteDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type OrganizationMemberDeleteOrganizationMemberDeleteDeleteResponse = {
  [key: string]: any;
};

export type OrganizationMemberDeleteOrganizationMemberDeleteDeleteVariables = {
  body: Schemas.OrganizationMemberDeleteRequest;
} & FetcherExtraProps;

/**
 * Delete a member from an organization
 */
export const organizationMemberDeleteOrganizationMemberDeleteDelete = (
  variables: OrganizationMemberDeleteOrganizationMemberDeleteDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    OrganizationMemberDeleteOrganizationMemberDeleteDeleteResponse,
    OrganizationMemberDeleteOrganizationMemberDeleteDeleteError,
    Schemas.OrganizationMemberDeleteRequest,
    {},
    {},
    {}
  >({ url: '/organization/member_delete', method: 'delete', ...variables, signal });

export type BlockUserCustomerBlockPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type BlockUserCustomerBlockPostResponse = {
  [key: string]: any;
};

export type BlockUserCustomerBlockPostVariables = {
  body: Schemas.BlockUsers;
} & FetcherExtraProps;

/**
 * [BETA] Reject calls with this end-user id
 *
 * Parameters:
 * - user_ids (List[str], required): The unique `user_id`s for the users to block
 *
 *     (any /chat/completion call with this user={end-user-id} param, will be rejected.)
 *
 *     ```
 *     curl -X POST "http://0.0.0.0:8000/user/block"
 *     -H "Authorization: Bearer sk-1234"
 *     -d '{
 *     "user_ids": [<user_id>, ...]
 *     }'
 *     ```
 */
export const blockUserCustomerBlockPost = (variables: BlockUserCustomerBlockPostVariables, signal?: AbortSignal) =>
  fetch<BlockUserCustomerBlockPostResponse, BlockUserCustomerBlockPostError, Schemas.BlockUsers, {}, {}, {}>({
    url: '/customer/block',
    method: 'post',
    ...variables,
    signal
  });

export type UnblockUserCustomerUnblockPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UnblockUserCustomerUnblockPostResponse = {
  [key: string]: any;
};

export type UnblockUserCustomerUnblockPostVariables = {
  body: Schemas.BlockUsers;
} & FetcherExtraProps;

/**
 * [BETA] Unblock calls with this user id
 *
 * Example
 * ```
 * curl -X POST "http://0.0.0.0:8000/user/unblock"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "user_ids": [<user_id>, ...]
 * }'
 * ```
 */
export const unblockUserCustomerUnblockPost = (
  variables: UnblockUserCustomerUnblockPostVariables,
  signal?: AbortSignal
) =>
  fetch<UnblockUserCustomerUnblockPostResponse, UnblockUserCustomerUnblockPostError, Schemas.BlockUsers, {}, {}, {}>({
    url: '/customer/unblock',
    method: 'post',
    ...variables,
    signal
  });

export type NewEndUserCustomerNewPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type NewEndUserCustomerNewPostResponse = {
  [key: string]: any;
};

export type NewEndUserCustomerNewPostVariables = {
  body: Schemas.NewCustomerRequest;
} & FetcherExtraProps;

/**
 * Allow creating a new Customer
 *
 *
 * Parameters:
 * - user_id: str - The unique identifier for the user.
 * - alias: Optional[str] - A human-friendly alias for the user.
 * - blocked: bool - Flag to allow or disallow requests for this end-user. Default is False.
 * - max_budget: Optional[float] - The maximum budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.
 * - budget_id: Optional[str] - The identifier for an existing budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.
 * - allowed_model_region: Optional[Union[Literal["eu"], Literal["us"]]] - Require all user requests to use models in this specific region.
 * - default_model: Optional[str] - If no equivalent model in the allowed region, default all requests to this model.
 * - metadata: Optional[dict] = Metadata for customer, store information for customer. Example metadata = {"data_training_opt_out": True}
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - tpm_limit: Optional[int] - [Not Implemented Yet] Specify tpm limit for a given customer (Tokens per minute)
 * - rpm_limit: Optional[int] - [Not Implemented Yet] Specify rpm limit for a given customer (Requests per minute)
 * - model_max_budget: Optional[dict] - [Not Implemented Yet] Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d"}}
 * - max_parallel_requests: Optional[int] - [Not Implemented Yet] Specify max parallel requests for a given customer.
 * - soft_budget: Optional[float] - [Not Implemented Yet] Get alerts when customer crosses given budget, doesn't block requests.
 *
 *
 * - Allow specifying allowed regions
 * - Allow specifying default model
 *
 * Example curl:
 * ```
 * curl --location 'http://0.0.0.0:4000/customer/new'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 *         "user_id" : "ishaan-jaff-3",
 *         "allowed_region": "eu",
 *         "budget_id": "free_tier",
 *         "default_model": "azure/gpt-3.5-turbo-eu" <- all calls from this user, use this model?
 *     }'
 *
 *     # return end-user object
 * ```
 *
 * NOTE: This used to be called `/end_user/new`, we will still be maintaining compatibility for /end_user/XXX for these endpoints
 */
export const newEndUserCustomerNewPost = (variables: NewEndUserCustomerNewPostVariables, signal?: AbortSignal) =>
  fetch<NewEndUserCustomerNewPostResponse, NewEndUserCustomerNewPostError, Schemas.NewCustomerRequest, {}, {}, {}>({
    url: '/customer/new',
    method: 'post',
    ...variables,
    signal
  });

export type EndUserInfoCustomerInfoGetQueryParams = {
  /**
   * End User ID in the request parameters
   */
  end_user_id: string;
};

export type EndUserInfoCustomerInfoGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type EndUserInfoCustomerInfoGetVariables = {
  queryParams: EndUserInfoCustomerInfoGetQueryParams;
} & FetcherExtraProps;

/**
 * Get information about an end-user. An `end_user` is a customer (external user) of the proxy.
 *
 * Parameters:
 * - end_user_id (str, required): The unique identifier for the end-user
 *
 * Example curl:
 * ```
 * curl -X GET 'http://localhost:4000/customer/info?end_user_id=test-litellm-user-4'         -H 'Authorization: Bearer sk-1234'
 * ```
 */
export const endUserInfoCustomerInfoGet = (variables: EndUserInfoCustomerInfoGetVariables, signal?: AbortSignal) =>
  fetch<
    Schemas.LiteLLMEndUserTable,
    EndUserInfoCustomerInfoGetError,
    undefined,
    {},
    EndUserInfoCustomerInfoGetQueryParams,
    {}
  >({ url: '/customer/info', method: 'get', ...variables, signal });

export type UpdateEndUserCustomerUpdatePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UpdateEndUserCustomerUpdatePostResponse = {
  [key: string]: any;
};

export type UpdateEndUserCustomerUpdatePostVariables = {
  body: Schemas.UpdateCustomerRequest;
} & FetcherExtraProps;

/**
 * Example curl
 *
 * Parameters:
 * - user_id: str
 * - alias: Optional[str] = None  # human-friendly alias
 * - blocked: bool = False  # allow/disallow requests for this end-user
 * - max_budget: Optional[float] = None
 * - budget_id: Optional[str] = None  # give either a budget_id or max_budget
 * - allowed_model_region: Optional[AllowedModelRegion] = (
 *     None  # require all user requests to use models in this specific region
 * )
 * - default_model: Optional[str] = (
 *     None  # if no equivalent model in allowed region - default all requests to this model
 * )
 *
 * Example curl:
 * ```
 * curl --location 'http://0.0.0.0:4000/customer/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 *     "user_id": "test-litellm-user-4",
 *     "budget_id": "paid_tier"
 * }'
 *
 * See below for all params
 * ```
 */
export const updateEndUserCustomerUpdatePost = (
  variables: UpdateEndUserCustomerUpdatePostVariables,
  signal?: AbortSignal
) =>
  fetch<
    UpdateEndUserCustomerUpdatePostResponse,
    UpdateEndUserCustomerUpdatePostError,
    Schemas.UpdateCustomerRequest,
    {},
    {},
    {}
  >({ url: '/customer/update', method: 'post', ...variables, signal });

export type DeleteEndUserCustomerDeletePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteEndUserCustomerDeletePostResponse = {
  [key: string]: any;
};

export type DeleteEndUserCustomerDeletePostVariables = {
  body: Schemas.DeleteCustomerRequest;
} & FetcherExtraProps;

/**
 * Delete multiple end-users.
 *
 * Parameters:
 * - user_ids (List[str], required): The unique `user_id`s for the users to delete
 *
 * Example curl:
 * ```
 * curl --location 'http://0.0.0.0:4000/customer/delete'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 *         "user_ids" :["ishaan-jaff-5"]
 * }'
 *
 * See below for all params
 * ```
 */
export const deleteEndUserCustomerDeletePost = (
  variables: DeleteEndUserCustomerDeletePostVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteEndUserCustomerDeletePostResponse,
    DeleteEndUserCustomerDeletePostError,
    Schemas.DeleteCustomerRequest,
    {},
    {},
    {}
  >({ url: '/customer/delete', method: 'post', ...variables, signal });

export type ListEndUserCustomerListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListEndUserCustomerListGetResponse = Schemas.LiteLLMEndUserTable[];

export type ListEndUserCustomerListGetVariables = FetcherExtraProps;

/**
 * [Admin-only] List all available customers
 *
 * Example curl:
 * ```
 * curl --location --request GET 'http://0.0.0.0:4000/customer/list'         --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const listEndUserCustomerListGet = (variables: ListEndUserCustomerListGetVariables, signal?: AbortSignal) =>
  fetch<ListEndUserCustomerListGetResponse, ListEndUserCustomerListGetError, undefined, {}, {}, {}>({
    url: '/customer/list',
    method: 'get',
    ...variables,
    signal
  });

export type ViewSpendTagsSpendTagsGetQueryParams = {
  /**
   * Time from which to start viewing key spend
   */
  start_date?: string | null;
  /**
   * Time till which to view key spend
   */
  end_date?: string | null;
};

export type ViewSpendTagsSpendTagsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ViewSpendTagsSpendTagsGetResponse = Schemas.LiteLLMSpendLogs[];

export type ViewSpendTagsSpendTagsGetVariables = {
  queryParams?: ViewSpendTagsSpendTagsGetQueryParams;
} & FetcherExtraProps;

/**
 * LiteLLM Enterprise - View Spend Per Request Tag
 *
 * Example Request:
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/tags" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Spend with Start Date and End Date
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const viewSpendTagsSpendTagsGet = (variables: ViewSpendTagsSpendTagsGetVariables, signal?: AbortSignal) =>
  fetch<
    ViewSpendTagsSpendTagsGetResponse,
    ViewSpendTagsSpendTagsGetError,
    undefined,
    {},
    ViewSpendTagsSpendTagsGetQueryParams,
    {}
  >({ url: '/spend/tags', method: 'get', ...variables, signal });

export type GetGlobalSpendReportGlobalSpendReportGetQueryParams = {
  /**
   * Time from which to start viewing spend
   */
  start_date?: string | null;
  /**
   * Time till which to view spend
   */
  end_date?: string | null;
  /**
   * Group spend by internal team or customer or api_key
   *
   * @default team
   */
  group_by?: ('team' | 'customer' | 'api_key') | null;
  /**
   * View spend for a specific api_key. Example api_key='sk-1234
   */
  api_key?: string | null;
  /**
   * View spend for a specific internal_user_id. Example internal_user_id='1234
   */
  internal_user_id?: string | null;
  /**
   * View spend for a specific team_id. Example team_id='1234
   */
  team_id?: string | null;
  /**
   * View spend for a specific customer_id. Example customer_id='1234. Can be used in conjunction with team_id as well.
   */
  customer_id?: string | null;
};

export type GetGlobalSpendReportGlobalSpendReportGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetGlobalSpendReportGlobalSpendReportGetResponse = Schemas.LiteLLMSpendLogs[];

export type GetGlobalSpendReportGlobalSpendReportGetVariables = {
  queryParams?: GetGlobalSpendReportGlobalSpendReportGetQueryParams;
} & FetcherExtraProps;

/**
 * Get Daily Spend per Team, based on specific startTime and endTime. Per team, view usage by each key, model
 * [
 *     {
 *         "group-by-day": "2024-05-10",
 *         "teams": [
 *             {
 *                 "team_name": "team-1"
 *                 "spend": 10,
 *                 "keys": [
 *                     "key": "1213",
 *                     "usage": {
 *                         "model-1": {
 *                                 "cost": 12.50,
 *                                 "input_tokens": 1000,
 *                                 "output_tokens": 5000,
 *                                 "requests": 100
 *                             },
 *                             "audio-modelname1": {
 *                             "cost": 25.50,
 *                             "seconds": 25,
 *                             "requests": 50
 *                     },
 *                     }
 *                 }
 *         ]
 *     ]
 * }
 */
export const getGlobalSpendReportGlobalSpendReportGet = (
  variables: GetGlobalSpendReportGlobalSpendReportGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetGlobalSpendReportGlobalSpendReportGetResponse,
    GetGlobalSpendReportGlobalSpendReportGetError,
    undefined,
    {},
    GetGlobalSpendReportGlobalSpendReportGetQueryParams,
    {}
  >({ url: '/global/spend/report', method: 'get', ...variables, signal });

export type GlobalViewSpendTagsGlobalSpendTagsGetQueryParams = {
  /**
   * Time from which to start viewing key spend
   */
  start_date?: string | null;
  /**
   * Time till which to view key spend
   */
  end_date?: string | null;
  /**
   * comman separated tags to filter on
   */
  tags?: string | null;
};

export type GlobalViewSpendTagsGlobalSpendTagsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GlobalViewSpendTagsGlobalSpendTagsGetResponse = Schemas.LiteLLMSpendLogs[];

export type GlobalViewSpendTagsGlobalSpendTagsGetVariables = {
  queryParams?: GlobalViewSpendTagsGlobalSpendTagsGetQueryParams;
} & FetcherExtraProps;

/**
 * LiteLLM Enterprise - View Spend Per Request Tag. Used by LiteLLM UI
 *
 * Example Request:
 * ```
 * curl -X GET "http://0.0.0.0:4000/spend/tags" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Spend with Start Date and End Date
 * ```
 * curl -X GET "http://0.0.0.0:4000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const globalViewSpendTagsGlobalSpendTagsGet = (
  variables: GlobalViewSpendTagsGlobalSpendTagsGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GlobalViewSpendTagsGlobalSpendTagsGetResponse,
    GlobalViewSpendTagsGlobalSpendTagsGetError,
    undefined,
    {},
    GlobalViewSpendTagsGlobalSpendTagsGetQueryParams,
    {}
  >({ url: '/global/spend/tags', method: 'get', ...variables, signal });

export type CalculateSpendSpendCalculatePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CalculateSpendSpendCalculatePostResponse = {
  [key: string]: any;
};

export type CalculateSpendSpendCalculatePostVariables = {
  body?: Schemas.SpendCalculateRequest;
} & FetcherExtraProps;

/**
 * Accepts all the params of completion_cost.
 *
 * Calculate spend **before** making call:
 *
 * Note: If you see a spend of $0.0 you need to set custom_pricing for your model: https://docs.litellm.ai/docs/proxy/custom_pricing
 *
 * ```
 * curl --location 'http://localhost:4000/spend/calculate'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 *     "model": "anthropic.claude-v2",
 *     "messages": [{"role": "user", "content": "Hey, how'''s it going?"}]
 * }'
 * ```
 *
 * Calculate spend **after** making call:
 *
 * ```
 * curl --location 'http://localhost:4000/spend/calculate'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 *     "completion_response": {
 *         "id": "chatcmpl-123",
 *         "object": "chat.completion",
 *         "created": 1677652288,
 *         "model": "gpt-3.5-turbo-0125",
 *         "system_fingerprint": "fp_44709d6fcb",
 *         "choices": [{
 *             "index": 0,
 *             "message": {
 *                 "role": "assistant",
 *                 "content": "Hello there, how may I assist you today?"
 *             },
 *             "logprobs": null,
 *             "finish_reason": "stop"
 *         }]
 *         "usage": {
 *             "prompt_tokens": 9,
 *             "completion_tokens": 12,
 *             "total_tokens": 21
 *         }
 *     }
 * }'
 * ```
 */
export const calculateSpendSpendCalculatePost = (
  variables: CalculateSpendSpendCalculatePostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CalculateSpendSpendCalculatePostResponse,
    CalculateSpendSpendCalculatePostError,
    Schemas.SpendCalculateRequest,
    {},
    {},
    {}
  >({ url: '/spend/calculate', method: 'post', ...variables, signal });

export type ViewSpendLogsSpendLogsGetQueryParams = {
  /**
   * Get spend logs based on api key
   */
  api_key?: string | null;
  /**
   * Get spend logs based on user_id
   */
  user_id?: string | null;
  /**
   * request_id to get spend logs for specific request_id. If none passed then pass spend logs for all requests
   */
  request_id?: string | null;
  /**
   * Time from which to start viewing key spend
   */
  start_date?: string | null;
  /**
   * Time till which to view key spend
   */
  end_date?: string | null;
};

export type ViewSpendLogsSpendLogsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ViewSpendLogsSpendLogsGetResponse = Schemas.LiteLLMSpendLogs[];

export type ViewSpendLogsSpendLogsGetVariables = {
  queryParams?: ViewSpendLogsSpendLogsGetQueryParams;
} & FetcherExtraProps;

/**
 * View all spend logs, if request_id is provided, only logs for that request_id will be returned
 *
 * Example Request for all logs
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for specific request_id
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?request_id=chatcmpl-6dcb2540-d3d7-4e49-bb27-291f863f112e" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for specific api_key
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?api_key=sk-Fn8Ej39NkBQmUagFEoUWPQ" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for specific user_id
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?user_id=ishaan@berri.ai" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const viewSpendLogsSpendLogsGet = (variables: ViewSpendLogsSpendLogsGetVariables, signal?: AbortSignal) =>
  fetch<
    ViewSpendLogsSpendLogsGetResponse,
    ViewSpendLogsSpendLogsGetError,
    undefined,
    {},
    ViewSpendLogsSpendLogsGetQueryParams,
    {}
  >({ url: '/spend/logs', method: 'get', ...variables, signal });

export type GlobalSpendResetGlobalSpendResetPostError = Fetcher.ErrorWrapper<undefined>;

export type GlobalSpendResetGlobalSpendResetPostResponse = {
  [key: string]: any;
};

export type GlobalSpendResetGlobalSpendResetPostVariables = FetcherExtraProps;

/**
 * ADMIN ONLY / MASTER KEY Only Endpoint
 *
 * Globally reset spend for All API Keys and Teams, maintain LiteLLM_SpendLogs
 *
 * 1. LiteLLM_SpendLogs will maintain the logs on spend, no data gets deleted from there
 * 2. LiteLLM_VerificationTokens spend will be set = 0
 * 3. LiteLLM_TeamTable spend will be set = 0
 */
export const globalSpendResetGlobalSpendResetPost = (
  variables: GlobalSpendResetGlobalSpendResetPostVariables,
  signal?: AbortSignal
) =>
  fetch<GlobalSpendResetGlobalSpendResetPostResponse, GlobalSpendResetGlobalSpendResetPostError, undefined, {}, {}, {}>(
    { url: '/global/spend/reset', method: 'post', ...variables, signal }
  );

export type ProviderBudgetsProviderBudgetsGetError = Fetcher.ErrorWrapper<undefined>;

export type ProviderBudgetsProviderBudgetsGetVariables = FetcherExtraProps;

/**
 * Provider Budget Routing - Get Budget, Spend Details https://docs.litellm.ai/docs/proxy/provider_budget_routing
 *
 * Use this endpoint to check current budget, spend and budget reset time for a provider
 *
 * Example Request
 *
 * ```bash
 * curl -X GET http://localhost:4000/provider/budgets     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Response
 *
 * ```json
 * {
 *     "providers": {
 *         "openai": {
 *             "budget_limit": 1e-12,
 *             "time_period": "1d",
 *             "spend": 0.0,
 *             "budget_reset_at": null
 *         },
 *         "azure": {
 *             "budget_limit": 100.0,
 *             "time_period": "1d",
 *             "spend": 0.0,
 *             "budget_reset_at": null
 *         },
 *         "anthropic": {
 *             "budget_limit": 100.0,
 *             "time_period": "10d",
 *             "spend": 0.0,
 *             "budget_reset_at": null
 *         },
 *         "vertex_ai": {
 *             "budget_limit": 100.0,
 *             "time_period": "12d",
 *             "spend": 0.0,
 *             "budget_reset_at": null
 *         }
 *     }
 * }
 * ```
 */
export const providerBudgetsProviderBudgetsGet = (
  variables: ProviderBudgetsProviderBudgetsGetVariables,
  signal?: AbortSignal
) =>
  fetch<Schemas.ProviderBudgetResponse, ProviderBudgetsProviderBudgetsGetError, undefined, {}, {}, {}>({
    url: '/provider/budgets',
    method: 'get',
    ...variables,
    signal
  });

export type CachePingCachePingGetError = Fetcher.ErrorWrapper<undefined>;

export type CachePingCachePingGetVariables = FetcherExtraProps;

/**
 * Endpoint for checking if cache can be pinged
 */
export const cachePingCachePingGet = (variables: CachePingCachePingGetVariables, signal?: AbortSignal) =>
  fetch<Schemas.CachePingResponse, CachePingCachePingGetError, undefined, {}, {}, {}>({
    url: '/cache/ping',
    method: 'get',
    ...variables,
    signal
  });

export type CacheDeleteCacheDeletePostError = Fetcher.ErrorWrapper<undefined>;

export type CacheDeleteCacheDeletePostResponse = {
  [key: string]: any;
};

export type CacheDeleteCacheDeletePostVariables = FetcherExtraProps;

/**
 * Endpoint for deleting a key from the cache. All responses from litellm proxy have `x-litellm-cache-key` in the headers
 *
 * Parameters:
 * - **keys**: *Optional[List[str]]* - A list of keys to delete from the cache. Example {"keys": ["key1", "key2"]}
 *
 * ```shell
 * curl -X POST "http://0.0.0.0:4000/cache/delete"     -H "Authorization: Bearer sk-1234"     -d '{"keys": ["key1", "key2"]}'
 * ```
 */
export const cacheDeleteCacheDeletePost = (variables: CacheDeleteCacheDeletePostVariables, signal?: AbortSignal) =>
  fetch<CacheDeleteCacheDeletePostResponse, CacheDeleteCacheDeletePostError, undefined, {}, {}, {}>({
    url: '/cache/delete',
    method: 'post',
    ...variables,
    signal
  });

export type CacheRedisInfoCacheRedisInfoGetError = Fetcher.ErrorWrapper<undefined>;

export type CacheRedisInfoCacheRedisInfoGetResponse = {
  [key: string]: any;
};

export type CacheRedisInfoCacheRedisInfoGetVariables = FetcherExtraProps;

/**
 * Endpoint for getting /redis/info
 */
export const cacheRedisInfoCacheRedisInfoGet = (
  variables: CacheRedisInfoCacheRedisInfoGetVariables,
  signal?: AbortSignal
) =>
  fetch<CacheRedisInfoCacheRedisInfoGetResponse, CacheRedisInfoCacheRedisInfoGetError, undefined, {}, {}, {}>({
    url: '/cache/redis/info',
    method: 'get',
    ...variables,
    signal
  });

export type CacheFlushallCacheFlushallPostError = Fetcher.ErrorWrapper<undefined>;

export type CacheFlushallCacheFlushallPostResponse = {
  [key: string]: any;
};

export type CacheFlushallCacheFlushallPostVariables = FetcherExtraProps;

/**
 * A function to flush all items from the cache. (All items will be deleted from the cache with this)
 * Raises HTTPException if the cache is not initialized or if the cache type does not support flushing.
 * Returns a dictionary with the status of the operation.
 *
 * Usage:
 * ```
 * curl -X POST http://0.0.0.0:4000/cache/flushall -H "Authorization: Bearer sk-1234"
 * ```
 */
export const cacheFlushallCacheFlushallPost = (
  variables: CacheFlushallCacheFlushallPostVariables,
  signal?: AbortSignal
) =>
  fetch<CacheFlushallCacheFlushallPostResponse, CacheFlushallCacheFlushallPostError, undefined, {}, {}, {}>({
    url: '/cache/flushall',
    method: 'post',
    ...variables,
    signal
  });

export type ListGuardrailsGuardrailsListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListGuardrailsGuardrailsListGetVariables = FetcherExtraProps;

/**
 * List the guardrails that are available on the proxy server
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/guardrails/list" -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 *     "guardrails": [
 *         {
 *         "guardrail_name": "bedrock-pre-guard",
 *         "guardrail_info": {
 *             "params": [
 *             {
 *                 "name": "toxicity_score",
 *                 "type": "float",
 *                 "description": "Score between 0-1 indicating content toxicity level"
 *             },
 *             {
 *                 "name": "pii_detection",
 *                 "type": "boolean"
 *             }
 *             ]
 *         }
 *         }
 *     ]
 * }
 * ```
 */
export const listGuardrailsGuardrailsListGet = (
  variables: ListGuardrailsGuardrailsListGetVariables,
  signal?: AbortSignal
) =>
  fetch<Schemas.ListGuardrailsResponse, ListGuardrailsGuardrailsListGetError, undefined, {}, {}, {}>({
    url: '/guardrails/list',
    method: 'get',
    ...variables,
    signal
  });

export type AddAllowedIpAddAllowedIpPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type AddAllowedIpAddAllowedIpPostResponse = {
  [key: string]: any;
};

export type AddAllowedIpAddAllowedIpPostVariables = {
  body: Schemas.IPAddress;
} & FetcherExtraProps;

export const addAllowedIpAddAllowedIpPost = (variables: AddAllowedIpAddAllowedIpPostVariables, signal?: AbortSignal) =>
  fetch<AddAllowedIpAddAllowedIpPostResponse, AddAllowedIpAddAllowedIpPostError, Schemas.IPAddress, {}, {}, {}>({
    url: '/add/allowed_ip',
    method: 'post',
    ...variables,
    signal
  });

export type DeleteAllowedIpDeleteAllowedIpPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteAllowedIpDeleteAllowedIpPostResponse = {
  [key: string]: any;
};

export type DeleteAllowedIpDeleteAllowedIpPostVariables = {
  body: Schemas.IPAddress;
} & FetcherExtraProps;

export const deleteAllowedIpDeleteAllowedIpPost = (
  variables: DeleteAllowedIpDeleteAllowedIpPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteAllowedIpDeleteAllowedIpPostResponse,
    DeleteAllowedIpDeleteAllowedIpPostError,
    Schemas.IPAddress,
    {},
    {},
    {}
  >({ url: '/delete/allowed_ip', method: 'post', ...variables, signal });

export type GetSsoSettingsGetInternalUserSettingsGetError = Fetcher.ErrorWrapper<undefined>;

export type GetSsoSettingsGetInternalUserSettingsGetResponse = {
  [key: string]: any;
};

export type GetSsoSettingsGetInternalUserSettingsGetVariables = FetcherExtraProps;

/**
 * Get all SSO settings from the litellm_settings configuration.
 * Returns a structured object with values and descriptions for UI display.
 */
export const getSsoSettingsGetInternalUserSettingsGet = (
  variables: GetSsoSettingsGetInternalUserSettingsGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetSsoSettingsGetInternalUserSettingsGetResponse,
    GetSsoSettingsGetInternalUserSettingsGetError,
    undefined,
    {},
    {},
    {}
  >({ url: '/get/internal_user_settings', method: 'get', ...variables, signal });

export type UpdateInternalUserSettingsUpdateInternalUserSettingsPatchError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UpdateInternalUserSettingsUpdateInternalUserSettingsPatchVariables = {
  body?: Schemas.DefaultInternalUserParams;
} & FetcherExtraProps;

/**
 * Update the default internal user parameters for SSO users.
 * These settings will be applied to new users who sign in via SSO.
 */
export const updateInternalUserSettingsUpdateInternalUserSettingsPatch = (
  variables: UpdateInternalUserSettingsUpdateInternalUserSettingsPatchVariables,
  signal?: AbortSignal
) =>
  fetch<
    void,
    UpdateInternalUserSettingsUpdateInternalUserSettingsPatchError,
    Schemas.DefaultInternalUserParams,
    {},
    {},
    {}
  >({ url: '/update/internal_user_settings', method: 'patch', ...variables, signal });

export type CreateFileFilesPostQueryParams = {
  provider?: string | null;
};

export type CreateFileFilesPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreateFileFilesPostResponse = {
  [key: string]: any;
};

export type CreateFileFilesPostVariables = {
  body: Schemas.BodyCreateFileFilesPost;
  queryParams?: CreateFileFilesPostQueryParams;
} & FetcherExtraProps;

/**
 * Upload a file that can be used across - Assistants API, Batch API
 * This is the equivalent of POST https://api.openai.com/v1/files
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/create
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"
 *
 * ```
 */
export const createFileFilesPost = (variables: CreateFileFilesPostVariables, signal?: AbortSignal) =>
  fetch<
    CreateFileFilesPostResponse,
    CreateFileFilesPostError,
    Schemas.BodyCreateFileFilesPost,
    {},
    CreateFileFilesPostQueryParams,
    {}
  >({ url: '/files', method: 'post', ...variables, signal });

export type ListFilesFilesGetQueryParams = {
  provider?: string | null;
  purpose?: string | null;
};

export type ListFilesFilesGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListFilesFilesGetResponse = {
  [key: string]: any;
};

export type ListFilesFilesGetVariables = {
  queryParams?: ListFilesFilesGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const listFilesFilesGet = (variables: ListFilesFilesGetVariables, signal?: AbortSignal) =>
  fetch<ListFilesFilesGetResponse, ListFilesFilesGetError, undefined, {}, ListFilesFilesGetQueryParams, {}>({
    url: '/files',
    method: 'get',
    ...variables,
    signal
  });

export type CreateFileV1FilesPostQueryParams = {
  provider?: string | null;
};

export type CreateFileV1FilesPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreateFileV1FilesPostResponse = {
  [key: string]: any;
};

export type CreateFileV1FilesPostVariables = {
  body: Schemas.BodyCreateFileV1FilesPost;
  queryParams?: CreateFileV1FilesPostQueryParams;
} & FetcherExtraProps;

/**
 * Upload a file that can be used across - Assistants API, Batch API
 * This is the equivalent of POST https://api.openai.com/v1/files
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/create
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"
 *
 * ```
 */
export const createFileV1FilesPost = (variables: CreateFileV1FilesPostVariables, signal?: AbortSignal) =>
  fetch<
    CreateFileV1FilesPostResponse,
    CreateFileV1FilesPostError,
    Schemas.BodyCreateFileV1FilesPost,
    {},
    CreateFileV1FilesPostQueryParams,
    {}
  >({ url: '/v1/files', method: 'post', ...variables, signal });

export type ListFilesV1FilesGetQueryParams = {
  provider?: string | null;
  purpose?: string | null;
};

export type ListFilesV1FilesGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListFilesV1FilesGetResponse = {
  [key: string]: any;
};

export type ListFilesV1FilesGetVariables = {
  queryParams?: ListFilesV1FilesGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const listFilesV1FilesGet = (variables: ListFilesV1FilesGetVariables, signal?: AbortSignal) =>
  fetch<ListFilesV1FilesGetResponse, ListFilesV1FilesGetError, undefined, {}, ListFilesV1FilesGetQueryParams, {}>({
    url: '/v1/files',
    method: 'get',
    ...variables,
    signal
  });

export type CreateFileProviderV1FilesPostPathParams = {
  provider: string | null;
};

export type CreateFileProviderV1FilesPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type CreateFileProviderV1FilesPostResponse = {
  [key: string]: any;
};

export type CreateFileProviderV1FilesPostVariables = {
  body: Schemas.BodyCreateFileProviderV1FilesPost;
  pathParams: CreateFileProviderV1FilesPostPathParams;
} & FetcherExtraProps;

/**
 * Upload a file that can be used across - Assistants API, Batch API
 * This is the equivalent of POST https://api.openai.com/v1/files
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/create
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"
 *
 * ```
 */
export const createFileProviderV1FilesPost = (
  variables: CreateFileProviderV1FilesPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    CreateFileProviderV1FilesPostResponse,
    CreateFileProviderV1FilesPostError,
    Schemas.BodyCreateFileProviderV1FilesPost,
    {},
    {},
    CreateFileProviderV1FilesPostPathParams
  >({ url: '/{provider}/v1/files', method: 'post', ...variables, signal });

export type ListFilesProviderV1FilesGetPathParams = {
  provider: string | null;
};

export type ListFilesProviderV1FilesGetQueryParams = {
  purpose?: string | null;
};

export type ListFilesProviderV1FilesGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type ListFilesProviderV1FilesGetResponse = {
  [key: string]: any;
};

export type ListFilesProviderV1FilesGetVariables = {
  pathParams: ListFilesProviderV1FilesGetPathParams;
  queryParams?: ListFilesProviderV1FilesGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const listFilesProviderV1FilesGet = (variables: ListFilesProviderV1FilesGetVariables, signal?: AbortSignal) =>
  fetch<
    ListFilesProviderV1FilesGetResponse,
    ListFilesProviderV1FilesGetError,
    undefined,
    {},
    ListFilesProviderV1FilesGetQueryParams,
    ListFilesProviderV1FilesGetPathParams
  >({ url: '/{provider}/v1/files', method: 'get', ...variables, signal });

export type GetFileContentFilesFileIdContentGetPathParams = {
  fileId: string;
};

export type GetFileContentFilesFileIdContentGetQueryParams = {
  provider?: string | null;
};

export type GetFileContentFilesFileIdContentGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetFileContentFilesFileIdContentGetResponse = {
  [key: string]: any;
};

export type GetFileContentFilesFileIdContentGetVariables = {
  pathParams: GetFileContentFilesFileIdContentGetPathParams;
  queryParams?: GetFileContentFilesFileIdContentGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileContentFilesFileIdContentGet = (
  variables: GetFileContentFilesFileIdContentGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetFileContentFilesFileIdContentGetResponse,
    GetFileContentFilesFileIdContentGetError,
    undefined,
    {},
    GetFileContentFilesFileIdContentGetQueryParams,
    GetFileContentFilesFileIdContentGetPathParams
  >({ url: '/files/{fileId}/content', method: 'get', ...variables, signal });

export type GetFileContentV1FilesFileIdContentGetPathParams = {
  fileId: string;
};

export type GetFileContentV1FilesFileIdContentGetQueryParams = {
  provider?: string | null;
};

export type GetFileContentV1FilesFileIdContentGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetFileContentV1FilesFileIdContentGetResponse = {
  [key: string]: any;
};

export type GetFileContentV1FilesFileIdContentGetVariables = {
  pathParams: GetFileContentV1FilesFileIdContentGetPathParams;
  queryParams?: GetFileContentV1FilesFileIdContentGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileContentV1FilesFileIdContentGet = (
  variables: GetFileContentV1FilesFileIdContentGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetFileContentV1FilesFileIdContentGetResponse,
    GetFileContentV1FilesFileIdContentGetError,
    undefined,
    {},
    GetFileContentV1FilesFileIdContentGetQueryParams,
    GetFileContentV1FilesFileIdContentGetPathParams
  >({ url: '/v1/files/{fileId}/content', method: 'get', ...variables, signal });

export type GetFileContentProviderV1FilesFileIdContentGetPathParams = {
  fileId: string;
  provider: string | null;
};

export type GetFileContentProviderV1FilesFileIdContentGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetFileContentProviderV1FilesFileIdContentGetResponse = {
  [key: string]: any;
};

export type GetFileContentProviderV1FilesFileIdContentGetVariables = {
  pathParams: GetFileContentProviderV1FilesFileIdContentGetPathParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileContentProviderV1FilesFileIdContentGet = (
  variables: GetFileContentProviderV1FilesFileIdContentGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetFileContentProviderV1FilesFileIdContentGetResponse,
    GetFileContentProviderV1FilesFileIdContentGetError,
    undefined,
    {},
    {},
    GetFileContentProviderV1FilesFileIdContentGetPathParams
  >({ url: '/{provider}/v1/files/{fileId}/content', method: 'get', ...variables, signal });

export type GetFileFilesFileIdGetPathParams = {
  fileId: string;
};

export type GetFileFilesFileIdGetQueryParams = {
  provider?: string | null;
};

export type GetFileFilesFileIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetFileFilesFileIdGetResponse = {
  [key: string]: any;
};

export type GetFileFilesFileIdGetVariables = {
  pathParams: GetFileFilesFileIdGetPathParams;
  queryParams?: GetFileFilesFileIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileFilesFileIdGet = (variables: GetFileFilesFileIdGetVariables, signal?: AbortSignal) =>
  fetch<
    GetFileFilesFileIdGetResponse,
    GetFileFilesFileIdGetError,
    undefined,
    {},
    GetFileFilesFileIdGetQueryParams,
    GetFileFilesFileIdGetPathParams
  >({ url: '/files/{fileId}', method: 'get', ...variables, signal });

export type DeleteFileFilesFileIdDeletePathParams = {
  fileId: string;
};

export type DeleteFileFilesFileIdDeleteQueryParams = {
  provider?: string | null;
};

export type DeleteFileFilesFileIdDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteFileFilesFileIdDeleteResponse = {
  [key: string]: any;
};

export type DeleteFileFilesFileIdDeleteVariables = {
  pathParams: DeleteFileFilesFileIdDeletePathParams;
  queryParams?: DeleteFileFilesFileIdDeleteQueryParams;
} & FetcherExtraProps;

/**
 * Deletes a specified file. that can be used across - Assistants API, Batch API
 * This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"
 *
 * ```
 */
export const deleteFileFilesFileIdDelete = (variables: DeleteFileFilesFileIdDeleteVariables, signal?: AbortSignal) =>
  fetch<
    DeleteFileFilesFileIdDeleteResponse,
    DeleteFileFilesFileIdDeleteError,
    undefined,
    {},
    DeleteFileFilesFileIdDeleteQueryParams,
    DeleteFileFilesFileIdDeletePathParams
  >({ url: '/files/{fileId}', method: 'delete', ...variables, signal });

export type GetFileV1FilesFileIdGetPathParams = {
  fileId: string;
};

export type GetFileV1FilesFileIdGetQueryParams = {
  provider?: string | null;
};

export type GetFileV1FilesFileIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetFileV1FilesFileIdGetResponse = {
  [key: string]: any;
};

export type GetFileV1FilesFileIdGetVariables = {
  pathParams: GetFileV1FilesFileIdGetPathParams;
  queryParams?: GetFileV1FilesFileIdGetQueryParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileV1FilesFileIdGet = (variables: GetFileV1FilesFileIdGetVariables, signal?: AbortSignal) =>
  fetch<
    GetFileV1FilesFileIdGetResponse,
    GetFileV1FilesFileIdGetError,
    undefined,
    {},
    GetFileV1FilesFileIdGetQueryParams,
    GetFileV1FilesFileIdGetPathParams
  >({ url: '/v1/files/{fileId}', method: 'get', ...variables, signal });

export type DeleteFileV1FilesFileIdDeletePathParams = {
  fileId: string;
};

export type DeleteFileV1FilesFileIdDeleteQueryParams = {
  provider?: string | null;
};

export type DeleteFileV1FilesFileIdDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteFileV1FilesFileIdDeleteResponse = {
  [key: string]: any;
};

export type DeleteFileV1FilesFileIdDeleteVariables = {
  pathParams: DeleteFileV1FilesFileIdDeletePathParams;
  queryParams?: DeleteFileV1FilesFileIdDeleteQueryParams;
} & FetcherExtraProps;

/**
 * Deletes a specified file. that can be used across - Assistants API, Batch API
 * This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"
 *
 * ```
 */
export const deleteFileV1FilesFileIdDelete = (
  variables: DeleteFileV1FilesFileIdDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteFileV1FilesFileIdDeleteResponse,
    DeleteFileV1FilesFileIdDeleteError,
    undefined,
    {},
    DeleteFileV1FilesFileIdDeleteQueryParams,
    DeleteFileV1FilesFileIdDeletePathParams
  >({ url: '/v1/files/{fileId}', method: 'delete', ...variables, signal });

export type GetFileProviderV1FilesFileIdGetPathParams = {
  fileId: string;
  provider: string | null;
};

export type GetFileProviderV1FilesFileIdGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetFileProviderV1FilesFileIdGetResponse = {
  [key: string]: any;
};

export type GetFileProviderV1FilesFileIdGetVariables = {
  pathParams: GetFileProviderV1FilesFileIdGetPathParams;
} & FetcherExtraProps;

/**
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileProviderV1FilesFileIdGet = (
  variables: GetFileProviderV1FilesFileIdGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetFileProviderV1FilesFileIdGetResponse,
    GetFileProviderV1FilesFileIdGetError,
    undefined,
    {},
    {},
    GetFileProviderV1FilesFileIdGetPathParams
  >({ url: '/{provider}/v1/files/{fileId}', method: 'get', ...variables, signal });

export type DeleteFileProviderV1FilesFileIdDeletePathParams = {
  fileId: string;
  provider: string | null;
};

export type DeleteFileProviderV1FilesFileIdDeleteError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteFileProviderV1FilesFileIdDeleteResponse = {
  [key: string]: any;
};

export type DeleteFileProviderV1FilesFileIdDeleteVariables = {
  pathParams: DeleteFileProviderV1FilesFileIdDeletePathParams;
} & FetcherExtraProps;

/**
 * Deletes a specified file. that can be used across - Assistants API, Batch API
 * This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"
 *
 * ```
 */
export const deleteFileProviderV1FilesFileIdDelete = (
  variables: DeleteFileProviderV1FilesFileIdDeleteVariables,
  signal?: AbortSignal
) =>
  fetch<
    DeleteFileProviderV1FilesFileIdDeleteResponse,
    DeleteFileProviderV1FilesFileIdDeleteError,
    undefined,
    {},
    {},
    DeleteFileProviderV1FilesFileIdDeletePathParams
  >({ url: '/{provider}/v1/files/{fileId}', method: 'delete', ...variables, signal });

export type AddTeamCallbacksTeamTeamIdCallbackPostPathParams = {
  teamId: string;
};

export type AddTeamCallbacksTeamTeamIdCallbackPostHeaders = {
  /**
   * The litellm-changed-by header enables tracking of actions performed by authorized users on behalf of other users, providing an audit trail for accountability
   */
  'litellm-changed-by'?: string | null;
};

export type AddTeamCallbacksTeamTeamIdCallbackPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type AddTeamCallbacksTeamTeamIdCallbackPostResponse = {
  [key: string]: any;
};

export type AddTeamCallbacksTeamTeamIdCallbackPostVariables = {
  body: Schemas.AddTeamCallback;
  headers?: AddTeamCallbacksTeamTeamIdCallbackPostHeaders;
  pathParams: AddTeamCallbacksTeamTeamIdCallbackPostPathParams;
} & FetcherExtraProps;

/**
 * Add a success/failure callback to a team
 *
 * Use this if if you want different teams to have different success/failure callbacks
 *
 * Parameters:
 * - callback_name (Literal["langfuse", "langsmith", "gcs"], required): The name of the callback to add
 * - callback_type (Literal["success", "failure", "success_and_failure"], required): The type of callback to add. One of:
 *     - "success": Callback for successful LLM calls
 *     - "failure": Callback for failed LLM calls
 *     - "success_and_failure": Callback for both successful and failed LLM calls
 * - callback_vars (StandardCallbackDynamicParams, required): A dictionary of variables to pass to the callback
 *     - langfuse_public_key: The public key for the Langfuse callback
 *     - langfuse_secret_key: The secret key for the Langfuse callback
 *     - langfuse_secret: The secret for the Langfuse callback
 *     - langfuse_host: The host for the Langfuse callback
 *     - gcs_bucket_name: The name of the GCS bucket
 *     - gcs_path_service_account: The path to the GCS service account
 *     - langsmith_api_key: The API key for the Langsmith callback
 *     - langsmith_project: The project for the Langsmith callback
 *     - langsmith_base_url: The base URL for the Langsmith callback
 *
 * Example curl:
 * ```
 * curl -X POST 'http:/localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Content-Type: application/json'         -H 'Authorization: Bearer sk-1234'         -d '{
 *     "callback_name": "langfuse",
 *     "callback_type": "success",
 *     "callback_vars": {"langfuse_public_key": "pk-lf-xxxx1", "langfuse_secret_key": "sk-xxxxx"}
 *
 * }'
 * ```
 *
 * This means for the team where team_id = dbe2f686-a686-4896-864a-4c3924458709, all LLM calls will be logged to langfuse using the public key pk-lf-xxxx1 and the secret key sk-xxxxx
 */
export const addTeamCallbacksTeamTeamIdCallbackPost = (
  variables: AddTeamCallbacksTeamTeamIdCallbackPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    AddTeamCallbacksTeamTeamIdCallbackPostResponse,
    AddTeamCallbacksTeamTeamIdCallbackPostError,
    Schemas.AddTeamCallback,
    AddTeamCallbacksTeamTeamIdCallbackPostHeaders,
    {},
    AddTeamCallbacksTeamTeamIdCallbackPostPathParams
  >({ url: '/team/{teamId}/callback', method: 'post', ...variables, signal });

export type GetTeamCallbacksTeamTeamIdCallbackGetPathParams = {
  teamId: string;
};

export type GetTeamCallbacksTeamTeamIdCallbackGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type GetTeamCallbacksTeamTeamIdCallbackGetResponse = {
  [key: string]: any;
};

export type GetTeamCallbacksTeamTeamIdCallbackGetVariables = {
  pathParams: GetTeamCallbacksTeamTeamIdCallbackGetPathParams;
} & FetcherExtraProps;

/**
 * Get the success/failure callbacks and variables for a team
 *
 * Parameters:
 * - team_id (str, required): The unique identifier for the team
 *
 * Example curl:
 * ```
 * curl -X GET 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Authorization: Bearer sk-1234'
 * ```
 *
 * This will return the callback settings for the team with id dbe2f686-a686-4896-864a-4c3924458709
 *
 * Returns {
 *         "status": "success",
 *         "data": {
 *             "team_id": team_id,
 *             "success_callbacks": team_callback_settings_obj.success_callback,
 *             "failure_callbacks": team_callback_settings_obj.failure_callback,
 *             "callback_vars": team_callback_settings_obj.callback_vars,
 *         },
 *     }
 */
export const getTeamCallbacksTeamTeamIdCallbackGet = (
  variables: GetTeamCallbacksTeamTeamIdCallbackGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    GetTeamCallbacksTeamTeamIdCallbackGetResponse,
    GetTeamCallbacksTeamTeamIdCallbackGetError,
    undefined,
    {},
    {},
    GetTeamCallbacksTeamTeamIdCallbackGetPathParams
  >({ url: '/team/{teamId}/callback', method: 'get', ...variables, signal });

export type DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams = {
  teamId: string;
};

export type DisableTeamLoggingTeamTeamIdDisableLoggingPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DisableTeamLoggingTeamTeamIdDisableLoggingPostResponse = {
  [key: string]: any;
};

export type DisableTeamLoggingTeamTeamIdDisableLoggingPostVariables = {
  pathParams: DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams;
} & FetcherExtraProps;

/**
 * Disable all logging callbacks for a team
 *
 * Parameters:
 * - team_id (str, required): The unique identifier for the team
 *
 * Example curl:
 * ```
 * curl -X POST 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/disable_logging'         -H 'Authorization: Bearer sk-1234'
 * ```
 */
export const disableTeamLoggingTeamTeamIdDisableLoggingPost = (
  variables: DisableTeamLoggingTeamTeamIdDisableLoggingPostVariables,
  signal?: AbortSignal
) =>
  fetch<
    DisableTeamLoggingTeamTeamIdDisableLoggingPostResponse,
    DisableTeamLoggingTeamTeamIdDisableLoggingPostError,
    undefined,
    {},
    {},
    DisableTeamLoggingTeamTeamIdDisableLoggingPostPathParams
  >({ url: '/team/{teamId}/disable_logging', method: 'post', ...variables, signal });

export type NewBudgetBudgetNewPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type NewBudgetBudgetNewPostResponse = {
  [key: string]: any;
};

export type NewBudgetBudgetNewPostVariables = {
  body?: Schemas.BudgetNewRequest;
} & FetcherExtraProps;

/**
 * Create a new budget object. Can apply this to teams, orgs, end-users, keys.
 *
 * Parameters:
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.
 * - max_budget: Optional[float] - The max budget for the budget.
 * - soft_budget: Optional[float] - The soft budget for the budget.
 * - max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.
 * - tpm_limit: Optional[int] - The tokens per minute limit for the budget.
 * - rpm_limit: Optional[int] - The requests per minute limit for the budget.
 * - model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}
 */
export const newBudgetBudgetNewPost = (variables: NewBudgetBudgetNewPostVariables, signal?: AbortSignal) =>
  fetch<NewBudgetBudgetNewPostResponse, NewBudgetBudgetNewPostError, Schemas.BudgetNewRequest, {}, {}, {}>({
    url: '/budget/new',
    method: 'post',
    ...variables,
    signal
  });

export type UpdateBudgetBudgetUpdatePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UpdateBudgetBudgetUpdatePostResponse = {
  [key: string]: any;
};

export type UpdateBudgetBudgetUpdatePostVariables = {
  body?: Schemas.BudgetNewRequest;
} & FetcherExtraProps;

/**
 * Update an existing budget object.
 *
 * Parameters:
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.
 * - max_budget: Optional[float] - The max budget for the budget.
 * - soft_budget: Optional[float] - The soft budget for the budget.
 * - max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.
 * - tpm_limit: Optional[int] - The tokens per minute limit for the budget.
 * - rpm_limit: Optional[int] - The requests per minute limit for the budget.
 * - model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}
 */
export const updateBudgetBudgetUpdatePost = (variables: UpdateBudgetBudgetUpdatePostVariables, signal?: AbortSignal) =>
  fetch<UpdateBudgetBudgetUpdatePostResponse, UpdateBudgetBudgetUpdatePostError, Schemas.BudgetNewRequest, {}, {}, {}>({
    url: '/budget/update',
    method: 'post',
    ...variables,
    signal
  });

export type InfoBudgetBudgetInfoPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type InfoBudgetBudgetInfoPostResponse = {
  [key: string]: any;
};

export type InfoBudgetBudgetInfoPostVariables = {
  body: Schemas.BudgetRequest;
} & FetcherExtraProps;

/**
 * Get the budget id specific information
 *
 * Parameters:
 * - budgets: List[str] - The list of budget ids to get information for
 */
export const infoBudgetBudgetInfoPost = (variables: InfoBudgetBudgetInfoPostVariables, signal?: AbortSignal) =>
  fetch<InfoBudgetBudgetInfoPostResponse, InfoBudgetBudgetInfoPostError, Schemas.BudgetRequest, {}, {}, {}>({
    url: '/budget/info',
    method: 'post',
    ...variables,
    signal
  });

export type BudgetSettingsBudgetSettingsGetQueryParams = {
  budget_id: string;
};

export type BudgetSettingsBudgetSettingsGetError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type BudgetSettingsBudgetSettingsGetResponse = {
  [key: string]: any;
};

export type BudgetSettingsBudgetSettingsGetVariables = {
  queryParams: BudgetSettingsBudgetSettingsGetQueryParams;
} & FetcherExtraProps;

/**
 * Get list of configurable params + current value for a budget item + description of each field
 *
 * Used on Admin UI.
 *
 * Query Parameters:
 * - budget_id: str - The budget id to get information for
 */
export const budgetSettingsBudgetSettingsGet = (
  variables: BudgetSettingsBudgetSettingsGetVariables,
  signal?: AbortSignal
) =>
  fetch<
    BudgetSettingsBudgetSettingsGetResponse,
    BudgetSettingsBudgetSettingsGetError,
    undefined,
    {},
    BudgetSettingsBudgetSettingsGetQueryParams,
    {}
  >({ url: '/budget/settings', method: 'get', ...variables, signal });

export type ListBudgetBudgetListGetError = Fetcher.ErrorWrapper<undefined>;

export type ListBudgetBudgetListGetResponse = {
  [key: string]: any;
};

export type ListBudgetBudgetListGetVariables = FetcherExtraProps;

/**
 * List all the created budgets in proxy db. Used on Admin UI.
 */
export const listBudgetBudgetListGet = (variables: ListBudgetBudgetListGetVariables, signal?: AbortSignal) =>
  fetch<ListBudgetBudgetListGetResponse, ListBudgetBudgetListGetError, undefined, {}, {}, {}>({
    url: '/budget/list',
    method: 'get',
    ...variables,
    signal
  });

export type DeleteBudgetBudgetDeletePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteBudgetBudgetDeletePostResponse = {
  [key: string]: any;
};

export type DeleteBudgetBudgetDeletePostVariables = {
  body: Schemas.BudgetDeleteRequest;
} & FetcherExtraProps;

/**
 * Delete budget
 *
 * Parameters:
 * - id: str - The budget id to delete
 */
export const deleteBudgetBudgetDeletePost = (variables: DeleteBudgetBudgetDeletePostVariables, signal?: AbortSignal) =>
  fetch<
    DeleteBudgetBudgetDeletePostResponse,
    DeleteBudgetBudgetDeletePostError,
    Schemas.BudgetDeleteRequest,
    {},
    {},
    {}
  >({ url: '/budget/delete', method: 'post', ...variables, signal });

export type PatchModelModelModelIdUpdatePatchPathParams = {
  modelId: string;
};

export type PatchModelModelModelIdUpdatePatchError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type PatchModelModelModelIdUpdatePatchVariables = {
  body?: Schemas.UpdateDeployment;
  pathParams: PatchModelModelModelIdUpdatePatchPathParams;
} & FetcherExtraProps;

/**
 * PATCH Endpoint for partial model updates.
 *
 * Only updates the fields specified in the request while preserving other existing values.
 * Follows proper PATCH semantics by only modifying provided fields.
 *
 * Args:
 *     model_id: The ID of the model to update
 *     patch_data: The fields to update and their new values
 *     user_api_key_dict: User authentication information
 *
 * Returns:
 *     Updated model information
 *
 * Raises:
 *     ProxyException: For various error conditions including authentication and database errors
 */
export const patchModelModelModelIdUpdatePatch = (
  variables: PatchModelModelModelIdUpdatePatchVariables,
  signal?: AbortSignal
) =>
  fetch<
    void,
    PatchModelModelModelIdUpdatePatchError,
    Schemas.UpdateDeployment,
    {},
    {},
    PatchModelModelModelIdUpdatePatchPathParams
  >({ url: '/model/{modelId}/update', method: 'patch', ...variables, signal });

export type DeleteModelModelDeletePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type DeleteModelModelDeletePostResponse = {
  [key: string]: any;
};

export type DeleteModelModelDeletePostVariables = {
  body: Schemas.ModelInfoDelete;
} & FetcherExtraProps;

/**
 * Allows deleting models in the model list in the config.yaml
 */
export const deleteModelModelDeletePost = (variables: DeleteModelModelDeletePostVariables, signal?: AbortSignal) =>
  fetch<DeleteModelModelDeletePostResponse, DeleteModelModelDeletePostError, Schemas.ModelInfoDelete, {}, {}, {}>({
    url: '/model/delete',
    method: 'post',
    ...variables,
    signal
  });

export type AddNewModelModelNewPostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type AddNewModelModelNewPostResponse = {
  [key: string]: any;
};

export type AddNewModelModelNewPostVariables = {
  body: Schemas.Deployment;
} & FetcherExtraProps;

/**
 * Allows adding new models to the model list in the config.yaml
 */
export const addNewModelModelNewPost = (variables: AddNewModelModelNewPostVariables, signal?: AbortSignal) =>
  fetch<AddNewModelModelNewPostResponse, AddNewModelModelNewPostError, Schemas.Deployment, {}, {}, {}>({
    url: '/model/new',
    method: 'post',
    ...variables,
    signal
  });

export type UpdateModelModelUpdatePostError = Fetcher.ErrorWrapper<{
  status: 422;
  payload: Schemas.HTTPValidationError;
}>;

export type UpdateModelModelUpdatePostResponse = {
  [key: string]: any;
};

export type UpdateModelModelUpdatePostVariables = {
  body?: Schemas.UpdateDeployment;
} & FetcherExtraProps;

/**
 * Edit existing model params
 */
export const updateModelModelUpdatePost = (variables: UpdateModelModelUpdatePostVariables, signal?: AbortSignal) =>
  fetch<UpdateModelModelUpdatePostResponse, UpdateModelModelUpdatePostError, Schemas.UpdateDeployment, {}, {}, {}>({
    url: '/model/update',
    method: 'post',
    ...variables,
    signal
  });

export const operationsByTag = {
  modelManagement: {
    modelListModelsGet,
    modelListV1ModelsGet,
    modelInfoV1V1ModelInfoGet,
    modelInfoV1ModelInfoGet,
    modelGroupInfoModelGroupInfoGet,
    patchModelModelModelIdUpdatePatch,
    deleteModelModelDeletePost,
    addNewModelModelNewPost,
    updateModelModelUpdatePost
  },
  chatCompletions: {
    chatCompletionOpenaiDeploymentsModelChatCompletionsPost,
    chatCompletionEnginesModelChatCompletionsPost,
    chatCompletionChatCompletionsPost,
    chatCompletionV1ChatCompletionsPost
  },
  completions: {
    completionOpenaiDeploymentsModelCompletionsPost,
    completionEnginesModelCompletionsPost,
    completionCompletionsPost,
    completionV1CompletionsPost
  },
  embeddings: {
    embeddingsOpenaiDeploymentsModelEmbeddingsPost,
    embeddingsEnginesModelEmbeddingsPost,
    embeddingsEmbeddingsPost,
    embeddingsV1EmbeddingsPost
  },
  images: { imageGenerationImagesGenerationsPost, imageGenerationV1ImagesGenerationsPost },
  audio: {
    audioSpeechAudioSpeechPost,
    audioSpeechV1AudioSpeechPost,
    audioTranscriptionsAudioTranscriptionsPost,
    audioTranscriptionsV1AudioTranscriptionsPost
  },
  assistants: {
    getAssistantsAssistantsGet,
    createAssistantAssistantsPost,
    getAssistantsV1AssistantsGet,
    createAssistantV1AssistantsPost,
    deleteAssistantAssistantsAssistantIdDelete,
    deleteAssistantV1AssistantsAssistantIdDelete,
    createThreadsThreadsPost,
    createThreadsV1ThreadsPost,
    getThreadThreadsThreadIdGet,
    getThreadV1ThreadsThreadIdGet,
    addMessagesThreadsThreadIdMessagesPost,
    getMessagesThreadsThreadIdMessagesGet,
    addMessagesV1ThreadsThreadIdMessagesPost,
    getMessagesV1ThreadsThreadIdMessagesGet,
    runThreadThreadsThreadIdRunsPost,
    runThreadV1ThreadsThreadIdRunsPost
  },
  moderations: { moderationsModerationsPost, moderationsV1ModerationsPost },
  llmUtils: {
    tokenCounterUtilsTokenCounterPost,
    supportedOpenaiParamsUtilsSupportedOpenaiParamsGet,
    transformRequestUtilsTransformRequestPost
  },
  responses: {
    responsesApiResponsesPost,
    responsesApiV1ResponsesPost,
    getResponseResponsesResponseIdGet,
    deleteResponseResponsesResponseIdDelete,
    getResponseV1ResponsesResponseIdGet,
    deleteResponseV1ResponsesResponseIdDelete,
    getResponseInputItemsResponsesResponseIdInputItemsGet,
    getResponseInputItemsV1ResponsesResponseIdInputItemsGet
  },
  batch: {
    createBatchBatchesPost,
    listBatchesBatchesGet,
    createBatchV1BatchesPost,
    listBatchesV1BatchesGet,
    createBatchProviderV1BatchesPost,
    listBatchesProviderV1BatchesGet,
    retrieveBatchBatchesBatchIdGet,
    retrieveBatchV1BatchesBatchIdGet,
    retrieveBatchProviderV1BatchesBatchIdGet,
    cancelBatchBatchesBatchIdCancelPost,
    cancelBatchV1BatchesBatchIdCancelPost,
    cancelBatchProviderV1BatchesBatchIdCancelPost
  },
  rerank: { rerankRerankPost, rerankV1RerankPost, rerankV2RerankPost },
  fineTuning: {
    createFineTuningJobFineTuningJobsPost,
    listFineTuningJobsFineTuningJobsGet,
    createFineTuningJobV1FineTuningJobsPost,
    listFineTuningJobsV1FineTuningJobsGet,
    retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet,
    retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet,
    cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost,
    cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost
  },
  credentialManagement: {
    getCredentialsCredentialsGet,
    createCredentialCredentialsPost,
    getCredentialCredentialsByModelModelIdGet,
    getCredentialCredentialsByNameCredentialNameGet,
    deleteCredentialCredentialsCredentialNameDelete,
    updateCredentialCredentialsCredentialNamePatch
  },
  mcp: {
    handleSseMcpGet,
    handleMessagesMcpSseMessagesPost,
    listToolRestApiMcpToolsListGet,
    callToolRestApiMcpToolsCallPost
  },
  health: {
    testEndpointTestGet,
    healthServicesEndpointHealthServicesGet,
    healthEndpointHealthGet,
    activeCallbacksActiveCallbacksGet,
    activeCallbacksSettingsGet,
    healthReadinessHealthReadinessGet,
    healthLivelinessHealthLivenessGet,
    healthLivelinessHealthLivelinessGet,
    testModelConnectionHealthTestConnectionPost
  },
  keyManagement: {
    generateKeyFnKeyGeneratePost,
    updateKeyFnKeyUpdatePost,
    deleteKeyFnKeyDeletePost,
    infoKeyFnKeyInfoGet,
    regenerateKeyFnKeyRegeneratePost,
    regenerateKeyFnKeyKeyRegeneratePost,
    listKeysKeyListGet,
    blockKeyKeyBlockPost,
    unblockKeyKeyUnblockPost,
    keyHealthKeyHealthPost
  },
  internalUserManagement: {
    newUserUserNewPost,
    userInfoUserInfoGet,
    userUpdateUserUpdatePost,
    getUsersUserListGet,
    getUsersUserGetUsersGet,
    deleteUserUserDeletePost,
    getUserDailyActivityUserDailyActivityGet
  },
  budgetSpendTracking: {
    getUserDailyActivityUserDailyActivityGet,
    viewSpendTagsSpendTagsGet,
    getGlobalSpendReportGlobalSpendReportGet,
    globalViewSpendTagsGlobalSpendTagsGet,
    calculateSpendSpendCalculatePost,
    viewSpendLogsSpendLogsGet,
    globalSpendResetGlobalSpendResetPost,
    addAllowedIpAddAllowedIpPost,
    deleteAllowedIpDeleteAllowedIpPost
  },
  teamManagement: {
    newTeamTeamNewPost,
    updateTeamTeamUpdatePost,
    teamMemberAddTeamMemberAddPost,
    teamMemberDeleteTeamMemberDeletePost,
    teamMemberUpdateTeamMemberUpdatePost,
    deleteTeamTeamDeletePost,
    teamInfoTeamInfoGet,
    blockTeamTeamBlockPost,
    unblockTeamTeamUnblockPost,
    listTeamTeamListGet,
    teamModelAddTeamModelAddPost,
    teamModelDeleteTeamModelDeletePost,
    addTeamCallbacksTeamTeamIdCallbackPost,
    getTeamCallbacksTeamTeamIdCallbackGet,
    disableTeamLoggingTeamTeamIdDisableLoggingPost
  },
  organizationManagement: {
    newOrganizationOrganizationNewPost,
    updateOrganizationOrganizationUpdatePatch,
    deleteOrganizationOrganizationDeleteDelete,
    listOrganizationOrganizationListGet,
    infoOrganizationOrganizationInfoGet,
    deprecatedInfoOrganizationOrganizationInfoPost,
    organizationMemberAddOrganizationMemberAddPost,
    organizationMemberUpdateOrganizationMemberUpdatePatch,
    organizationMemberDeleteOrganizationMemberDeleteDelete
  },
  customerManagement: {
    blockUserCustomerBlockPost,
    unblockUserCustomerUnblockPost,
    newEndUserCustomerNewPost,
    endUserInfoCustomerInfoGet,
    updateEndUserCustomerUpdatePost,
    deleteEndUserCustomerDeletePost,
    listEndUserCustomerListGet
  },
  caching: {
    cachePingCachePingGet,
    cacheDeleteCacheDeletePost,
    cacheRedisInfoCacheRedisInfoGet,
    cacheFlushallCacheFlushallPost
  },
  guardrails: { listGuardrailsGuardrailsListGet },
  sSOSettings: { getSsoSettingsGetInternalUserSettingsGet, updateInternalUserSettingsUpdateInternalUserSettingsPatch },
  files: {
    createFileFilesPost,
    listFilesFilesGet,
    createFileV1FilesPost,
    listFilesV1FilesGet,
    createFileProviderV1FilesPost,
    listFilesProviderV1FilesGet,
    getFileContentFilesFileIdContentGet,
    getFileContentV1FilesFileIdContentGet,
    getFileContentProviderV1FilesFileIdContentGet,
    getFileFilesFileIdGet,
    deleteFileFilesFileIdDelete,
    getFileV1FilesFileIdGet,
    deleteFileV1FilesFileIdDelete,
    getFileProviderV1FilesFileIdGet,
    deleteFileProviderV1FilesFileIdDelete
  },
  budgetManagement: {
    newBudgetBudgetNewPost,
    updateBudgetBudgetUpdatePost,
    infoBudgetBudgetInfoPost,
    budgetSettingsBudgetSettingsGet,
    listBudgetBudgetListGet,
    deleteBudgetBudgetDeletePost
  }
};
